{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# author: patricewangen\n",
    "# created: 21 February 2020\n",
    "# last_edited: 25 February 2020\n",
    "##########################################################################\n",
    "\n",
    "# TODO\n",
    "# (1) Homework Solutions\n",
    "# (2) Document-Term Matrices\n",
    "# (3) Pre-Processing: Tokenizing, Removing-Stuff, Stemming\n",
    "# (4) Pairwise Cosine Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Exercise 03\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# (1) Browse through the raw Twitter object, try to understand its \n",
    "# structure, and extract the following information about the status \n",
    "# update: \"user_id\", \"user_handle\", \"user_loc\", \"user_desc\", \"tweet_text\", \n",
    "# \"tweet_id\", \"tweet_time\"\n",
    "\n",
    "# For this, we need some functionalities from the json package. Let's \n",
    "# load it into our current python session\n",
    "import json\n",
    "\n",
    "# Let's open the JSON file with the 25.000 Twitter objects. First, we\n",
    "# read it into our python session as a simple text file.\n",
    "json_data = open(\"DATA/2019-12-06_16-43-32.json\").read()\n",
    "\n",
    "# Then we use the json.loads() function to recognize the python-like\n",
    "# json structures encoded into this string. In this case, it should\n",
    "# return a list ([]) of strings (\"\")\n",
    "json_data = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Fri Dec 06 14:24:28 +0000 2019',\n",
       " 'id': 1202956978286452738,\n",
       " 'id_str': '1202956978286452738',\n",
       " 'text': 'RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\\n\\nWhy would I only want to…',\n",
       " 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       " 'truncated': False,\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'user': {'id': 2496109354,\n",
       "  'id_str': '2496109354',\n",
       "  'name': 'robert',\n",
       "  'screen_name': 'rb218702',\n",
       "  'location': 'Northampton, England',\n",
       "  'url': None,\n",
       "  'description': 'British liberal, artist, check out my instagram page rob_burch_arts.',\n",
       "  'translator_type': 'none',\n",
       "  'protected': False,\n",
       "  'verified': False,\n",
       "  'followers_count': 230,\n",
       "  'friends_count': 614,\n",
       "  'listed_count': 2,\n",
       "  'favourites_count': 30169,\n",
       "  'statuses_count': 40775,\n",
       "  'created_at': 'Sun Apr 20 01:48:49 +0000 2014',\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': True,\n",
       "  'lang': None,\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'profile_background_color': 'C0DEED',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_link_color': '1DA1F2',\n",
       "  'profile_sidebar_border_color': 'C0DEED',\n",
       "  'profile_sidebar_fill_color': 'DDEEF6',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/948960672272060416/eDqUj4Ni_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/948960672272060416/eDqUj4Ni_normal.jpg',\n",
       "  'default_profile': True,\n",
       "  'default_profile_image': False,\n",
       "  'following': None,\n",
       "  'follow_request_sent': None,\n",
       "  'notifications': None},\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'retweeted_status': {'created_at': 'Fri Dec 06 12:41:07 +0000 2019',\n",
       "  'id': 1202930969830985728,\n",
       "  'id_str': '1202930969830985728',\n",
       "  'text': 'If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\\n\\nWhy would I only w… https://t.co/IReDDMuYTH',\n",
       "  'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
       "  'truncated': True,\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'in_reply_to_screen_name': None,\n",
       "  'user': {'id': 117777690,\n",
       "   'id_str': '117777690',\n",
       "   'name': 'Jeremy Corbyn',\n",
       "   'screen_name': 'jeremycorbyn',\n",
       "   'location': 'UK',\n",
       "   'url': 'https://volunteer.labour.org.uk/',\n",
       "   'description': 'Leader of the Labour Party.',\n",
       "   'translator_type': 'none',\n",
       "   'protected': False,\n",
       "   'verified': True,\n",
       "   'followers_count': 2248731,\n",
       "   'friends_count': 2650,\n",
       "   'listed_count': 7762,\n",
       "   'favourites_count': 248,\n",
       "   'statuses_count': 13704,\n",
       "   'created_at': 'Fri Feb 26 15:45:23 +0000 2010',\n",
       "   'utc_offset': None,\n",
       "   'time_zone': None,\n",
       "   'geo_enabled': True,\n",
       "   'lang': None,\n",
       "   'contributors_enabled': False,\n",
       "   'is_translator': False,\n",
       "   'profile_background_color': '131516',\n",
       "   'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme14/bg.gif',\n",
       "   'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme14/bg.gif',\n",
       "   'profile_background_tile': True,\n",
       "   'profile_link_color': '009999',\n",
       "   'profile_sidebar_border_color': '000000',\n",
       "   'profile_sidebar_fill_color': '000000',\n",
       "   'profile_text_color': '000000',\n",
       "   'profile_use_background_image': True,\n",
       "   'profile_image_url': 'http://pbs.twimg.com/profile_images/1197846676578426880/EiaPjwTi_normal.jpg',\n",
       "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1197846676578426880/EiaPjwTi_normal.jpg',\n",
       "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/117777690/1506521898',\n",
       "   'default_profile': False,\n",
       "   'default_profile_image': False,\n",
       "   'following': None,\n",
       "   'follow_request_sent': None,\n",
       "   'notifications': None},\n",
       "  'geo': None,\n",
       "  'coordinates': None,\n",
       "  'place': None,\n",
       "  'contributors': None,\n",
       "  'is_quote_status': False,\n",
       "  'extended_tweet': {'full_text': 'If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\\n\\nWhy would I only want to talk to half the country? I don’t want to live in half a country.\\n\\nA prime minister must talk and listen to everyone - and bring our divided country together.',\n",
       "   'display_text_range': [0, 280],\n",
       "   'entities': {'hashtags': [],\n",
       "    'urls': [],\n",
       "    'user_mentions': [],\n",
       "    'symbols': []}},\n",
       "  'quote_count': 655,\n",
       "  'reply_count': 1461,\n",
       "  'retweet_count': 8068,\n",
       "  'favorite_count': 36096,\n",
       "  'entities': {'hashtags': [],\n",
       "   'urls': [{'url': 'https://t.co/IReDDMuYTH',\n",
       "     'expanded_url': 'https://twitter.com/i/web/status/1202930969830985728',\n",
       "     'display_url': 'twitter.com/i/web/status/1…',\n",
       "     'indices': [117, 140]}],\n",
       "   'user_mentions': [],\n",
       "   'symbols': []},\n",
       "  'favorited': False,\n",
       "  'retweeted': False,\n",
       "  'filter_level': 'low',\n",
       "  'lang': 'en'},\n",
       " 'is_quote_status': False,\n",
       " 'quote_count': 0,\n",
       " 'reply_count': 0,\n",
       " 'retweet_count': 0,\n",
       " 'favorite_count': 0,\n",
       " 'entities': {'hashtags': [],\n",
       "  'urls': [],\n",
       "  'user_mentions': [{'screen_name': 'jeremycorbyn',\n",
       "    'name': 'Jeremy Corbyn',\n",
       "    'id': 117777690,\n",
       "    'id_str': '117777690',\n",
       "    'indices': [3, 16]}],\n",
       "  'symbols': []},\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'filter_level': 'low',\n",
       " 'lang': 'en',\n",
       " 'timestamp_ms': '1575642268140'}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each of these strings contains a raw Twitter object that is again\n",
    "# encoded into python-like json structures. We keep these as strings\n",
    "# because the complex nested structures of the raw Twitter object\n",
    "# would slow python down. So, if we want to process these Tweets, let's\n",
    "# do so one by one. Let's look at the first one (list index = 0):\n",
    "tweet = json.loads(json_data[0])\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user_id is: 2496109354\n",
      "The user_handle is: rb218702\n",
      "The user_loc(ation) is: Northampton, England\n",
      "The user_desc(ription) is: British liberal, artist, check out my instagram page rob_burch_arts.\n",
      "The tweet_text is: RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "The tweet_id is: 1202956978286452738\n",
      "The tweet_time is: Fri Dec 06 14:24:28 +0000 2019\n"
     ]
    }
   ],
   "source": [
    "# Once we used the json package to convert this string into a \n",
    "# python-like data structure, we see that we are dealing with\n",
    "# a complex and nested dictionary that we can subset with the\n",
    "# tools we learned in the last classes.\n",
    "# We are supposed to find the following information about this\n",
    "# Twitter object: \"user_id\", \"user_handle\", \"user_loc\", \n",
    "# \"user_desc\", \"tweet_text\", \"tweet_id\", \"tweet_time\"\n",
    "\n",
    "# Here are the solutions\n",
    "print(\"The user_id is: \" + tweet['user']['id_str']) # Or user str(tweet['id']) to convert an integer object into a string we can use with print()\n",
    "print(\"The user_handle is: \" + tweet['user']['screen_name'])\n",
    "print(\"The user_loc(ation) is: \" + tweet['user']['location']) # note that this is self-declared and not based on GPS\n",
    "print(\"The user_desc(ription) is: \" + tweet['user']['description']) \n",
    "print(\"The tweet_text is: \" + tweet['text']) # see exercise 3 for further complications to this\n",
    "print(\"The tweet_id is: \" + tweet['id_str'])\n",
    "print(\"The tweet_time is: \" + tweet['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fri Dec 06 14:24:28 +0000 2019'"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2) Check out the time package and try to convert Twitter's time \n",
    "# signature into the format \"29/05/2019 07:04\"\n",
    "\n",
    "# Let's load the time package into our current python session\n",
    "import time\n",
    "\n",
    "# It has two functions that are relevant here:\n",
    "# - strptime() takes a string with date-time information and \n",
    "# creates a standardized date-time object (another object type \n",
    "# next to lists, dictionaries, etc.)\n",
    "# - strftime() takes a data-time object and creates a string\n",
    "# version of the date-time according to your own specification\n",
    "\n",
    "# Let's store the time-string from the Twitter dictionary into a\n",
    "# separate object for processing.\n",
    "tweet_time = tweet['created_at']\n",
    "tweet_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time.struct_time(tm_year=2019, tm_mon=12, tm_mday=6, tm_hour=14, tm_min=24, tm_sec=28, tm_wday=4, tm_yday=340, tm_isdst=-1)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following creates a structured date-time object based on\n",
    "# where we tell the function to look for each specific information\n",
    "# in the string. We do so by comparing the string structure with\n",
    "# the documentation of the strptime function in the time package:\n",
    "# https://docs.python.org/3/library/time.html\n",
    "tweet_time = time.strptime(tweet_time,'%a %b %d %H:%M:%S +0000 %Y')\n",
    "tweet_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-12-06 14:24:28'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can turn this structured time object into a new string that\n",
    "# lives up to whatever we need:\n",
    "tweet_time_str = time.strftime(\"%Y-%m-%d %H:%M:%S\", tweet_time)\n",
    "tweet_time_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-12-06'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can use the structured time objects in python if you want to \n",
    "# do, e.g., time-series analysis or plot a timeline in python. If you\n",
    "# move to another programm (R or STATA), you might want to turn this \n",
    "# into the respectively useful string format. Alternatively, you could \n",
    "# also use this to aggregate Tweets per day:\n",
    "tweet_data_str = time.strftime(\"%Y-%m-%d\", tweet_time)\n",
    "tweet_data_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tweet_text is: RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "\n",
      "Most likely, we are dealing with a: Retweet\n",
      "\n",
      "So the full length original tweet is: \n",
      " If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to talk to half the country? I don’t want to live in half a country.\n",
      "\n",
      "A prime minister must talk and listen to everyone - and bring our divided country together.\n"
     ]
    }
   ],
   "source": [
    "# (3) Go through multiple Twitter objects and try to understand the \n",
    "# inconsistencies in which Tweet texts are stored depending on Tweet type\n",
    "# and text length.\n",
    "\n",
    "# The tweet text is a bit of a complicated story. Usually, you \n",
    "# will be able to find the text in tweet['text']... (see exercise 3 \n",
    "# for further complications)\n",
    "print(\"The tweet_text is: \" + tweet['text']) \n",
    "\n",
    "# But there are some exceptions to be wary about:\n",
    "# - Longer texts: If the tweet text exceeds a certain length, \n",
    "# you will find the non-abbreviated text in tweet['extended_tweet']['full_text']\n",
    "\n",
    "# - Retweets: You will find the full non-abbreviated original Tweet text\n",
    "# in tweet['retweeted_status']['text'], unless the original Tweet\n",
    "# was a longer text, in which case it is the same story as above \n",
    "# tweet['retweeted_status']['extended_tweet']['full_text']\n",
    "\n",
    "# - Quotes: If we are dealing with a quoted text, the tweet['text']\n",
    "# refers to the comment by the user, but you can get the original\n",
    "# quoted text with tweet['quoted_status']['text'] or \n",
    "# tweet['quoted_status']['extended_tweet']['full_text'] depending on \n",
    "# the length of the quoted tweet. \n",
    "\n",
    "# You can check with which type of Twitter object you are dealing with\n",
    "# by using some nested conditional questions:\n",
    "tweet_type = \"Tweet\"\n",
    "if 'quoted_status' in tweet:\n",
    "    tweet_type = \"Quote\"\n",
    "if 'retweeted_status' in tweet:\n",
    "    tweet_type = \"Retweet\"\n",
    "    if 'quoted_status' in tweet:\n",
    "        tweet_type = \"Re_Quote\"\n",
    "            \n",
    "print(\"\\nMost likely, we are dealing with a: \" + tweet_type)\n",
    "print(\"\\nSo the full length original tweet is: \\n \" + tweet['retweeted_status']['extended_tweet']['full_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>user_desc</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, user_handle, user_loc, user_desc, tweet_text, tweet_id, tweet_time]\n",
       "Index: []"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (4) Create a new pandas dataframe to store the information extracted in\n",
    "# the first task. Try to create a pandas dataframe without any content\n",
    "# a.k.a. an empty dataframe. This will be your master dataframe to which\n",
    "# you append information from Twitter objects row-by-row. (call it \"df\")\n",
    "\n",
    "# Let's load the pandas package into our python session under the name pd\n",
    "import pandas as pd\n",
    "\n",
    "# Let's define the relevant columns for these exercises (later one, you\n",
    "# might add columns depending on what you want to extract from the raw\n",
    "# Twitter data)\n",
    "selected_cols = [\"user_id\", \"user_handle\", \"user_loc\", \"user_desc\", \n",
    "                 \"tweet_text\", \"tweet_id\", \"tweet_time\"]\n",
    "\n",
    "# Now, let's create a DataFrame that does not contain any data to which\n",
    "# we will add a new row for each Twitter object we process. To create\n",
    "# a dataframe with 0 rows, we can use an empty list ([]) as the first\n",
    "# argument of the DataFrame() function\n",
    "df = pd.DataFrame([], columns=selected_cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @LaboursBlackPLP: This is massive, Former Tory Prime Minister will not be voting Tory and neither should you.\n",
      "\n",
      "John Major breaks Tory ra…\n",
      "RT @faisalislam: table in leaked Government presentation shows extraordinary new Irish Sea checks on the cards as a result of PMs Brexit de…\n",
      "RT @Conservatives: \"This is a Brexit election after all – and a vote for @BorisJohnson this time around is a vote to #GetBrexitDone\"\n",
      "\n",
      "🌳🗳 #V…\n",
      "@KLbils @BiztheBuz @NickBoles @jeremycorbyn Please bear in mind that if brexit is the biggest issue for you, you are extremely privileged.\n",
      "RT @DavidLammy: Evidence that @BorisJohnson is lying again and doing what he previously said he would never accept. Putting a border down t…\n",
      "RT @LeaveEUOfficial: In a letter to the anti-Semite, Boris blasts Corbyn's \"sly attempt to undermine the result of the 2016 referendum\" by…\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @achrisafis: “If we want to treat Macron as a future leader for the whole of Europe, in a political sense, then for this we need a polit…\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @chrisinsilico: I can’t get over this. The Prime Minister literally just said he wants to subject people of colour to “democratic contro…\n",
      "Good thread.\n",
      "RT @LFIU2019: BREAKING NEWS: Leaked documents shows the truth about British border in the Island of Ireland. #VoteLabour #NeverTrustATory…\n",
      "RT @OwenJones84: The leaked document revealed by Jeremy Corbyn exposes Boris Johnson is lying about Brexit and Northern Ireland, just like…\n",
      "EU distances itself from Johnson’s timetable for post-Brexit trade deal\n",
      "\n",
      "https://t.co/CrukzmUg4i\n",
      "@DevonianMatthew I knew Brexit would put it up again!\n",
      "RT @August05398614: How can anyone vote for an existing PM who will sleep with your granny to get a vote and the nation has a number 1 hit…\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @billnewtondunn: How many benefits to EU membership can I list in 60 seconds? Not enough as it turns out. With fewer than 60 days to go…\n",
      "RT @RichardCollettW: Electoral Commission records show political parties and individual politicians have taken more than £9 million in gift…\n",
      "RT @LabourLeft: Brexit voter explains why it’s so important for ordinary working people to vote Labour in this election. \n",
      "\n",
      "Don’t be conned…\n",
      "RT @Channel4News: \"We have now caught Johnson red-handed misrepresenting his own Brexit deal.\"\n",
      "\n",
      "Jeremy Corbyn says Labour has a \"confidenti…\n",
      "RT @BrexitPartridge: If the Left didn't hate him enough, Boris goes to a Jewish bakery 😂👊👍 https://t.co/ThRmKgJNnS\n",
      "RT @LaurakBuzz: Jeremy Corbyn releases leaked government documents that show Boris Johnson 'lied about Brexit deal' https://t.co/Zo9qyQEzI7\n",
      "RT @Keir_Starmer: Boris Johnson has been caught out lying (again) about the damaging impact of his Brexit deal.\n",
      " \n",
      "Johnson has repeatedly sa…\n",
      "RT @UKLabour: Boris Johnson is lying to you about his plan for Brexit and his own Government's report proves it. https://t.co/KIH4O9Z9cZ\n",
      "RT @alexwickham: NEW: Boris Johnson team launches furious attack on Channel 4\n",
      "\n",
      "Accuses the broadcaster of “inventing the most damaging thin…\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @JohnGPeet: Why I am worried about Johnson getting Brexit done, short thread based on my piece in this week’s Economist./1\n",
      "You know you've reached ridiculous levels of social media #Brexit stupidity, when people (including certain Sky presenters) are even being triggered by the PM's gf posting a harmless video of two sibling dogs playing. https://t.co/4qGDhe8T9N\n",
      "RT @Mandoline_Blue: BREAKING game changer! EU has changed its stance on BJ's deal. The latest EU text says UK must respect EU standards on…\n",
      "RT @thomasbrake: You can't be pro-business and pro-Brexit. And a damaging Brexit makes a mockery of manifesto promises. \n",
      "\n",
      "The Lib Dems have…\n",
      "@bbclaurak https://t.co/wZEbLjZJgm\n",
      "RT @BBCPolitics: General election 2019: Johnson 'misrepresenting' Brexit deal, says Corbyn \n",
      "\n",
      "https://t.co/gKzEUx7Mrv\n",
      "RT @UKLabour: Boris Johnson is lying to you about his plan for Brexit and his own Government's report proves it. https://t.co/KIH4O9Z9cZ\n",
      "RT @LanceForman: OFFICIAL CONFESSION\n",
      "\n",
      "People have asked what the Tories have offered me.   \n",
      "\n",
      "Here goes:\n",
      "\n",
      "1. Getting Brexit done\n",
      "\n",
      "2. Keeping…\n",
      "RT @celtjules66: If you’re considering voting Tory to “get Brexit done “, I’m afraid you’re going to have a long wait.\n",
      "Please spare a thoug…\n",
      "RT @DianaHarding7: Brexit Party candidate who was sent death threats from far-left activists is run off the road while campaigning in Donca…\n",
      "RT @BrexitPartridge: If the Left didn't hate him enough, Boris goes to a Jewish bakery 😂👊👍 https://t.co/ThRmKgJNnS\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @DavidLammy: Huge blow for @Conservatives. Former Conservative Prime Minister John Major urging the public to vote against Boris Johnson…\n",
      "RT @chrisinsilico: I can’t get over this. The Prime Minister literally just said he wants to subject people of colour to “democratic contro…\n",
      "@MarkTowler1 @LanceForman @Conservatives @BorisJohnson Yes because Brexit didn’t have a majority in Parliament\n",
      "\n",
      "If you want Brexit done, but don’t want to vote Conservative, what on Earth is the grand plan? \n",
      "\n",
      "If you are voting Brexit Party then I can only think that on some subconscious level you actually don’t want to leave the EU\n",
      "RT @PeoplesMomentum: Brexit voter has something to say to Boris Johnson.\n",
      "\n",
      "#Brexit #GE2019 https://t.co/lv7r7fDB9H\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @Cleisthenes6: @john4brexit Boris Johnson lied to the DUP. No border down the Irish Sea \n",
      "\n",
      "He lied to NI businesspeople a few weeks ago.…\n",
      "RT @DCHutchings: EU distances itself from Johnson’s timetable for post-Brexit trade deal\n",
      "\n",
      "https://t.co/CrukzmUg4i\n",
      "RT @BenJolly9: This man nails the real divide in our society - “The problems have got nothing to do with Brexit, the problems have been inf…\n",
      "https://t.co/RkmkFt7o9b\n",
      "RT @pmdfoster: There is a lot of 'nothing to see here' response to leaked @hmtreasury assessment of @BorisJohnson #Brexit Northern Ireland…\n",
      "Just how I'm feeling too\n",
      "RT @grahambsi: John Major breaks Tory ranks as he urges young voters to stop Boris Johnson's Brexit plan | London Evening Standard https://…\n",
      "RT @cliodiaspora: I have no idea how low you still intend to sink, ⁦@BorisJohnson,⁩ but how dare you argue that giving us EU citizens a vot…\n",
      "RT @Peston: A Tory former prime minister Sir John Major does something extraordinary in an extraordinary election. He says vote to stop Bre…\n",
      "RT @DavidLammy: Huge blow for @Conservatives. Former Conservative Prime Minister John Major urging the public to vote against Boris Johnson…\n",
      "RT @anotherview16: We knew Boris Johnson wasn't telling us the whole Brexit deal story - but this shows it was all DAMN LIES https://t.co/2…\n",
      "What Laura can't quite bring herself to say is \"he's been caught lying\"\n",
      "RT @UKLabour: BREAKING: A secret government report proves Boris Johnson is lying to the public about his plan for Brexit. \n",
      "If Boris Johnson…\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @DavidLammy: Huge blow for @Conservatives. Former Conservative Prime Minister John Major urging the public to vote against Boris Johnson…\n",
      "RT @nadialanomade: @HackedOffHugh Imagine the alternative. They get a majority. A hard Brexit is unstoppable. NHS is on the chopping block.…\n",
      "@femaledownfall You me and the BEST part of the population. All I can tell you, anyone who voted #Brexit or #Boris will not get to visit us in France. #harshbutfair\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "🎼 So here it is, Merry Christmas,\n",
      "Everybody's having fun.🎵\n",
      "🎼 @theSNP are scunnered,\n",
      "&amp; the 'Toaaarrrieees' are No.1🎵\n",
      "\n",
      "{STD Verse}\n",
      "\n",
      "🎼 So here it is, Merry Christmas,\n",
      "Everybody's having fun.🎵\n",
      "🎼Look to the future,\n",
      "#BrExit has just begun🎵\n",
      "\n",
      "#GE2019 \n",
      "#VoteConservative\n",
      "#BackBoris\n",
      "RT @Keir_Starmer: Boris Johnson has been caught out lying (again) about the damaging impact of his Brexit deal.\n",
      " \n",
      "Johnson has repeatedly sa…\n",
      "RT @juliefair: I am starting to think that this Brexit election is a massive  Trojan Horse, designed to slip in manifesto page 48 , so that…\n",
      "RT @jeremycorbyn: This leaked government document shows Boris Johnson hasn't been telling the truth to the people of our country about his…\n",
      "RT @Tpopularfront: There was a BBC series in the 90’s called ‘Our friends in the North’. Big budget, made massive stars of the main actors.…\n",
      "#NeverCorbyn #CorbynUnfit4PM #DONTVOTELABOUR #NeverLabour #TerroristSympathiser \n",
      "D\n",
      "O\n",
      "N\n",
      "T\n",
      "\n",
      "V\n",
      "O\n",
      "T\n",
      "E\n",
      "\n",
      "L\n",
      "A\n",
      "B\n",
      "O\n",
      "U\n",
      "R https://t.co/be9xpOrNTg\n",
      "@jeremycorbyn BREXIT UNDER LABOUR WONT HAPPEN - THE MAN IS INCAPABLE OF RUNNING A BATH -UNICORN IDEAS THAT WILL MAKE YOU POOR https://t.co/aKY8vjd8Cx\n",
      "RT @AudreyAurus1: Jeremy Corbyn doing the job that journalists are supposed to be doing... \n",
      "You know, dear journalists, there are more to f…\n",
      "RT @Shamils18: @bbclaurak Caught lying again?\n",
      "\n",
      "This is the only Brexit video everyone must watch.\n",
      "\n",
      "Whether you voted Leave or Remain, take…\n",
      "RT @lewis_goodall: This isn’t true. There will. \n",
      "\n",
      "The civil service says it. The Brexit Secretary says it. The PM’s de facto deputy says it…\n",
      "@paul13walnut5 @AnnieWellsMSP @ScotTories It's the risk of Brexit  - uncertainty and actuality - that is damaging business.\n",
      "\n",
      "Its Brexit that will be the shock that finally wakes Scotland to the need for independence. \n",
      "\n",
      "A happier, fairer, richer future awaits us.\n",
      "\n",
      "#ItsTime to #DissolveTheUnion\n",
      "RT @Peston: A Tory former prime minister Sir John Major does something extraordinary in an extraordinary election. He says vote to stop Bre…\n",
      "RT @Alex_Loze_Davis: All 6 constituencies in Cornwall have candidates from the new Liberal Party, which include 3 re. active UKIP campaigne…\n",
      "RT @nicktolhurst: I’ve been a bit skeptical about those attacking @bbclaurak\n",
      "..but when a leaked document reveals PM lied, NI economy utter…\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @DavidLammy: Huge blow for @Conservatives. Former Conservative Prime Minister John Major urging the public to vote against Boris Johnson…\n",
      "RT @AaronBastani: Labour is competitive in seats it needs to win but didn't last time: Swindon, Putney, Hendon, Southampton, Hastings.\n",
      "\n",
      "Mea…\n",
      "@prodlegacy @BorisJohnson Nope; that’s not correct.\n",
      "\n",
      "The Good Friday Agreement is a treaty between two countries.\n",
      "\n",
      "Whereas\n",
      "\n",
      "Brexit was an exercise in public opinion. It does not bind the UK Parliament since you are not a Republic. The UK people are not sovereign: your Parliament and your Queen are. https://t.co/CUbCRc7YuQ\n",
      "RT @DavidLammy: Evidence that @BorisJohnson is lying again and doing what he previously said he would never accept. Putting a border down t…\n",
      "RT @OwenJones84: The leaked document revealed by Jeremy Corbyn exposes Boris Johnson is lying about Brexit and Northern Ireland, just like…\n",
      "#BottleJobBoris does it again!\n",
      "The truth about whether Boris Johnson is misleading voters over his Brexit deal https://t.co/6Py0lKUTb8\n",
      "RT @BBCPolitics: Boris Johnson is asked about a leaked document, which Labour says shows his Brexit deal will mean checks between Northern…\n",
      "RT @jpwhite1985: My brother doing us proud on Question Time!!! “The problems have got nothing to do with Brexit, the problems have been inf…\n",
      "RT @faisalislam: table in leaked Government presentation shows extraordinary new Irish Sea checks on the cards as a result of PMs Brexit de…\n",
      "RT @trebor4128: @JWalton12267995 @Paula55855 @Lugey6 @DanielJHannan @LanceForman @zatzi @john4brexit @Conservatives Only Lucy has removed B…\n",
      "RT @SamCoatesSky: NEW - Leaked Treasury document, here in full, which suggests potential checks on goods going to/ from NI under Boris John…\n",
      "RT @13sarahmurphy: Everything about Brexit is stupid and really quite evil: the way the mandate has been twisted into a Tory wet dream, the…\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "If only we could all distance ourselves from Johnson.\n",
      "EU distances itself from Johnson’s timetable for post-Brexit trade deal https://t.co/ZKi09aEBQg\n",
      "#PantsOnFire #BorisOut #ToriesOut #BrexitShambles #brexitchaos #brexit #brexitbarometer\n",
      "RT @mrjamesob: Two former PMs to join Final Say rally calling for tactical voting to block majority for Boris Johnson https://t.co/RftokdKD…\n",
      "RT @Simon_Nixon: An astonishing moment. https://t.co/0L4puSOvPU\n",
      "RT @AngusRobertson: Interesting to see that negative impressions about Boris Johnson and his Brexit policy is making some traditional Scott…\n",
      "RT @MatthewGreen02: If, 4 years ago, someone said Tony Blair &amp; John Major, would both join a rally in a General Election that's explicitly…\n",
      "RT @bbclaurak: PM admitted there would be some checks in this interview here - acknowledges this was compromise with EU to avoid checks on…\n"
     ]
    }
   ],
   "source": [
    "# (5) Write a for-loop that runs through the first 100 Twitter objects \n",
    "# from the JSON data, converts the string into a dictionary, and prints \n",
    "# the tweet_text for each. \n",
    "# Tipp: Check our if-else statements to ensure that you extract the text \n",
    "# reliably for each Tweet format.\n",
    "\n",
    "# Let's loop through the first 100 elements in the json_data list, and\n",
    "# do some stuff for each Twitter object\n",
    "for ix in range(0, 100):\n",
    "    # First, let's turn the string into a dictionary that we can query\n",
    "    # for relevant information\n",
    "    tweet = json.loads(json_data[ix])\n",
    "    \n",
    "    # Now let's print the tweet text, and make sure we get the \n",
    "    # extended version in case the text is too long...\n",
    "    \n",
    "    if 'extended_tweet' in tweet: # If you find the key 'extended_tweet' in the tweet dictionary, do the following\n",
    "        print(tweet['extended_tweet']['full_text'])\n",
    "    else: # If you don't find the key 'extended_tweet' in the tweet dictionary, do this instead\n",
    "        print(tweet['text'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>user_desc</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  user_handle  user_loc  user_desc  tweet_text  tweet_id  tweet_time\n",
       "0      NaN          NaN       NaN        NaN         NaN       NaN         NaN"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (6) Extend this loop to create a new pandas dataframe with the same \n",
    "# columns as \"df\" and one row with np.nan for each column. (call it \n",
    "# \"new_row\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# First, let's define some empty data for the same columns as in the\n",
    "# df DataFrame, which we can use to store the respective information\n",
    "# for each Twitter object (see 03_Tasting.ipynb)\n",
    "empty_data = {col: [np.nan] for col in selected_cols}\n",
    "\n",
    "for ix in range(0, 100):\n",
    "    # Get the dictionary of the Twitter object\n",
    "    tweet = json.loads(json_data[ix])\n",
    "    \n",
    "    # Create an DataFrame with one empty row\n",
    "    new_row = pd.DataFrame(empty_data)\n",
    "    \n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>user_desc</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2496109354</td>\n",
       "      <td>rb218702</td>\n",
       "      <td>Northampton, England</td>\n",
       "      <td>British liberal, artist, check out my instagra...</td>\n",
       "      <td>RT @jeremycorbyn: If some accuse me of talking...</td>\n",
       "      <td>1202956978286452738</td>\n",
       "      <td>2019-12-06 14:24:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>496433273</td>\n",
       "      <td>david707x</td>\n",
       "      <td>Newport, Wales</td>\n",
       "      <td>http://Gov.UK/registertovote\\n#RemainAlliance\\...</td>\n",
       "      <td>RT @LaboursBlackPLP: This is massive, Former T...</td>\n",
       "      <td>1202956979284647938</td>\n",
       "      <td>2019-12-06 14:24:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3390733695</td>\n",
       "      <td>AndrewHemmingt2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @faisalislam: table in leaked Government pr...</td>\n",
       "      <td>1202956979838304260</td>\n",
       "      <td>2019-12-06 14:24:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>269708883</td>\n",
       "      <td>ferrier3</td>\n",
       "      <td>paisley</td>\n",
       "      <td>singer sometimes!</td>\n",
       "      <td>RT @Conservatives: \"This is a Brexit election ...</td>\n",
       "      <td>1202956980949786627</td>\n",
       "      <td>2019-12-06 14:24:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1038400204305850368</td>\n",
       "      <td>fran_oneill_s</td>\n",
       "      <td>Leeds, England</td>\n",
       "      <td>Feminist. Humanist. Cyclist. Likes kindness &amp; ...</td>\n",
       "      <td>@KLbils @BiztheBuz @NickBoles @jeremycorbyn Pl...</td>\n",
       "      <td>1202956981767720961</td>\n",
       "      <td>2019-12-06 14:24:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1822726884</td>\n",
       "      <td>MatthewGreen02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Director, Green Planning Studio @greenplanning...</td>\n",
       "      <td>RT @mrjamesob: Two former PMs to join Final Sa...</td>\n",
       "      <td>1202957080090599426</td>\n",
       "      <td>2019-12-06 14:24:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>124313779</td>\n",
       "      <td>Untidy_mind</td>\n",
       "      <td>UK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @Simon_Nixon: An astonishing moment. https:...</td>\n",
       "      <td>1202957080333828098</td>\n",
       "      <td>2019-12-06 14:24:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>431515838</td>\n",
       "      <td>mclaren_joanne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @AngusRobertson: Interesting to see that ne...</td>\n",
       "      <td>1202957080669425666</td>\n",
       "      <td>2019-12-06 14:24:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>104141401</td>\n",
       "      <td>angegarrod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#BlockTheCoup  Arty farty. Artist, photographe...</td>\n",
       "      <td>RT @MatthewGreen02: If, 4 years ago, someone s...</td>\n",
       "      <td>1202957082254860292</td>\n",
       "      <td>2019-12-06 14:24:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>351664268</td>\n",
       "      <td>rastahill</td>\n",
       "      <td>Eastbourne, East Sussex, UK</td>\n",
       "      <td>Husband, father. X Deputy CX Reigate &amp; Banstea...</td>\n",
       "      <td>RT @bbclaurak: PM admitted there would be some...</td>\n",
       "      <td>1202957082619785216</td>\n",
       "      <td>2019-12-06 14:24:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                user_id      user_handle                     user_loc  \\\n",
       "0            2496109354         rb218702         Northampton, England   \n",
       "1             496433273        david707x               Newport, Wales   \n",
       "2            3390733695  AndrewHemmingt2                          NaN   \n",
       "3             269708883         ferrier3                      paisley   \n",
       "4   1038400204305850368    fran_oneill_s               Leeds, England   \n",
       "..                  ...              ...                          ...   \n",
       "95           1822726884   MatthewGreen02                          NaN   \n",
       "96            124313779      Untidy_mind                           UK   \n",
       "97            431515838   mclaren_joanne                          NaN   \n",
       "98            104141401       angegarrod                          NaN   \n",
       "99            351664268        rastahill  Eastbourne, East Sussex, UK   \n",
       "\n",
       "                                            user_desc  \\\n",
       "0   British liberal, artist, check out my instagra...   \n",
       "1   http://Gov.UK/registertovote\\n#RemainAlliance\\...   \n",
       "2                                                 NaN   \n",
       "3                                   singer sometimes!   \n",
       "4   Feminist. Humanist. Cyclist. Likes kindness & ...   \n",
       "..                                                ...   \n",
       "95  Director, Green Planning Studio @greenplanning...   \n",
       "96                                                NaN   \n",
       "97                                                NaN   \n",
       "98  #BlockTheCoup  Arty farty. Artist, photographe...   \n",
       "99  Husband, father. X Deputy CX Reigate & Banstea...   \n",
       "\n",
       "                                           tweet_text             tweet_id  \\\n",
       "0   RT @jeremycorbyn: If some accuse me of talking...  1202956978286452738   \n",
       "1   RT @LaboursBlackPLP: This is massive, Former T...  1202956979284647938   \n",
       "2   RT @faisalislam: table in leaked Government pr...  1202956979838304260   \n",
       "3   RT @Conservatives: \"This is a Brexit election ...  1202956980949786627   \n",
       "4   @KLbils @BiztheBuz @NickBoles @jeremycorbyn Pl...  1202956981767720961   \n",
       "..                                                ...                  ...   \n",
       "95  RT @mrjamesob: Two former PMs to join Final Sa...  1202957080090599426   \n",
       "96  RT @Simon_Nixon: An astonishing moment. https:...  1202957080333828098   \n",
       "97  RT @AngusRobertson: Interesting to see that ne...  1202957080669425666   \n",
       "98  RT @MatthewGreen02: If, 4 years ago, someone s...  1202957082254860292   \n",
       "99  RT @bbclaurak: PM admitted there would be some...  1202957082619785216   \n",
       "\n",
       "             tweet_time  \n",
       "0   2019-12-06 14:24:28  \n",
       "1   2019-12-06 14:24:28  \n",
       "2   2019-12-06 14:24:28  \n",
       "3   2019-12-06 14:24:28  \n",
       "4   2019-12-06 14:24:28  \n",
       "..                  ...  \n",
       "95  2019-12-06 14:24:52  \n",
       "96  2019-12-06 14:24:52  \n",
       "97  2019-12-06 14:24:52  \n",
       "98  2019-12-06 14:24:52  \n",
       "99  2019-12-06 14:24:53  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (7) Extend this loop to fill in the cells for each new Tweet and append\n",
    "# the result to the \"df\" dataframe.\n",
    "empty_data = {col: [np.nan] for col in selected_cols}\n",
    "\n",
    "for ix in range(0, 100):\n",
    "    tweet = json.loads(json_data[ix])\n",
    "    new_row = pd.DataFrame(empty_data)\n",
    "    \n",
    "    if 'extended_tweet' in tweet: \n",
    "        new_row.loc[0, \"tweet_text\"] = tweet['extended_tweet']['full_text']\n",
    "    else: \n",
    "        new_row.loc[0, \"tweet_text\"] = tweet['text']\n",
    "    \n",
    "    new_row.loc[0, \"user_id\"] = tweet['user']['id_str']\n",
    "    new_row.loc[0, \"user_handle\"] = tweet['user']['screen_name']\n",
    "    new_row.loc[0, \"user_loc\"] = tweet['user']['location']\n",
    "    new_row.loc[0, \"user_desc\"] = tweet['user']['description']\n",
    "    new_row.loc[0, \"tweet_id\"] = tweet[\"id_str\"]\n",
    "\n",
    "\n",
    "    # For fun's sake, let's apply what we learned in exercise 2\n",
    "    tweet_time = tweet['created_at']\n",
    "    tweet_time = time.strptime(tweet_time,'%a %b %d %H:%M:%S +0000 %Y')\n",
    "    new_row.loc[0, \"tweet_time\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\", tweet_time)\n",
    "    \n",
    "    # Now, in order to save each newly extracted row, append it to the master \n",
    "    # DataFrame created in exercise 4. Use the ignore_index option to ensure\n",
    "    # a clean indexing of the master DataFrame df.\n",
    "    df = df.append(new_row, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8) After this loop, save \"df\" on your disk in the feather format.\n",
    "df.to_feather(\"DATA/processed_tweets.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 0 of 25000\n",
      "Processed: 1000 of 25000\n",
      "Processed: 2000 of 25000\n",
      "Processed: 3000 of 25000\n",
      "Processed: 4000 of 25000\n",
      "Processed: 5000 of 25000\n",
      "Processed: 6000 of 25000\n",
      "Processed: 7000 of 25000\n",
      "Processed: 8000 of 25000\n",
      "Processed: 9000 of 25000\n",
      "Processed: 10000 of 25000\n",
      "Processed: 11000 of 25000\n",
      "Processed: 12000 of 25000\n",
      "Processed: 13000 of 25000\n",
      "Processed: 14000 of 25000\n",
      "Processed: 15000 of 25000\n",
      "Processed: 16000 of 25000\n",
      "Processed: 17000 of 25000\n",
      "Processed: 18000 of 25000\n",
      "Processed: 19000 of 25000\n",
      "Processed: 20000 of 25000\n",
      "Processed: 21000 of 25000\n",
      "Processed: 22000 of 25000\n",
      "Processed: 23000 of 25000\n",
      "Processed: 24000 of 25000\n"
     ]
    }
   ],
   "source": [
    "# (9) Try to process all 25.000 Twitter objects with this loop. \n",
    "# Tipp: If you run into troubles, manually check out the Twitter object\n",
    "# that breaks the loop to ensure you're looking for the information at\n",
    "# the right place in the dictionary.\n",
    "\n",
    "# First let's load all the different packages that we need for this\n",
    "# process\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Then, recreate the master DataFrame that we want to store the\n",
    "# processed data in:\n",
    "selected_cols = [\"user_id\", \"user_handle\", \"user_loc\", \"user_desc\", \n",
    "                 \"tweet_text\", \"tweet_id\", \"tweet_time\"]\n",
    "df = pd.DataFrame([], columns=selected_cols)\n",
    "empty_data = {col: [np.nan] for col in selected_cols}\n",
    "\n",
    "# Let's open the JSON batch of 25.000 tweets\n",
    "json_data = open(\"DATA/2019-12-06_16-43-32.json\").read()\n",
    "json_data = json.loads(json_data)\n",
    "\n",
    "# Now, loop through the list of json-formatted Twitter objects,\n",
    "# extract the information we need, and add rows to the main \n",
    "# DataFrame for each Tweet.\n",
    "for ix in range(0, len(json_data)):\n",
    "    tweet = json.loads(json_data[ix])\n",
    "    new_row = pd.DataFrame(empty_data)\n",
    "    \n",
    "    # EXTRACTION\n",
    "    # Non problematic information\n",
    "    new_row.loc[0, \"user_id\"] = tweet['user']['id_str']\n",
    "    new_row.loc[0, \"user_handle\"] = tweet['user']['screen_name']\n",
    "    new_row.loc[0, \"user_loc\"] = tweet['user']['location']\n",
    "    new_row.loc[0, \"user_desc\"] = tweet['user']['description']\n",
    "    new_row.loc[0, \"tweet_id\"] = tweet[\"id_str\"]\n",
    "    \n",
    "    if 'extended_tweet' in tweet: \n",
    "        new_row.loc[0, \"tweet_text\"] = tweet['extended_tweet']['full_text']\n",
    "    else: \n",
    "        new_row.loc[0, \"tweet_text\"] = tweet['text']\n",
    "    \n",
    "    tweet_time = tweet['created_at']\n",
    "    tweet_time = time.strptime(tweet_time,'%a %b %d %H:%M:%S +0000 %Y')\n",
    "    new_row.loc[0, \"tweet_time\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\", tweet_time)\n",
    "    \n",
    "    df = df.append(new_row, ignore_index=True)\n",
    "    \n",
    "    # In order to check how quickly or slowly you computer is handling this\n",
    "    # let's just print something at every 100 Tweets processed:\n",
    "    if ix%1000 == 0: # If the remainder of dividing ix by 100 is equal to 0, do the following\n",
    "        print(\"Processed: \" + str(ix) + \" of \" + str(len(json_data)))\n",
    "        \n",
    "df.to_feather(\"DATA/processed_tweets.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10) Check out how to write functions in python, and write this process\n",
    "# into a function that takes the string Twitter object, converts it into\n",
    "# a dictionary, etc. and outputs the new_row pandas dataframe. You should\n",
    "# be able to run the following for-loop executing everything from the \n",
    "# previous exercises:\n",
    "# for tweet in range(0, len(json_data)):\n",
    "#     new_row = process_raw(tweet)\n",
    "#     df.append(new_row)\n",
    "\n",
    "# (11) Try to find a way to time how long your computer takes to calculate\n",
    "# each of these loops. Is the short version with the function quicker?\n",
    "# Can you think of ways to speed this up? Why is it taking so long?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>json_file</th>\n",
       "      <th>json_pos</th>\n",
       "      <th>processed_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>user_desc</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>...</th>\n",
       "      <th>qu_user_desc</th>\n",
       "      <th>qu_tweet_text</th>\n",
       "      <th>qu_tweet_id</th>\n",
       "      <th>qu_tweet_time</th>\n",
       "      <th>qu_tweet_geo</th>\n",
       "      <th>qu_tweet_country</th>\n",
       "      <th>qu_tweet_loc</th>\n",
       "      <th>qu_tweet_loc_type</th>\n",
       "      <th>qu_tweet_hashtags</th>\n",
       "      <th>qu_tweet_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1259863</td>\n",
       "      <td>2019-05-06_12-11-56</td>\n",
       "      <td>8979</td>\n",
       "      <td>2019-09-19 11:47:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>London</td>\n",
       "      <td>MP for Uxbridge and South Ruislip</td>\n",
       "      <td>None</td>\n",
       "      <td>1125328351974105088</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3794418</td>\n",
       "      <td>2019-09-05_21-10-31</td>\n",
       "      <td>1624</td>\n",
       "      <td>2019-09-19 14:07:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Prime Minister of the United Kingdom and @Cons...</td>\n",
       "      <td>Corbyn and his friends in Parliament don’t tru...</td>\n",
       "      <td>1169681044573962240</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3895193</td>\n",
       "      <td>2019-06-19_18-33-12</td>\n",
       "      <td>8378</td>\n",
       "      <td>2019-09-19 14:13:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>MP for Uxbridge and South Ruislip #BackBoris</td>\n",
       "      <td>None</td>\n",
       "      <td>1141362273941958666</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5512364</td>\n",
       "      <td>2019-08-19_09-25-10</td>\n",
       "      <td>17164</td>\n",
       "      <td>2019-09-19 15:44:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Prime Minister of the United Kingdom and @Cons...</td>\n",
       "      <td>None</td>\n",
       "      <td>1163346035718205440</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5908998</td>\n",
       "      <td>2019-06-15_17-58-59</td>\n",
       "      <td>24268</td>\n",
       "      <td>2019-09-19 16:06:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>MP for Uxbridge and South Ruislip #BackBoris</td>\n",
       "      <td>Fantastic to address our party faithful at the...</td>\n",
       "      <td>1139923957296111617</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>70388493</td>\n",
       "      <td>2019-08-27_19-22-41</td>\n",
       "      <td>9680</td>\n",
       "      <td>2019-09-23 00:43:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Prime Minister of the United Kingdom and @Cons...</td>\n",
       "      <td>Jeremy Corbyn wants to cancel the referendum a...</td>\n",
       "      <td>1166391520062300160</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>70751519</td>\n",
       "      <td>2019-08-29_13-36-31</td>\n",
       "      <td>7660</td>\n",
       "      <td>2019-09-23 01:13:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Prime Minister of the United Kingdom and @Cons...</td>\n",
       "      <td>None</td>\n",
       "      <td>1167030319775735811</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>71742418</td>\n",
       "      <td>2019-09-09_14-02-14</td>\n",
       "      <td>6016</td>\n",
       "      <td>2019-09-23 02:27:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Prime Minister of the United Kingdom and @Cons...</td>\n",
       "      <td>Let’s come together and get Brexit done on Oct...</td>\n",
       "      <td>1171024527410814976</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>72721638</td>\n",
       "      <td>2019-06-28_18-02-17</td>\n",
       "      <td>17833</td>\n",
       "      <td>2019-09-23 03:40:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>MP for Uxbridge and South Ruislip #BackBoris</td>\n",
       "      <td>Thank you @JSHeappey for the invitation to spe...</td>\n",
       "      <td>1144626979045629952</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>73532101</td>\n",
       "      <td>2019-06-27_10-58-03</td>\n",
       "      <td>17940</td>\n",
       "      <td>2019-09-23 04:41:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>MP for Uxbridge and South Ruislip #BackBoris</td>\n",
       "      <td>We must leave the EU on October 31st, with or ...</td>\n",
       "      <td>1144159500779302912</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID            json_file  json_pos         processed_at     user_id  \\\n",
       "0     1259863  2019-05-06_12-11-56      8979  2019-09-19 11:47:00  3131144855   \n",
       "1     3794418  2019-09-05_21-10-31      1624  2019-09-19 14:07:00  3131144855   \n",
       "2     3895193  2019-06-19_18-33-12      8378  2019-09-19 14:13:00  3131144855   \n",
       "3     5512364  2019-08-19_09-25-10     17164  2019-09-19 15:44:00  3131144855   \n",
       "4     5908998  2019-06-15_17-58-59     24268  2019-09-19 16:06:00  3131144855   \n",
       "..        ...                  ...       ...                  ...         ...   \n",
       "152  70388493  2019-08-27_19-22-41      9680  2019-09-23 00:43:00  3131144855   \n",
       "153  70751519  2019-08-29_13-36-31      7660  2019-09-23 01:13:00  3131144855   \n",
       "154  71742418  2019-09-09_14-02-14      6016  2019-09-23 02:27:00  3131144855   \n",
       "155  72721638  2019-06-28_18-02-17     17833  2019-09-23 03:40:00  3131144855   \n",
       "156  73532101  2019-06-27_10-58-03     17940  2019-09-23 04:41:00  3131144855   \n",
       "\n",
       "      user_handle        user_loc  \\\n",
       "0    BorisJohnson          London   \n",
       "1    BorisJohnson  United Kingdom   \n",
       "2    BorisJohnson  United Kingdom   \n",
       "3    BorisJohnson  United Kingdom   \n",
       "4    BorisJohnson  United Kingdom   \n",
       "..            ...             ...   \n",
       "152  BorisJohnson  United Kingdom   \n",
       "153  BorisJohnson  United Kingdom   \n",
       "154  BorisJohnson  United Kingdom   \n",
       "155  BorisJohnson  United Kingdom   \n",
       "156  BorisJohnson  United Kingdom   \n",
       "\n",
       "                                             user_desc  \\\n",
       "0                    MP for Uxbridge and South Ruislip   \n",
       "1    Prime Minister of the United Kingdom and @Cons...   \n",
       "2         MP for Uxbridge and South Ruislip #BackBoris   \n",
       "3    Prime Minister of the United Kingdom and @Cons...   \n",
       "4         MP for Uxbridge and South Ruislip #BackBoris   \n",
       "..                                                 ...   \n",
       "152  Prime Minister of the United Kingdom and @Cons...   \n",
       "153  Prime Minister of the United Kingdom and @Cons...   \n",
       "154  Prime Minister of the United Kingdom and @Cons...   \n",
       "155       MP for Uxbridge and South Ruislip #BackBoris   \n",
       "156       MP for Uxbridge and South Ruislip #BackBoris   \n",
       "\n",
       "                                            tweet_text             tweet_id  \\\n",
       "0                                                 None  1125328351974105088   \n",
       "1    Corbyn and his friends in Parliament don’t tru...  1169681044573962240   \n",
       "2                                                 None  1141362273941958666   \n",
       "3                                                 None  1163346035718205440   \n",
       "4    Fantastic to address our party faithful at the...  1139923957296111617   \n",
       "..                                                 ...                  ...   \n",
       "152  Jeremy Corbyn wants to cancel the referendum a...  1166391520062300160   \n",
       "153                                               None  1167030319775735811   \n",
       "154  Let’s come together and get Brexit done on Oct...  1171024527410814976   \n",
       "155  Thank you @JSHeappey for the invitation to spe...  1144626979045629952   \n",
       "156  We must leave the EU on October 31st, with or ...  1144159500779302912   \n",
       "\n",
       "     ... qu_user_desc  qu_tweet_text qu_tweet_id        qu_tweet_time  \\\n",
       "0    ...         None           None           0  1900-01-01 00:00:00   \n",
       "1    ...         None           None           0  1900-01-01 00:00:00   \n",
       "2    ...         None           None           0  1900-01-01 00:00:00   \n",
       "3    ...         None           None           0  1900-01-01 00:00:00   \n",
       "4    ...         None           None           0  1900-01-01 00:00:00   \n",
       "..   ...          ...            ...         ...                  ...   \n",
       "152  ...         None           None           0  1900-01-01 00:00:00   \n",
       "153  ...         None           None           0  1900-01-01 00:00:00   \n",
       "154  ...         None           None           0  1900-01-01 00:00:00   \n",
       "155  ...         None           None           0  1900-01-01 00:00:00   \n",
       "156  ...         None           None           0  1900-01-01 00:00:00   \n",
       "\n",
       "    qu_tweet_geo qu_tweet_country qu_tweet_loc qu_tweet_loc_type  \\\n",
       "0          False              NaN          NaN               NaN   \n",
       "1          False              NaN          NaN               NaN   \n",
       "2          False              NaN          NaN               NaN   \n",
       "3          False              NaN          NaN               NaN   \n",
       "4          False              NaN          NaN               NaN   \n",
       "..           ...              ...          ...               ...   \n",
       "152        False              NaN          NaN               NaN   \n",
       "153        False              NaN          NaN               NaN   \n",
       "154        False              NaN          NaN               NaN   \n",
       "155        False              NaN          NaN               NaN   \n",
       "156        False              NaN          NaN               NaN   \n",
       "\n",
       "    qu_tweet_hashtags  qu_tweet_mentions  \n",
       "0                None               None  \n",
       "1                None               None  \n",
       "2                None               None  \n",
       "3                None               None  \n",
       "4                None               None  \n",
       "..                ...                ...  \n",
       "152              None               None  \n",
       "153              None               None  \n",
       "154              None               None  \n",
       "155              None               None  \n",
       "156              None               None  \n",
       "\n",
       "[157 rows x 45 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Week 4: Natural Language Processing\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# For the purpose of the NLP sessions, we will be working with a \n",
    "# small set of Brexit Tweets from the users eucopresident, \n",
    "# BorisJohnson, and theresa_may. The data for this was extracted \n",
    "# using the process_tweet function you can find in the \n",
    "# 04_processing.py script I uploaded to Absalon. There you can\n",
    "# also find the CSV and feather versions of this dataset, which\n",
    "# was taken directly from DIPLOFACE's SQL server.\n",
    "\n",
    "# Let's load the usual packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# pandas has an inbuild function to read feather files, but \n",
    "# depending on you package version, this sometimes gives you \n",
    "# some error messages. If that happens, a quick fix is to use\n",
    "# the feather package directly\n",
    "import feather\n",
    "df = feather.read_dataframe(\"DATA/love-triangle.feather\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>json_file</th>\n",
       "      <th>json_pos</th>\n",
       "      <th>processed_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>user_desc</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>...</th>\n",
       "      <th>qu_user_desc</th>\n",
       "      <th>qu_tweet_text</th>\n",
       "      <th>qu_tweet_id</th>\n",
       "      <th>qu_tweet_time</th>\n",
       "      <th>qu_tweet_geo</th>\n",
       "      <th>qu_tweet_country</th>\n",
       "      <th>qu_tweet_loc</th>\n",
       "      <th>qu_tweet_loc_type</th>\n",
       "      <th>qu_tweet_hashtags</th>\n",
       "      <th>qu_tweet_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1259863</td>\n",
       "      <td>2019-05-06_12-11-56</td>\n",
       "      <td>8979</td>\n",
       "      <td>2019-09-19 11:47:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>London</td>\n",
       "      <td>MP for Uxbridge and South Ruislip</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1125328351974105088</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3794418</td>\n",
       "      <td>2019-09-05_21-10-31</td>\n",
       "      <td>1624</td>\n",
       "      <td>2019-09-19 14:07:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Prime Minister of the United Kingdom and @Cons...</td>\n",
       "      <td>Corbyn and his friends in Parliament don’t tru...</td>\n",
       "      <td>1169681044573962240</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3895193</td>\n",
       "      <td>2019-06-19_18-33-12</td>\n",
       "      <td>8378</td>\n",
       "      <td>2019-09-19 14:13:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>MP for Uxbridge and South Ruislip #BackBoris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1141362273941958666</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5512364</td>\n",
       "      <td>2019-08-19_09-25-10</td>\n",
       "      <td>17164</td>\n",
       "      <td>2019-09-19 15:44:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Prime Minister of the United Kingdom and @Cons...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1163346035718205440</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5908998</td>\n",
       "      <td>2019-06-15_17-58-59</td>\n",
       "      <td>24268</td>\n",
       "      <td>2019-09-19 16:06:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>MP for Uxbridge and South Ruislip #BackBoris</td>\n",
       "      <td>Fantastic to address our party faithful at the...</td>\n",
       "      <td>1139923957296111617</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>70388493</td>\n",
       "      <td>2019-08-27_19-22-41</td>\n",
       "      <td>9680</td>\n",
       "      <td>2019-09-23 00:43:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Prime Minister of the United Kingdom and @Cons...</td>\n",
       "      <td>Jeremy Corbyn wants to cancel the referendum a...</td>\n",
       "      <td>1166391520062300160</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>70751519</td>\n",
       "      <td>2019-08-29_13-36-31</td>\n",
       "      <td>7660</td>\n",
       "      <td>2019-09-23 01:13:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Prime Minister of the United Kingdom and @Cons...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1167030319775735811</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>71742418</td>\n",
       "      <td>2019-09-09_14-02-14</td>\n",
       "      <td>6016</td>\n",
       "      <td>2019-09-23 02:27:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Prime Minister of the United Kingdom and @Cons...</td>\n",
       "      <td>Let’s come together and get Brexit done on Oct...</td>\n",
       "      <td>1171024527410814976</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>72721638</td>\n",
       "      <td>2019-06-28_18-02-17</td>\n",
       "      <td>17833</td>\n",
       "      <td>2019-09-23 03:40:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>MP for Uxbridge and South Ruislip #BackBoris</td>\n",
       "      <td>Thank you @JSHeappey for the invitation to spe...</td>\n",
       "      <td>1144626979045629952</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>73532101</td>\n",
       "      <td>2019-06-27_10-58-03</td>\n",
       "      <td>17940</td>\n",
       "      <td>2019-09-23 04:41:00</td>\n",
       "      <td>3131144855</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>MP for Uxbridge and South Ruislip #BackBoris</td>\n",
       "      <td>We must leave the EU on October 31st, with or ...</td>\n",
       "      <td>1144159500779302912</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID            json_file  json_pos         processed_at     user_id  \\\n",
       "0     1259863  2019-05-06_12-11-56      8979  2019-09-19 11:47:00  3131144855   \n",
       "1     3794418  2019-09-05_21-10-31      1624  2019-09-19 14:07:00  3131144855   \n",
       "2     3895193  2019-06-19_18-33-12      8378  2019-09-19 14:13:00  3131144855   \n",
       "3     5512364  2019-08-19_09-25-10     17164  2019-09-19 15:44:00  3131144855   \n",
       "4     5908998  2019-06-15_17-58-59     24268  2019-09-19 16:06:00  3131144855   \n",
       "..        ...                  ...       ...                  ...         ...   \n",
       "152  70388493  2019-08-27_19-22-41      9680  2019-09-23 00:43:00  3131144855   \n",
       "153  70751519  2019-08-29_13-36-31      7660  2019-09-23 01:13:00  3131144855   \n",
       "154  71742418  2019-09-09_14-02-14      6016  2019-09-23 02:27:00  3131144855   \n",
       "155  72721638  2019-06-28_18-02-17     17833  2019-09-23 03:40:00  3131144855   \n",
       "156  73532101  2019-06-27_10-58-03     17940  2019-09-23 04:41:00  3131144855   \n",
       "\n",
       "      user_handle        user_loc  \\\n",
       "0    BorisJohnson          London   \n",
       "1    BorisJohnson  United Kingdom   \n",
       "2    BorisJohnson  United Kingdom   \n",
       "3    BorisJohnson  United Kingdom   \n",
       "4    BorisJohnson  United Kingdom   \n",
       "..            ...             ...   \n",
       "152  BorisJohnson  United Kingdom   \n",
       "153  BorisJohnson  United Kingdom   \n",
       "154  BorisJohnson  United Kingdom   \n",
       "155  BorisJohnson  United Kingdom   \n",
       "156  BorisJohnson  United Kingdom   \n",
       "\n",
       "                                             user_desc  \\\n",
       "0                    MP for Uxbridge and South Ruislip   \n",
       "1    Prime Minister of the United Kingdom and @Cons...   \n",
       "2         MP for Uxbridge and South Ruislip #BackBoris   \n",
       "3    Prime Minister of the United Kingdom and @Cons...   \n",
       "4         MP for Uxbridge and South Ruislip #BackBoris   \n",
       "..                                                 ...   \n",
       "152  Prime Minister of the United Kingdom and @Cons...   \n",
       "153  Prime Minister of the United Kingdom and @Cons...   \n",
       "154  Prime Minister of the United Kingdom and @Cons...   \n",
       "155       MP for Uxbridge and South Ruislip #BackBoris   \n",
       "156       MP for Uxbridge and South Ruislip #BackBoris   \n",
       "\n",
       "                                            tweet_text             tweet_id  \\\n",
       "0                                                  NaN  1125328351974105088   \n",
       "1    Corbyn and his friends in Parliament don’t tru...  1169681044573962240   \n",
       "2                                                  NaN  1141362273941958666   \n",
       "3                                                  NaN  1163346035718205440   \n",
       "4    Fantastic to address our party faithful at the...  1139923957296111617   \n",
       "..                                                 ...                  ...   \n",
       "152  Jeremy Corbyn wants to cancel the referendum a...  1166391520062300160   \n",
       "153                                                NaN  1167030319775735811   \n",
       "154  Let’s come together and get Brexit done on Oct...  1171024527410814976   \n",
       "155  Thank you @JSHeappey for the invitation to spe...  1144626979045629952   \n",
       "156  We must leave the EU on October 31st, with or ...  1144159500779302912   \n",
       "\n",
       "     ... qu_user_desc  qu_tweet_text qu_tweet_id        qu_tweet_time  \\\n",
       "0    ...          NaN            NaN           0  1900-01-01 00:00:00   \n",
       "1    ...          NaN            NaN           0  1900-01-01 00:00:00   \n",
       "2    ...          NaN            NaN           0  1900-01-01 00:00:00   \n",
       "3    ...          NaN            NaN           0  1900-01-01 00:00:00   \n",
       "4    ...          NaN            NaN           0  1900-01-01 00:00:00   \n",
       "..   ...          ...            ...         ...                  ...   \n",
       "152  ...          NaN            NaN           0  1900-01-01 00:00:00   \n",
       "153  ...          NaN            NaN           0  1900-01-01 00:00:00   \n",
       "154  ...          NaN            NaN           0  1900-01-01 00:00:00   \n",
       "155  ...          NaN            NaN           0  1900-01-01 00:00:00   \n",
       "156  ...          NaN            NaN           0  1900-01-01 00:00:00   \n",
       "\n",
       "    qu_tweet_geo qu_tweet_country qu_tweet_loc qu_tweet_loc_type  \\\n",
       "0          False              NaN          NaN               NaN   \n",
       "1          False              NaN          NaN               NaN   \n",
       "2          False              NaN          NaN               NaN   \n",
       "3          False              NaN          NaN               NaN   \n",
       "4          False              NaN          NaN               NaN   \n",
       "..           ...              ...          ...               ...   \n",
       "152        False              NaN          NaN               NaN   \n",
       "153        False              NaN          NaN               NaN   \n",
       "154        False              NaN          NaN               NaN   \n",
       "155        False              NaN          NaN               NaN   \n",
       "156        False              NaN          NaN               NaN   \n",
       "\n",
       "    qu_tweet_hashtags  qu_tweet_mentions  \n",
       "0                 NaN                NaN  \n",
       "1                 NaN                NaN  \n",
       "2                 NaN                NaN  \n",
       "3                 NaN                NaN  \n",
       "4                 NaN                NaN  \n",
       "..                ...                ...  \n",
       "152               NaN                NaN  \n",
       "153               NaN                NaN  \n",
       "154               NaN                NaN  \n",
       "155               NaN                NaN  \n",
       "156               NaN                NaN  \n",
       "\n",
       "[157 rows x 45 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that missing values are now specified with None instead of\n",
    "# np.nan – Both are fine to handle, but sometimes, you might prefer\n",
    "# one over the other as the standard for missing values. You can\n",
    "# easily change this with the following line\n",
    "df.fillna(value=np.nan, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_handle</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Corbyn and his friends in Parliament don’t tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Fantastic to address our party faithful at the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>theresa_may</td>\n",
       "      <td>You want this stage of the Brexit process to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>eucopresident</td>\n",
       "      <td>EU27 unanimously agrees on its response to UK’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>I’m deeply honoured to have secured more than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>I’m standing to be Leader of the Conservative ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Jeremy Corbyn wants to cancel the referendum a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Let’s come together and get Brexit done on Oct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Thank you @JSHeappey for the invitation to spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>We must leave the EU on October 31st, with or ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_handle                                         tweet_text\n",
       "0    BorisJohnson  Corbyn and his friends in Parliament don’t tru...\n",
       "1    BorisJohnson  Fantastic to address our party faithful at the...\n",
       "2     theresa_may  You want this stage of the Brexit process to b...\n",
       "3   eucopresident  EU27 unanimously agrees on its response to UK’...\n",
       "4    BorisJohnson  I’m deeply honoured to have secured more than ...\n",
       "..            ...                                                ...\n",
       "91   BorisJohnson  I’m standing to be Leader of the Conservative ...\n",
       "92   BorisJohnson  Jeremy Corbyn wants to cancel the referendum a...\n",
       "93   BorisJohnson  Let’s come together and get Brexit done on Oct...\n",
       "94   BorisJohnson  Thank you @JSHeappey for the invitation to spe...\n",
       "95   BorisJohnson  We must leave the EU on October 31st, with or ...\n",
       "\n",
       "[96 rows x 2 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2) Document-Term Matrices\n",
    "# Let's focus on the tweet_text variable for now, and filter\n",
    "# out all rows without a text. Let's also keep the user handle\n",
    "# so we can later on compare how these four politicians tweet\n",
    "# about the topic.\n",
    "df = df.loc[df['tweet_text'].notna(), ['user_handle', 'tweet_text']]\n",
    "\n",
    "# Make sure to reset the index to avoid confusion down the line...\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method CountVectorizer.fit_transform of CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to turn the column 'tweet_text' into a\n",
    "# document-term matrix, we can simply use the sklearn\n",
    "# package that should come pre-installed with your Anaconda\n",
    "# distribution. Either we use the Tfidf or Count Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Let's start with the simple CountVectorizer and create a \n",
    "# DTM using the inbuild tokenizer.\n",
    "\n",
    "# Notice, there is something slightly odd about the name of \n",
    "# this imported thing. Rather than count_vectorizer, it's \n",
    "# spelled CountVectorizer. You can take this as a hint that \n",
    "# you did notimport a specific function, but something slightly\n",
    "# different.\n",
    "# What we imported is a more general object called \"class\", \n",
    "# which is a template for creating new objects that contain\n",
    "# specific attributes and methods (see also the StreamListener \n",
    "# situation in the StreamingAPI script). With this template,\n",
    "# we create a vectorizer object, on which we can now call\n",
    "# certain methods.\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0kxjwwsprm</th>\n",
       "      <th>0w7ghgviel</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>16</th>\n",
       "      <th>200</th>\n",
       "      <th>2019</th>\n",
       "      <th>31st</th>\n",
       "      <th>3ke6f1fgx0</th>\n",
       "      <th>...</th>\n",
       "      <th>yet</th>\n",
       "      <th>ygrsfessfy</th>\n",
       "      <th>yorkshire</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yykczinjbv</th>\n",
       "      <th>yzobcftvjd</th>\n",
       "      <th>zgb6dfhbhd</th>\n",
       "      <th>zvudfp7mon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 790 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0kxjwwsprm  0w7ghgviel  10  100  150  16  200  2019  31st  3ke6f1fgx0  \\\n",
       "0            0           0   0    0    0   0    0     0     1           0   \n",
       "1            0           0   0    0    0   0    0     0     0           0   \n",
       "2            0           1   0    0    0   0    0     0     0           0   \n",
       "3            0           0   0    0    0   0    0     0     0           0   \n",
       "4            0           0   0    0    0   0    0     0     0           0   \n",
       "..         ...         ...  ..  ...  ...  ..  ...   ...   ...         ...   \n",
       "91           0           0   0    0    0   0    0     0     0           0   \n",
       "92           0           0   0    0    0   0    0     0     1           0   \n",
       "93           0           0   0    0    0   0    0     0     1           0   \n",
       "94           0           0   0    0    0   0    0     0     0           0   \n",
       "95           0           0   0    0    0   0    0     0     1           0   \n",
       "\n",
       "    ...  yet  ygrsfessfy  yorkshire  you  young  your  yykczinjbv  yzobcftvjd  \\\n",
       "0   ...    0           0          0    1      0     0           0           0   \n",
       "1   ...    0           0          0    0      0     0           0           0   \n",
       "2   ...    0           0          0    1      0     1           0           0   \n",
       "3   ...    0           0          0    0      0     0           0           0   \n",
       "4   ...    0           0          0    1      0     1           0           0   \n",
       "..  ...  ...         ...        ...  ...    ...   ...         ...         ...   \n",
       "91  ...    0           0          0    0      0     1           0           0   \n",
       "92  ...    0           0          0    0      0     0           0           0   \n",
       "93  ...    0           0          0    0      0     0           0           0   \n",
       "94  ...    0           0          0    1      0     1           0           0   \n",
       "95  ...    0           0          0    0      0     0           0           0   \n",
       "\n",
       "    zgb6dfhbhd  zvudfp7mon  \n",
       "0            0           0  \n",
       "1            0           0  \n",
       "2            0           0  \n",
       "3            0           0  \n",
       "4            0           0  \n",
       "..         ...         ...  \n",
       "91           0           0  \n",
       "92           0           0  \n",
       "93           0           0  \n",
       "94           0           0  \n",
       "95           0           0  \n",
       "\n",
       "[96 rows x 790 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit_transform returns the DTM in a sparse matrix format\n",
    "# from numpy that is extremely computationally efficient. \n",
    "sparse_dtm = vectorizer.fit_transform(df['tweet_text'])\n",
    "\n",
    "# But for the sake of illustration, let's turn this into\n",
    "# a nice pandas DataFrame, which works fine with such a\n",
    "# small amount of documents and tokens (or features).\n",
    "tokens = vectorizer.get_feature_names()\n",
    "dtm = pd.DataFrame(data=sparse_dtm.toarray(), \n",
    "                   index=df.index,\n",
    "                   columns=tokens)\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0kxjwwsprm',\n",
       " '0w7ghgviel',\n",
       " '10',\n",
       " '100',\n",
       " '150',\n",
       " '16',\n",
       " '200',\n",
       " '2019',\n",
       " '31st',\n",
       " '3ke6f1fgx0',\n",
       " '3pypnuvpyp',\n",
       " '3vrdupnwhs',\n",
       " '42y3hi5z8p',\n",
       " '4jinkgtzyc',\n",
       " '4lj0whityp',\n",
       " '50',\n",
       " '596iosh01u',\n",
       " '7jydiszdjb',\n",
       " '8000',\n",
       " '8gkvhwud55',\n",
       " '8vbg3jz6dk',\n",
       " '8vcdlajean',\n",
       " '9sdjciimxl',\n",
       " '9vi8oqqjgj',\n",
       " 'aada8qvd1x',\n",
       " 'about',\n",
       " 'accept',\n",
       " 'across',\n",
       " 'address',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'again',\n",
       " 'agenda',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'ahead',\n",
       " 'all',\n",
       " 'also',\n",
       " 'alternatives',\n",
       " 'although',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'amp',\n",
       " 'an',\n",
       " 'and',\n",
       " 'andrejplenkovic',\n",
       " 'another',\n",
       " 'anti',\n",
       " 'anyone',\n",
       " 'appeal',\n",
       " 'approach',\n",
       " 'april',\n",
       " 'are',\n",
       " 'argue',\n",
       " 'around',\n",
       " 'art',\n",
       " 'as',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'aspects',\n",
       " 'at',\n",
       " 'avoid',\n",
       " 'b02wiljds2',\n",
       " 'b3luadnfjw',\n",
       " 'back',\n",
       " 'backboris',\n",
       " 'backing',\n",
       " 'backstop',\n",
       " 'bad',\n",
       " 'ballot',\n",
       " 'basz4qx36s',\n",
       " 'bbi0kc6cdg',\n",
       " 'be',\n",
       " 'become',\n",
       " 'been',\n",
       " 'before',\n",
       " 'begin',\n",
       " 'begins',\n",
       " 'being',\n",
       " 'belfast',\n",
       " 'believe',\n",
       " 'believing',\n",
       " 'benches',\n",
       " 'bennqkfftd',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'bicester',\n",
       " 'big',\n",
       " 'bill',\n",
       " 'birmingham',\n",
       " 'bjugonyyq2',\n",
       " 'bmwsoqn12q',\n",
       " 'bold',\n",
       " 'borisjohnson',\n",
       " 'both',\n",
       " 'bournemouth',\n",
       " 'break',\n",
       " 'brexit',\n",
       " 'brighter',\n",
       " 'bring',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'brussels',\n",
       " 'bsyqxmtzuw',\n",
       " 'bucks',\n",
       " 'build',\n",
       " 'bum39qtizg',\n",
       " 'businesses',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'buts',\n",
       " 'by',\n",
       " 'cabinet',\n",
       " 'call',\n",
       " 'campaign',\n",
       " 'campaignforleo',\n",
       " 'campaigning',\n",
       " 'can',\n",
       " 'cancel',\n",
       " 'candidate',\n",
       " 'candidates',\n",
       " 'cannot',\n",
       " 'capitulation',\n",
       " 'cent',\n",
       " 'champion',\n",
       " 'chance',\n",
       " 'chancellor',\n",
       " 'change',\n",
       " 'check',\n",
       " 'choice',\n",
       " 'chvlb0ului',\n",
       " 'clear',\n",
       " 'close',\n",
       " 'co',\n",
       " 'coldfield',\n",
       " 'colleagues',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'commiserations',\n",
       " 'commit',\n",
       " 'commitment',\n",
       " 'committed',\n",
       " 'commons',\n",
       " 'concrete',\n",
       " 'condoning',\n",
       " 'confidence',\n",
       " 'confirm',\n",
       " 'congratulations',\n",
       " 'consensus',\n",
       " 'conservatism',\n",
       " 'conservative',\n",
       " 'conservatives',\n",
       " 'constant',\n",
       " 'consult',\n",
       " 'consultations',\n",
       " 'consulting',\n",
       " 'contest',\n",
       " 'continue',\n",
       " 'contribution',\n",
       " 'control',\n",
       " 'convention',\n",
       " 'corbyn',\n",
       " 'corbyns',\n",
       " 'could',\n",
       " 'council',\n",
       " 'councillors',\n",
       " 'country',\n",
       " 'counts',\n",
       " 'create',\n",
       " 'creators',\n",
       " 'crime',\n",
       " 'dablu8iqmq',\n",
       " 'date',\n",
       " 'day',\n",
       " 'dctjdo8orp',\n",
       " 'deal',\n",
       " 'decided',\n",
       " 'decision',\n",
       " 'deepening',\n",
       " 'deeply',\n",
       " 'defeat',\n",
       " 'defects',\n",
       " 'delay',\n",
       " 'delayed',\n",
       " 'delays',\n",
       " 'deliver',\n",
       " 'delivered',\n",
       " 'delivering',\n",
       " 'democracy',\n",
       " 'deserve',\n",
       " 'despair',\n",
       " 'determine',\n",
       " 'developments',\n",
       " 'did',\n",
       " 'diet',\n",
       " 'difficult',\n",
       " 'dignified',\n",
       " 'disappointing',\n",
       " 'discover',\n",
       " 'discuss',\n",
       " 'discussing',\n",
       " 'divided',\n",
       " 'do',\n",
       " 'document',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'done',\n",
       " 'down',\n",
       " 'downing',\n",
       " 'dreamers',\n",
       " 'dreaming',\n",
       " 'dreams',\n",
       " 'dublin',\n",
       " 'during',\n",
       " 'dxugrhr6ia',\n",
       " 'e2inihqjtq',\n",
       " 'either',\n",
       " 'elected',\n",
       " 'election',\n",
       " 'elections',\n",
       " 'else',\n",
       " 'emmanuelmacron',\n",
       " 'end',\n",
       " 'energise',\n",
       " 'enhanced',\n",
       " 'entrust',\n",
       " 'eu',\n",
       " 'eu27',\n",
       " 'euco',\n",
       " 'eucopresident',\n",
       " 'europe',\n",
       " 'european',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'events',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'exactly',\n",
       " 'excellent',\n",
       " 'exeter',\n",
       " 'explain',\n",
       " 'extension',\n",
       " 'extraordinary',\n",
       " 'face',\n",
       " 'facts',\n",
       " 'faith',\n",
       " 'faithful',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'fatalism',\n",
       " 'fatigue',\n",
       " 'fgtmhp33vx',\n",
       " 'fgxgdkh0yz',\n",
       " 'fi1meregmz',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'finding',\n",
       " 'finds',\n",
       " 'first',\n",
       " 'fitzmp',\n",
       " 'fixing',\n",
       " 'flat',\n",
       " 'focus',\n",
       " 'focused',\n",
       " 'folks',\n",
       " 'follow',\n",
       " 'following',\n",
       " 'for',\n",
       " 'forced',\n",
       " 'forward',\n",
       " 'fos9ag42ht',\n",
       " 'frail',\n",
       " 'friday',\n",
       " 'friends',\n",
       " 'friendship',\n",
       " 'from',\n",
       " 'full',\n",
       " 'fund',\n",
       " 'further',\n",
       " 'future',\n",
       " 'gavinwilliamson',\n",
       " 'georgefreeman',\n",
       " 'georgefreemanmp',\n",
       " 'get',\n",
       " 'getting',\n",
       " 'gitanasnauseda',\n",
       " 'giuseppeconteit',\n",
       " 'give',\n",
       " 'given',\n",
       " 'giving',\n",
       " 'gjgkvfk8ft',\n",
       " 'global',\n",
       " 'glorious',\n",
       " 'go',\n",
       " 'going',\n",
       " 'good',\n",
       " 'government',\n",
       " 'great',\n",
       " 'greater',\n",
       " 'grybauskaite_lt',\n",
       " 'gt',\n",
       " 'had',\n",
       " 'handed',\n",
       " 'handling',\n",
       " 'happen',\n",
       " 'happening',\n",
       " 'has',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'he',\n",
       " 'head',\n",
       " 'health',\n",
       " 'help',\n",
       " 'her',\n",
       " 'here',\n",
       " 'high',\n",
       " 'his',\n",
       " 'hlyrizpc3i',\n",
       " 'homes',\n",
       " 'honour',\n",
       " 'honoured',\n",
       " 'honours',\n",
       " 'hope',\n",
       " 'hosting',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'housing',\n",
       " 'how',\n",
       " 'https',\n",
       " 'humiliation',\n",
       " 'hundreds',\n",
       " 'hustings',\n",
       " 'i5d4byuram',\n",
       " 'iainastewart',\n",
       " 'if',\n",
       " 'ifs',\n",
       " 'illusory',\n",
       " 'impasse',\n",
       " 'importance',\n",
       " 'important',\n",
       " 'improve',\n",
       " 'improved',\n",
       " 'in',\n",
       " 'increasingly',\n",
       " 'incredible',\n",
       " 'innovation',\n",
       " 'intensifying',\n",
       " 'interest',\n",
       " 'interests',\n",
       " 'into',\n",
       " 'investing',\n",
       " 'invitation',\n",
       " 'involved',\n",
       " 'irz8b0flrk',\n",
       " 'is',\n",
       " 'isle',\n",
       " 'isnpukg1e4',\n",
       " 'issues',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itvdebate',\n",
       " 'jacvrzq5n6',\n",
       " 'jazud0xtgv',\n",
       " 'jeremy',\n",
       " 'jeremy_hunt',\n",
       " 'jj30xepetk',\n",
       " 'job',\n",
       " 'join',\n",
       " 'jsheappey',\n",
       " 'just',\n",
       " 'justified',\n",
       " 'keep',\n",
       " 'key',\n",
       " 'kmec3wvxtj',\n",
       " 'know',\n",
       " 'krisjaniskarins',\n",
       " 'kxoprhodzh',\n",
       " 'l1oqppjbxr',\n",
       " 'labour',\n",
       " 'lasee8iimt',\n",
       " 'last',\n",
       " 'latest',\n",
       " 'launch',\n",
       " 'law',\n",
       " 'laws',\n",
       " 'leader',\n",
       " 'leaders',\n",
       " 'leadership',\n",
       " 'leading',\n",
       " 'least',\n",
       " 'leave',\n",
       " 'leaveoct31',\n",
       " 'leaving',\n",
       " 'less',\n",
       " 'let',\n",
       " 'letsgetthisdone',\n",
       " 'letter',\n",
       " 'likely',\n",
       " 'line',\n",
       " 'lithuania',\n",
       " 'live',\n",
       " 'lives',\n",
       " 'ljs7f2wjug',\n",
       " 'll',\n",
       " 'local',\n",
       " 'london',\n",
       " 'long',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'losing',\n",
       " 'losses',\n",
       " 'lost',\n",
       " 'maidstone',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'manchester',\n",
       " 'many',\n",
       " 'market',\n",
       " 'matter',\n",
       " 'may',\n",
       " 'me',\n",
       " 'means',\n",
       " 'measures',\n",
       " 'meet',\n",
       " 'meeting',\n",
       " 'meetings',\n",
       " 'mega',\n",
       " 'members',\n",
       " 'meps',\n",
       " 'merkel',\n",
       " 'message',\n",
       " 'met',\n",
       " 'midlands',\n",
       " 'miles',\n",
       " 'minds',\n",
       " 'minister',\n",
       " 'minpres',\n",
       " 'missed',\n",
       " 'mkconservatives',\n",
       " 'modern',\n",
       " 'moment',\n",
       " 'more',\n",
       " 'morning',\n",
       " 'move',\n",
       " 'mps',\n",
       " 'much',\n",
       " 'must',\n",
       " 'mv4wre9ao4',\n",
       " 'my',\n",
       " 'n9fqetq25s',\n",
       " 'narrative',\n",
       " 'nation',\n",
       " 'national',\n",
       " 'nations',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'negotiations',\n",
       " 'new',\n",
       " 'news',\n",
       " 'next',\n",
       " 'night',\n",
       " 'nkzii7dx1r',\n",
       " 'no',\n",
       " 'no10',\n",
       " 'not',\n",
       " 'nottinghamshire',\n",
       " 'now',\n",
       " 'oct',\n",
       " 'october',\n",
       " 'of',\n",
       " 'offer',\n",
       " 'olcgggs6x5',\n",
       " 'on',\n",
       " 'one',\n",
       " 'only',\n",
       " 'open',\n",
       " 'opportunities',\n",
       " 'opportunity',\n",
       " 'optimism',\n",
       " 'oqsbd5dvwo',\n",
       " 'or',\n",
       " 'our',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outlined',\n",
       " 'over',\n",
       " 'overwhelmed',\n",
       " 'owerka4ade',\n",
       " 'own',\n",
       " 'package',\n",
       " 'painful',\n",
       " 'paper',\n",
       " 'paris',\n",
       " 'parliament',\n",
       " 'partnership',\n",
       " 'party',\n",
       " 'patient',\n",
       " 'paulbristow79',\n",
       " 'people',\n",
       " 'per',\n",
       " 'peterborough',\n",
       " 'phase',\n",
       " 'phone',\n",
       " 'piikkg4hys',\n",
       " 'plan',\n",
       " 'plans',\n",
       " 'please',\n",
       " 'pledged',\n",
       " 'pm',\n",
       " 'pmcpzlb0wy',\n",
       " 'point',\n",
       " 'policy',\n",
       " 'political',\n",
       " 'politicians',\n",
       " 'politics',\n",
       " 'polls',\n",
       " 'portsmouth',\n",
       " 'positive',\n",
       " 'positivity',\n",
       " 'possible',\n",
       " 'post',\n",
       " 'power',\n",
       " 'powers',\n",
       " 'pragmatic',\n",
       " 'pragmatically',\n",
       " 'prepare',\n",
       " 'preparedness',\n",
       " 'president',\n",
       " 'prime',\n",
       " 'problems',\n",
       " 'process',\n",
       " 'promises',\n",
       " 'proper',\n",
       " 'proposals',\n",
       " 'protect',\n",
       " 'proud',\n",
       " 'public',\n",
       " 'punish',\n",
       " 'put',\n",
       " 'pzbzbd4haj',\n",
       " 'q8tiwdmkch',\n",
       " 'qqooioatoz',\n",
       " 'qri41evzp7',\n",
       " 'qv7blaohw7',\n",
       " 'qxkbc1tbty',\n",
       " 'r184tcluef',\n",
       " 're',\n",
       " 'ready',\n",
       " 'real',\n",
       " 'realistic',\n",
       " 'really',\n",
       " 'receive',\n",
       " 'received',\n",
       " 'receiving',\n",
       " 'reception',\n",
       " 'record',\n",
       " 'referendum',\n",
       " 'region',\n",
       " 'regional',\n",
       " 'rejection',\n",
       " 'remarks',\n",
       " 'remedy',\n",
       " 'repay',\n",
       " 'report',\n",
       " 'represent',\n",
       " 'requesting',\n",
       " 'requests',\n",
       " 'residents',\n",
       " 'resist',\n",
       " 'response',\n",
       " 'restore',\n",
       " 'result',\n",
       " 'results',\n",
       " 'rethink',\n",
       " 'reversed',\n",
       " 'right',\n",
       " 'rights',\n",
       " 'risk',\n",
       " 'rlcppvdmw8',\n",
       " 'role',\n",
       " 'room',\n",
       " 'run',\n",
       " 'running',\n",
       " 'rutte',\n",
       " 'rzt8r1o01i',\n",
       " 'salford',\n",
       " 'same',\n",
       " 'sarecmarjan',\n",
       " 'say',\n",
       " 'sbgyhrhkrk',\n",
       " 'sc6wjdpdkw',\n",
       " 'schools',\n",
       " 'science',\n",
       " 'scqnokprdb',\n",
       " 'sczyb18xcf',\n",
       " 'seats',\n",
       " 'second',\n",
       " 'secured',\n",
       " 'seeking',\n",
       " 'seem',\n",
       " 'seems',\n",
       " 'semitism',\n",
       " 'sensible',\n",
       " 'sensibly',\n",
       " 'service',\n",
       " 'services',\n",
       " 'session',\n",
       " 'set',\n",
       " 'setting',\n",
       " 'shaping',\n",
       " 'shortly',\n",
       " 'shows',\n",
       " 'shropshire',\n",
       " 'sick',\n",
       " 'side',\n",
       " 'sides',\n",
       " 'sign',\n",
       " 'signing',\n",
       " 'simple',\n",
       " 'sincerely',\n",
       " 'situation',\n",
       " 'so',\n",
       " 'society',\n",
       " 'solution',\n",
       " 'some',\n",
       " 'somerset',\n",
       " 'soon',\n",
       " 'speak',\n",
       " 'speaking',\n",
       " 'special',\n",
       " 'spend',\n",
       " 'spending',\n",
       " 'spring',\n",
       " 'stage',\n",
       " 'standing',\n",
       " 'start',\n",
       " 'statement',\n",
       " 'step',\n",
       " 'sticks',\n",
       " 'still',\n",
       " 'stoical',\n",
       " 'stop',\n",
       " 'strategy',\n",
       " 'street',\n",
       " 'strive',\n",
       " 'strong',\n",
       " 'succeed',\n",
       " 'success',\n",
       " 'such',\n",
       " 'suffered',\n",
       " 'suggestion',\n",
       " 'summit',\n",
       " 'support',\n",
       " 'surrenderbill',\n",
       " 'sutton',\n",
       " 'tackling',\n",
       " 'take',\n",
       " 'talk',\n",
       " 'talking',\n",
       " 'talkradio',\n",
       " 'taoiseach',\n",
       " 'taxing',\n",
       " 'taxpayer',\n",
       " 'team',\n",
       " 'ten',\n",
       " 'tendencies',\n",
       " 'tfgkx4slib',\n",
       " 'tgrxu94cmt',\n",
       " 'than',\n",
       " 'thank',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'therefore',\n",
       " 'theresa_may',\n",
       " 'these',\n",
       " 'thesun',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'throughout',\n",
       " 'time',\n",
       " 'times',\n",
       " 'to',\n",
       " 'today',\n",
       " 'together',\n",
       " 'tomorrow',\n",
       " 'tonight',\n",
       " 'too',\n",
       " 'took',\n",
       " 'tories',\n",
       " 'touring',\n",
       " 'track',\n",
       " 'trade',\n",
       " 'tradition',\n",
       " 'trap',\n",
       " 'trust',\n",
       " 'uk',\n",
       " 'unanimously',\n",
       " 'uncertain',\n",
       " 'uncertainty',\n",
       " 'union',\n",
       " 'unions',\n",
       " 'unite',\n",
       " 'united',\n",
       " 'unity',\n",
       " 'until',\n",
       " 'up',\n",
       " 'urgings',\n",
       " 'us',\n",
       " 'use',\n",
       " 'value',\n",
       " 've',\n",
       " 'version',\n",
       " 'very',\n",
       " 'video',\n",
       " 'view',\n",
       " 'visible',\n",
       " 'vision',\n",
       " 'visit',\n",
       " 'vital',\n",
       " 'vote',\n",
       " 'voted',\n",
       " 'voters',\n",
       " 'votes',\n",
       " 'vqh3jx8y2x',\n",
       " 'waiting',\n",
       " 'want',\n",
       " 'wants',\n",
       " 'warned',\n",
       " 'was',\n",
       " 'way',\n",
       " 'we',\n",
       " 'wealth',\n",
       " 'wednesday',\n",
       " 'week',\n",
       " 'weekend',\n",
       " 'well',\n",
       " 'wells',\n",
       " 'west',\n",
       " 'westminster',\n",
       " 'what',\n",
       " 'when',\n",
       " 'whether',\n",
       " 'who',\n",
       " 'whole',\n",
       " 'why',\n",
       " 'wight',\n",
       " 'will',\n",
       " 'willingness',\n",
       " 'win',\n",
       " 'with',\n",
       " 'withdrawal',\n",
       " 'without',\n",
       " 'wmxg40xrkl',\n",
       " 'work',\n",
       " 'workers',\n",
       " 'working',\n",
       " 'works',\n",
       " 'worse',\n",
       " 'written',\n",
       " 'wtvqqryyvq',\n",
       " 'x9hfkop0qu',\n",
       " 'years',\n",
       " 'yesterday',\n",
       " 'yet',\n",
       " 'ygrsfessfy',\n",
       " 'yorkshire',\n",
       " 'you',\n",
       " 'young',\n",
       " 'your',\n",
       " 'yykczinjbv',\n",
       " 'yzobcftvjd',\n",
       " 'zgb6dfhbhd',\n",
       " 'zvudfp7mon']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So, this DTM has 96 rows (documents, in this case Tweets),\n",
    "# and 790 columns (features/tokens/variables). The CountVectorizer\n",
    "# looks at all the unique tokens it can find across all the\n",
    "# documents. It automatically uses a very simple tokenizer\n",
    "# for this. Check out the documentation to see whether you\n",
    "# can find out how its tokenizer splits texts into individual\n",
    "# tokens. Let's look at the outcome, and see whether we can\n",
    "# improve on this crude first take:\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3) Pre-Processing: Tokenizing, Removing-Stuff, Stemming\n",
    "# As we can see, there is a bunch of weird stuff in there, and\n",
    "# some tokens should be counted as one, which we can achieve\n",
    "# by pre-processing techniques like stemming (getting rid of\n",
    "# suffixes etc.). \n",
    "\n",
    "# There are many different packages to do this, and I hope\n",
    "# that Jurafsky and Martin convinced you that there are \n",
    "# different computational approaches to pre-processing, most\n",
    "# of which will give you different results. For this session,\n",
    "# we will stick to a collection of tools provided by the \n",
    "# NLTK (Natural Language Tool Kit) package. This is kind of\n",
    "# a hub of different techniques that comes in handy. Besides\n",
    "# installing nltk via pip (google \"install nltk package Windows/Mac\"),\n",
    "# you will als need to download individual packages. There\n",
    "# are two ways to do so. Either you try to run the code, and\n",
    "# let NLTK tell you which things you need to download to\n",
    "# run a specific functionality (the error messages will\n",
    "# provide precise instructions), or you just install all\n",
    "# of their functionalities at once via the command line \n",
    "# interface. I prefer the latter, but be aware that this\n",
    "# requires up to 4GB storage space on your computer. \n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Corbyn and his friends in Parliament don’t trust you to make this decision - but I do. Let’s put it to the people: more delay with Corbyn’s #SurrenderBill, or Brexit delivered on October 31st ???? https://t.co/q8tIwDMkcH'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do all the pre-processing on a single tweet first,\n",
    "# so we can have a look at the individual changes as they\n",
    "# happen to the text.\n",
    "tweet = df.loc[0, 'tweet_text']\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Corbyn',\n",
       " 'and',\n",
       " 'his',\n",
       " 'friends',\n",
       " 'in',\n",
       " 'Parliament',\n",
       " 'don’t',\n",
       " 'trust',\n",
       " 'you',\n",
       " 'to',\n",
       " 'make',\n",
       " 'this',\n",
       " 'decision',\n",
       " '-',\n",
       " 'but',\n",
       " 'I',\n",
       " 'do.',\n",
       " 'Let’s',\n",
       " 'put',\n",
       " 'it',\n",
       " 'to',\n",
       " 'the',\n",
       " 'people:',\n",
       " 'more',\n",
       " 'delay',\n",
       " 'with',\n",
       " 'Corbyn’s',\n",
       " '#SurrenderBill,',\n",
       " 'or',\n",
       " 'Brexit',\n",
       " 'delivered',\n",
       " 'on',\n",
       " 'October',\n",
       " '31st',\n",
       " '????',\n",
       " 'https://t.co/q8tIwDMkcH']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [3a] Tokenizing\n",
    "# The most simple way to tokenize a given text is to use the \n",
    "# python-internal string function split(), which we can\n",
    "# call on a given string object. It simply splits the string\n",
    "# into individual tokens at every whitespace it encounters.\n",
    "tokens = tweet.split()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Corbyn',\n",
       " 'and',\n",
       " 'his',\n",
       " 'friends',\n",
       " 'in',\n",
       " 'Parliament',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'trust',\n",
       " 'you',\n",
       " 'to',\n",
       " 'make',\n",
       " 'this',\n",
       " 'decision',\n",
       " '-',\n",
       " 'but',\n",
       " 'I',\n",
       " 'do',\n",
       " '.',\n",
       " 'Let',\n",
       " '’',\n",
       " 's',\n",
       " 'put',\n",
       " 'it',\n",
       " 'to',\n",
       " 'the',\n",
       " 'people',\n",
       " ':',\n",
       " 'more',\n",
       " 'delay',\n",
       " 'with',\n",
       " 'Corbyn',\n",
       " '’',\n",
       " 's',\n",
       " '#',\n",
       " 'SurrenderBill',\n",
       " ',',\n",
       " 'or',\n",
       " 'Brexit',\n",
       " 'delivered',\n",
       " 'on',\n",
       " 'October',\n",
       " '31st',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " 'https',\n",
       " ':',\n",
       " '//t.co/q8tIwDMkcH']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is a bunch of problems with this, which have\n",
    "# to do with the punctuation that is directly linked\n",
    "# to a word and not separated by whitespace. Plenty\n",
    "# of people have worked to solve such issues, and the\n",
    "# easy-to-use alternative that you see the most is\n",
    "# the word_tokenize function from NLTK. Let's import it:\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(tweet)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Corbyn',\n",
       " 'and',\n",
       " 'his',\n",
       " 'friends',\n",
       " 'in',\n",
       " 'Parliament',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'trust',\n",
       " 'you',\n",
       " 'to',\n",
       " 'make',\n",
       " 'this',\n",
       " 'decision',\n",
       " '-',\n",
       " 'but',\n",
       " 'I',\n",
       " 'do',\n",
       " '.',\n",
       " 'Let',\n",
       " '’',\n",
       " 's',\n",
       " 'put',\n",
       " 'it',\n",
       " 'to',\n",
       " 'the',\n",
       " 'people',\n",
       " ':',\n",
       " 'more',\n",
       " 'delay',\n",
       " 'with',\n",
       " 'Corbyn',\n",
       " '’',\n",
       " 's',\n",
       " '#SurrenderBill',\n",
       " ',',\n",
       " 'or',\n",
       " 'Brexit',\n",
       " 'delivered',\n",
       " 'on',\n",
       " 'October',\n",
       " '31st',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " 'https://t.co/q8tIwDMkcH']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This looks slightly better in that it recognized more\n",
    "# common English language style separation of two words\n",
    "# like in \"don't\" = \"do not\" – However, it also has a \n",
    "# weird understanding of URLs and separated the hashtag\n",
    "# from the word in #SurrenderBill. We might want to \n",
    "# keep this as the hashtag is part of the tokens underlying\n",
    "# meaning in Twitter communication.\n",
    "\n",
    "# In order to find out whether there is a tokenizer \n",
    "# more appropriate for our context, we can have a look\n",
    "# at the documentation of the nltk tokenize section\n",
    "# https://www.nltk.org/api/nltk.tokenize.html \n",
    "\n",
    "# And voilà, there is a tokenizer specifically \n",
    "# developped for parsing tweets. Again, we can import the\n",
    "# general class, create an instance of this class, and\n",
    "# then call certain methods from this instance.\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "tokens = tokenizer.tokenize(tweet)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corbyn',\n",
       " 'and',\n",
       " 'his',\n",
       " 'friends',\n",
       " 'in',\n",
       " 'parliament',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'trust',\n",
       " 'you',\n",
       " 'to',\n",
       " 'make',\n",
       " 'this',\n",
       " 'decision',\n",
       " '-',\n",
       " 'but',\n",
       " 'i',\n",
       " 'do',\n",
       " '.',\n",
       " 'let',\n",
       " '’',\n",
       " 's',\n",
       " 'put',\n",
       " 'it',\n",
       " 'to',\n",
       " 'the',\n",
       " 'people',\n",
       " ':',\n",
       " 'more',\n",
       " 'delay',\n",
       " 'with',\n",
       " 'corbyn',\n",
       " '’',\n",
       " 's',\n",
       " '#surrenderbill',\n",
       " ',',\n",
       " 'or',\n",
       " 'brexit',\n",
       " 'delivered',\n",
       " 'on',\n",
       " 'october',\n",
       " '31st',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " 'https://t.co/q8tiwdmkch']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [3b] Lowercasing\n",
    "# Now that we have individual tokens, we can easilyapply more \n",
    "# pre-processing techniques to each token with list-comprehension.\n",
    "# Turning every character to lowercasing is super easy in python,\n",
    "# and uncontroversial for once.\n",
    "tokens = [word.lower() for word in tokens]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [3c] Punctuation Removal\n",
    "# There are a bunch of approaches to this, but let's\n",
    "# use the string package, which has a lot of other\n",
    "# cool features\n",
    "import string\n",
    "\n",
    "# It contains a list of the most common punctuation \n",
    "# characters\n",
    "punct = string.punctuation\n",
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem is that this list contains the # symbol,\n",
    "# which we do want to keep, so let's replace this\n",
    "punct = punct.replace(\"#\", \"\")\n",
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corbyn',\n",
       " 'and',\n",
       " 'his',\n",
       " 'friends',\n",
       " 'in',\n",
       " 'parliament',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'trust',\n",
       " 'you',\n",
       " 'to',\n",
       " 'make',\n",
       " 'this',\n",
       " 'decision',\n",
       " 'but',\n",
       " 'i',\n",
       " 'do',\n",
       " 'let',\n",
       " '’',\n",
       " 's',\n",
       " 'put',\n",
       " 'it',\n",
       " 'to',\n",
       " 'the',\n",
       " 'people',\n",
       " 'more',\n",
       " 'delay',\n",
       " 'with',\n",
       " 'corbyn',\n",
       " '’',\n",
       " 's',\n",
       " '#surrenderbill',\n",
       " 'or',\n",
       " 'brexit',\n",
       " 'delivered',\n",
       " 'on',\n",
       " 'october',\n",
       " '31st',\n",
       " 'https://t.co/q8tiwdmkch']"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we can use list comprehension to drop all\n",
    "# the punctuation tokens in our list of tokens\n",
    "tokens = [word for word in tokens if word not in punct]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~’'"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we see, this didn't remove the ’ – let's just add it to punct,\n",
    "# and repeat the process\n",
    "punct = punct + \"’\"\n",
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corbyn',\n",
       " 'and',\n",
       " 'his',\n",
       " 'friends',\n",
       " 'in',\n",
       " 'parliament',\n",
       " 'don',\n",
       " 't',\n",
       " 'trust',\n",
       " 'you',\n",
       " 'to',\n",
       " 'make',\n",
       " 'this',\n",
       " 'decision',\n",
       " 'but',\n",
       " 'i',\n",
       " 'do',\n",
       " 'let',\n",
       " 's',\n",
       " 'put',\n",
       " 'it',\n",
       " 'to',\n",
       " 'the',\n",
       " 'people',\n",
       " 'more',\n",
       " 'delay',\n",
       " 'with',\n",
       " 'corbyn',\n",
       " 's',\n",
       " '#surrenderbill',\n",
       " 'or',\n",
       " 'brexit',\n",
       " 'delivered',\n",
       " 'on',\n",
       " 'october',\n",
       " '31st',\n",
       " 'https://t.co/q8tiwdmkch']"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we are left with only alphanumerical characters\n",
    "# and we managed to not throw away the hashtag sign.\n",
    "# in the process.\n",
    "tokens = [word for word in tokens if word not in punct]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################################################################\n",
    "# 3d Number Removal\n",
    "# If\n",
    "\"1942\".isdigit()\n",
    "# any(char.isdigit() for char in inputString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3e Stopword Removal\n",
    "# We can use NLTK's standard stoplist for English\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in words if not w in stop_words]\n",
    "\n",
    "# 3f Stemming\n",
    "# Let's use some different stemmers now. \n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "from nltk import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "words = [porter.stem(w) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's write a loop that applies all of this to \n",
    "# each tweet in the dataframe and creates a new 'processed'\n",
    "# variable. that we can turn into a DTM now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) Pairwise cosine Similarity scores:\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(sparse_dtm[0,], sparse_dtm[1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Exercise 04\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# (1) Unit of analysis challenge: Single tweets lead to zero-inflated\n",
    "# DTMs, use the join() function to collapse all tweets from each user\n",
    "# into a single string object. You should end with a list of three\n",
    "# large strings.\n",
    "\n",
    "# (2) Process them above using the word_tokenizer, lowercasing,\n",
    "# punctuation removal, number removal, stopword removal, and\n",
    "# stemming with the PorterStemmer.\n",
    "\n",
    "# (3) Turn this into a DTM for these three documents (3 rows)\n",
    "\n",
    "# (4) Our prior believe is that BorisJohnson is more similar to \n",
    "# theresa_may than to eucopresident in terms of their Brexit tweets.\n",
    "# Do the pairwise cosine similarity scores confirm that prior believe?\n",
    "\n",
    "# (5) Now repeat exercises 2 to 5, but use the Twitter tokenizer \n",
    "# instead. Is there a significant difference in the outcome? Which\n",
    "# tokenizer should I use if I want to analyze these tweets?\n",
    "\n",
    "# (6) What happens to these cosine similarity scores if I use the \n",
    "# Tfidf Vectorizer instead of the CountVectorizer from sklearn?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
