{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# author: patricewangen\n",
    "# created: 21 February 2020\n",
    "# last_edited: 25 February 2020\n",
    "##########################################################################\n",
    "\n",
    "# TODO\n",
    "# (1) Homework Solutions\n",
    "# (2) Document-Term Matrices\n",
    "# (3) Pre-Processing: Tokenizing, Removing-Stuff, Stemming\n",
    "# (4) Pairwise Cosine Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Exercise 03\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# (1) Browse through the raw Twitter object, try to understand its \n",
    "# structure, and extract the following information about the status \n",
    "# update: \"user_id\", \"user_handle\", \"user_loc\", \"user_desc\", \"tweet_text\", \n",
    "# \"tweet_id\", \"tweet_time\"\n",
    "\n",
    "# For this, we need some functionalities from the json package. Let's \n",
    "# load it into our current python session\n",
    "import json\n",
    "\n",
    "# Let's open the JSON file with the 25.000 Twitter objects. First, we\n",
    "# read it into our python session as a simple text file.\n",
    "json_data = open(\"DATA/2019-12-06_16-43-32.json\").read()\n",
    "type(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we use the json.loads() function to recognize the python-like\n",
    "# json structures encoded into this string. In this case, it should\n",
    "# return a list ([]) of strings (\"\")\n",
    "json_data = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Fri Dec 06 14:24:28 +0000 2019',\n",
       " 'id': 1202956978286452738,\n",
       " 'id_str': '1202956978286452738',\n",
       " 'text': 'RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\\n\\nWhy would I only want to…',\n",
       " 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       " 'truncated': False,\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'user': {'id': 2496109354,\n",
       "  'id_str': '2496109354',\n",
       "  'name': 'robert',\n",
       "  'screen_name': 'rb218702',\n",
       "  'location': 'Northampton, England',\n",
       "  'url': None,\n",
       "  'description': 'British liberal, artist, check out my instagram page rob_burch_arts.',\n",
       "  'translator_type': 'none',\n",
       "  'protected': False,\n",
       "  'verified': False,\n",
       "  'followers_count': 230,\n",
       "  'friends_count': 614,\n",
       "  'listed_count': 2,\n",
       "  'favourites_count': 30169,\n",
       "  'statuses_count': 40775,\n",
       "  'created_at': 'Sun Apr 20 01:48:49 +0000 2014',\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': True,\n",
       "  'lang': None,\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'profile_background_color': 'C0DEED',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_link_color': '1DA1F2',\n",
       "  'profile_sidebar_border_color': 'C0DEED',\n",
       "  'profile_sidebar_fill_color': 'DDEEF6',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/948960672272060416/eDqUj4Ni_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/948960672272060416/eDqUj4Ni_normal.jpg',\n",
       "  'default_profile': True,\n",
       "  'default_profile_image': False,\n",
       "  'following': None,\n",
       "  'follow_request_sent': None,\n",
       "  'notifications': None},\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'retweeted_status': {'created_at': 'Fri Dec 06 12:41:07 +0000 2019',\n",
       "  'id': 1202930969830985728,\n",
       "  'id_str': '1202930969830985728',\n",
       "  'text': 'If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\\n\\nWhy would I only w… https://t.co/IReDDMuYTH',\n",
       "  'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
       "  'truncated': True,\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'in_reply_to_screen_name': None,\n",
       "  'user': {'id': 117777690,\n",
       "   'id_str': '117777690',\n",
       "   'name': 'Jeremy Corbyn',\n",
       "   'screen_name': 'jeremycorbyn',\n",
       "   'location': 'UK',\n",
       "   'url': 'https://volunteer.labour.org.uk/',\n",
       "   'description': 'Leader of the Labour Party.',\n",
       "   'translator_type': 'none',\n",
       "   'protected': False,\n",
       "   'verified': True,\n",
       "   'followers_count': 2248731,\n",
       "   'friends_count': 2650,\n",
       "   'listed_count': 7762,\n",
       "   'favourites_count': 248,\n",
       "   'statuses_count': 13704,\n",
       "   'created_at': 'Fri Feb 26 15:45:23 +0000 2010',\n",
       "   'utc_offset': None,\n",
       "   'time_zone': None,\n",
       "   'geo_enabled': True,\n",
       "   'lang': None,\n",
       "   'contributors_enabled': False,\n",
       "   'is_translator': False,\n",
       "   'profile_background_color': '131516',\n",
       "   'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme14/bg.gif',\n",
       "   'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme14/bg.gif',\n",
       "   'profile_background_tile': True,\n",
       "   'profile_link_color': '009999',\n",
       "   'profile_sidebar_border_color': '000000',\n",
       "   'profile_sidebar_fill_color': '000000',\n",
       "   'profile_text_color': '000000',\n",
       "   'profile_use_background_image': True,\n",
       "   'profile_image_url': 'http://pbs.twimg.com/profile_images/1197846676578426880/EiaPjwTi_normal.jpg',\n",
       "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1197846676578426880/EiaPjwTi_normal.jpg',\n",
       "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/117777690/1506521898',\n",
       "   'default_profile': False,\n",
       "   'default_profile_image': False,\n",
       "   'following': None,\n",
       "   'follow_request_sent': None,\n",
       "   'notifications': None},\n",
       "  'geo': None,\n",
       "  'coordinates': None,\n",
       "  'place': None,\n",
       "  'contributors': None,\n",
       "  'is_quote_status': False,\n",
       "  'extended_tweet': {'full_text': 'If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\\n\\nWhy would I only want to talk to half the country? I don’t want to live in half a country.\\n\\nA prime minister must talk and listen to everyone - and bring our divided country together.',\n",
       "   'display_text_range': [0, 280],\n",
       "   'entities': {'hashtags': [],\n",
       "    'urls': [],\n",
       "    'user_mentions': [],\n",
       "    'symbols': []}},\n",
       "  'quote_count': 655,\n",
       "  'reply_count': 1461,\n",
       "  'retweet_count': 8068,\n",
       "  'favorite_count': 36096,\n",
       "  'entities': {'hashtags': [],\n",
       "   'urls': [{'url': 'https://t.co/IReDDMuYTH',\n",
       "     'expanded_url': 'https://twitter.com/i/web/status/1202930969830985728',\n",
       "     'display_url': 'twitter.com/i/web/status/1…',\n",
       "     'indices': [117, 140]}],\n",
       "   'user_mentions': [],\n",
       "   'symbols': []},\n",
       "  'favorited': False,\n",
       "  'retweeted': False,\n",
       "  'filter_level': 'low',\n",
       "  'lang': 'en'},\n",
       " 'is_quote_status': False,\n",
       " 'quote_count': 0,\n",
       " 'reply_count': 0,\n",
       " 'retweet_count': 0,\n",
       " 'favorite_count': 0,\n",
       " 'entities': {'hashtags': [],\n",
       "  'urls': [],\n",
       "  'user_mentions': [{'screen_name': 'jeremycorbyn',\n",
       "    'name': 'Jeremy Corbyn',\n",
       "    'id': 117777690,\n",
       "    'id_str': '117777690',\n",
       "    'indices': [3, 16]}],\n",
       "  'symbols': []},\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'filter_level': 'low',\n",
       " 'lang': 'en',\n",
       " 'timestamp_ms': '1575642268140'}"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each of these strings contains a raw Twitter object that is again\n",
    "# encoded into python-like json structures. We keep these as strings\n",
    "# because the complex nested structures of the raw Twitter object\n",
    "# would slow python down. So, if we want to process these Tweets, let's\n",
    "# do so one by one. Let's look at the first one (list index = 0):\n",
    "tweet = json.loads(json_data[0])\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2496109354\n",
      "rb218702\n",
      "Northampton, England\n",
      "British liberal, artist, check out my instagram page rob_burch_arts.\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "1202956978286452738\n",
      "Fri Dec 06 14:24:28 +0000 2019\n"
     ]
    }
   ],
   "source": [
    "# Once we used the json package to convert this string into a \n",
    "# python-like data structure, we see that we are dealing with\n",
    "# a complex and nested dictionary that we can subset with the\n",
    "# tools we learned in the last classes.\n",
    "# We are supposed to find the following information about this\n",
    "# Twitter object: \"user_id\", \"user_handle\", \"user_loc\", \n",
    "# \"user_desc\", \"tweet_text\", \"tweet_id\", \"tweet_time\"\n",
    "\n",
    "print(tweet['user']['id'])\n",
    "print(tweet['user']['screen_name'])\n",
    "print(tweet['user']['location'])\n",
    "print(tweet['user']['description'])\n",
    "print(tweet['text'])\n",
    "print(tweet['id'])\n",
    "print(tweet['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fri Dec 06 14:24:28 +0000 2019'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2) Check out the time package and try to convert Twitter's time \n",
    "# signature into the format \"29/05/2019 07:04\"\n",
    "\n",
    "# Let's load the time package into our current python session\n",
    "import time\n",
    "\n",
    "# It has two functions that are relevant here:\n",
    "# - strptime() takes a string with date-time information and \n",
    "# creates a standardized date-time object (another object type \n",
    "# next to lists, dictionaries, etc.)\n",
    "# - strftime() takes a data-time object and creates a string\n",
    "# version of the date-time according to your own specification\n",
    "\n",
    "# Let's store the time-string from the Twitter dictionary into a\n",
    "# separate object for processing.\n",
    "tweet_time = tweet['created_at']\n",
    "tweet_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time.struct_time(tm_year=2019, tm_mon=12, tm_mday=6, tm_hour=14, tm_min=24, tm_sec=28, tm_wday=4, tm_yday=340, tm_isdst=-1)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following creates a structured date-time object based on\n",
    "# where we tell the function to look for each specific information\n",
    "# in the string. We do so by comparing the string structure with\n",
    "# the documentation of the strptime function in the time package:\n",
    "# https://docs.python.org/3/library/time.html\n",
    "tweet_time = time.strptime(tweet_time,'%a %b %d %H:%M:%S +0000 %Y')\n",
    "tweet_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-12-06 14:24:28'"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can turn this structured time object into a new string that\n",
    "# lives up to whatever we need:\n",
    "tweet_time_str = time.strftime(\"%Y-%m-%d %H:%M:%S\", tweet_time)\n",
    "tweet_time_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-12-06'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can use the structured time objects in python if you want to \n",
    "# do, e.g., time-series analysis or plot a timeline in python. If you\n",
    "# move to another programm (R or STATA), you might want to turn this \n",
    "# into the respectively useful string format. Alternatively, you could \n",
    "# also use this to aggregate Tweets per day:\n",
    "tweet_data_str = time.strftime(\"%Y-%m-%d\", tweet_time)\n",
    "tweet_data_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tweet_text is: RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n"
     ]
    }
   ],
   "source": [
    "# (3) Go through multiple Twitter objects and try to understand the \n",
    "# inconsistencies in which Tweet texts are stored depending on Tweet type\n",
    "# and text length.\n",
    "\n",
    "# The tweet text is a bit of a complicated story. Usually, you \n",
    "# will be able to find the text in tweet['text']... (see exercise 3 \n",
    "# for further complications)\n",
    "print(\"The tweet_text is: \" + tweet['text']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most likely, we are dealing with a: Retweet\n",
      "\n",
      "So the full length original tweet is: \n",
      " If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to talk to half the country? I don’t want to live in half a country.\n",
      "\n",
      "A prime minister must talk and listen to everyone - and bring our divided country together.\n"
     ]
    }
   ],
   "source": [
    "# But there are some exceptions to be wary about:\n",
    "# - Longer texts: If the tweet text exceeds a certain length, \n",
    "# you will find the non-abbreviated text in tweet['extended_tweet']['full_text']\n",
    "\n",
    "# - Retweets: You will find the full non-abbreviated original Tweet text\n",
    "# in tweet['retweeted_status']['text'], unless the original Tweet\n",
    "# was a longer text, in which case it is the same story as above \n",
    "# tweet['retweeted_status']['extended_tweet']['full_text']\n",
    "\n",
    "# - Quotes: If we are dealing with a quoted text, the tweet['text']\n",
    "# refers to the comment by the user, but you can get the original\n",
    "# quoted text with tweet['quoted_status']['text'] or \n",
    "# tweet['quoted_status']['extended_tweet']['full_text'] depending on \n",
    "# the length of the quoted tweet. \n",
    "\n",
    "# You can check with which type of Twitter object you are dealing with\n",
    "# by using some nested conditional questions:\n",
    "tweet_type = \"Tweet\"\n",
    "if 'quoted_status' in tweet:\n",
    "    tweet_type = \"Quote\"\n",
    "if 'retweeted_status' in tweet:\n",
    "    tweet_type = \"Retweet\"\n",
    "    if 'quoted_status' in tweet:\n",
    "        tweet_type = \"Re_Quote\"\n",
    "            \n",
    "print(\"\\nMost likely, we are dealing with a: \" + tweet_type)\n",
    "print(\"\\nSo the full length original tweet is: \\n \" + tweet['retweeted_status']['extended_tweet']['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>user_desc</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, user_handle, user_loc, user_desc, tweet_text, tweet_id, tweet_time]\n",
       "Index: []"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (4) Create a new pandas dataframe to store the information extracted in\n",
    "# the first task. Try to create a pandas dataframe without any content\n",
    "# a.k.a. an empty dataframe. This will be your master dataframe to which\n",
    "# you append information from Twitter objects row-by-row. (call it \"df\")\n",
    "\n",
    "# Let's load the pandas package into our python session under the name pd\n",
    "import pandas as pd\n",
    "\n",
    "# Let's define the relevant columns for these exercises (later one, you\n",
    "# might add columns depending on what you want to extract from the raw\n",
    "# Twitter data)\n",
    "selected_cols = [\"user_id\", \"user_handle\", \"user_loc\", \"user_desc\", \n",
    "                 \"tweet_text\", \"tweet_id\", \"tweet_time\"]\n",
    "\n",
    "# Now, let's create a DataFrame that does not contain any data to which\n",
    "# we will add a new row for each Twitter object we process. To create\n",
    "# a dataframe with 0 rows, we can use an empty list ([]) as the first\n",
    "# argument of the DataFrame() function\n",
    "df = pd.DataFrame([], columns=selected_cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @LaboursBlackPLP: This is massive, Former Tory Prime Minister will not be voting Tory and neither should you.\n",
      "\n",
      "John Major breaks Tory ra…\n",
      "RT @faisalislam: table in leaked Government presentation shows extraordinary new Irish Sea checks on the cards as a result of PMs Brexit de…\n",
      "RT @Conservatives: \"This is a Brexit election after all – and a vote for @BorisJohnson this time around is a vote to #GetBrexitDone\"\n",
      "\n",
      "🌳🗳 #V…\n",
      "@KLbils @BiztheBuz @NickBoles @jeremycorbyn Please bear in mind that if brexit is the biggest issue for you, you are extremely privileged.\n",
      "RT @DavidLammy: Evidence that @BorisJohnson is lying again and doing what he previously said he would never accept. Putting a border down t…\n",
      "RT @LeaveEUOfficial: In a letter to the anti-Semite, Boris blasts Corbyn's \"sly attempt to undermine the result of the 2016 referendum\" by…\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @achrisafis: “If we want to treat Macron as a future leader for the whole of Europe, in a political sense, then for this we need a polit…\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @chrisinsilico: I can’t get over this. The Prime Minister literally just said he wants to subject people of colour to “democratic contro…\n",
      "Good thread.\n",
      "RT @LFIU2019: BREAKING NEWS: Leaked documents shows the truth about British border in the Island of Ireland. #VoteLabour #NeverTrustATory…\n",
      "RT @OwenJones84: The leaked document revealed by Jeremy Corbyn exposes Boris Johnson is lying about Brexit and Northern Ireland, just like…\n",
      "EU distances itself from Johnson’s timetable for post-Brexit trade deal\n",
      "\n",
      "https://t.co/CrukzmUg4i\n",
      "@DevonianMatthew I knew Brexit would put it up again!\n",
      "RT @August05398614: How can anyone vote for an existing PM who will sleep with your granny to get a vote and the nation has a number 1 hit…\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @billnewtondunn: How many benefits to EU membership can I list in 60 seconds? Not enough as it turns out. With fewer than 60 days to go…\n",
      "RT @RichardCollettW: Electoral Commission records show political parties and individual politicians have taken more than £9 million in gift…\n",
      "RT @LabourLeft: Brexit voter explains why it’s so important for ordinary working people to vote Labour in this election. \n",
      "\n",
      "Don’t be conned…\n",
      "RT @Channel4News: \"We have now caught Johnson red-handed misrepresenting his own Brexit deal.\"\n",
      "\n",
      "Jeremy Corbyn says Labour has a \"confidenti…\n",
      "RT @BrexitPartridge: If the Left didn't hate him enough, Boris goes to a Jewish bakery 😂👊👍 https://t.co/ThRmKgJNnS\n",
      "RT @LaurakBuzz: Jeremy Corbyn releases leaked government documents that show Boris Johnson 'lied about Brexit deal' https://t.co/Zo9qyQEzI7\n",
      "RT @Keir_Starmer: Boris Johnson has been caught out lying (again) about the damaging impact of his Brexit deal.\n",
      " \n",
      "Johnson has repeatedly sa…\n",
      "RT @UKLabour: Boris Johnson is lying to you about his plan for Brexit and his own Government's report proves it. https://t.co/KIH4O9Z9cZ\n",
      "RT @alexwickham: NEW: Boris Johnson team launches furious attack on Channel 4\n",
      "\n",
      "Accuses the broadcaster of “inventing the most damaging thin…\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @JohnGPeet: Why I am worried about Johnson getting Brexit done, short thread based on my piece in this week’s Economist./1\n",
      "You know you've reached ridiculous levels of social media #Brexit stupidity, when people (including certain Sky presenters) are even being triggered by the PM's gf posting a harmless video of two sibling dogs playing. https://t.co/4qGDhe8T9N\n",
      "RT @Mandoline_Blue: BREAKING game changer! EU has changed its stance on BJ's deal. The latest EU text says UK must respect EU standards on…\n",
      "RT @thomasbrake: You can't be pro-business and pro-Brexit. And a damaging Brexit makes a mockery of manifesto promises. \n",
      "\n",
      "The Lib Dems have…\n",
      "@bbclaurak https://t.co/wZEbLjZJgm\n",
      "RT @BBCPolitics: General election 2019: Johnson 'misrepresenting' Brexit deal, says Corbyn \n",
      "\n",
      "https://t.co/gKzEUx7Mrv\n",
      "RT @UKLabour: Boris Johnson is lying to you about his plan for Brexit and his own Government's report proves it. https://t.co/KIH4O9Z9cZ\n",
      "RT @LanceForman: OFFICIAL CONFESSION\n",
      "\n",
      "People have asked what the Tories have offered me.   \n",
      "\n",
      "Here goes:\n",
      "\n",
      "1. Getting Brexit done\n",
      "\n",
      "2. Keeping…\n",
      "RT @celtjules66: If you’re considering voting Tory to “get Brexit done “, I’m afraid you’re going to have a long wait.\n",
      "Please spare a thoug…\n",
      "RT @DianaHarding7: Brexit Party candidate who was sent death threats from far-left activists is run off the road while campaigning in Donca…\n",
      "RT @BrexitPartridge: If the Left didn't hate him enough, Boris goes to a Jewish bakery 😂👊👍 https://t.co/ThRmKgJNnS\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @DavidLammy: Huge blow for @Conservatives. Former Conservative Prime Minister John Major urging the public to vote against Boris Johnson…\n",
      "RT @chrisinsilico: I can’t get over this. The Prime Minister literally just said he wants to subject people of colour to “democratic contro…\n",
      "@MarkTowler1 @LanceForman @Conservatives @BorisJohnson Yes because Brexit didn’t have a majority in Parliament\n",
      "\n",
      "If you want Brexit done, but don’t want to vote Conservative, what on Earth is the grand plan? \n",
      "\n",
      "If you are voting Brexit Party then I can only think that on some subconscious level you actually don’t want to leave the EU\n",
      "RT @PeoplesMomentum: Brexit voter has something to say to Boris Johnson.\n",
      "\n",
      "#Brexit #GE2019 https://t.co/lv7r7fDB9H\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @Cleisthenes6: @john4brexit Boris Johnson lied to the DUP. No border down the Irish Sea \n",
      "\n",
      "He lied to NI businesspeople a few weeks ago.…\n",
      "RT @DCHutchings: EU distances itself from Johnson’s timetable for post-Brexit trade deal\n",
      "\n",
      "https://t.co/CrukzmUg4i\n",
      "RT @BenJolly9: This man nails the real divide in our society - “The problems have got nothing to do with Brexit, the problems have been inf…\n",
      "https://t.co/RkmkFt7o9b\n",
      "RT @pmdfoster: There is a lot of 'nothing to see here' response to leaked @hmtreasury assessment of @BorisJohnson #Brexit Northern Ireland…\n",
      "Just how I'm feeling too\n",
      "RT @grahambsi: John Major breaks Tory ranks as he urges young voters to stop Boris Johnson's Brexit plan | London Evening Standard https://…\n",
      "RT @cliodiaspora: I have no idea how low you still intend to sink, ⁦@BorisJohnson,⁩ but how dare you argue that giving us EU citizens a vot…\n",
      "RT @Peston: A Tory former prime minister Sir John Major does something extraordinary in an extraordinary election. He says vote to stop Bre…\n",
      "RT @DavidLammy: Huge blow for @Conservatives. Former Conservative Prime Minister John Major urging the public to vote against Boris Johnson…\n",
      "RT @anotherview16: We knew Boris Johnson wasn't telling us the whole Brexit deal story - but this shows it was all DAMN LIES https://t.co/2…\n",
      "What Laura can't quite bring herself to say is \"he's been caught lying\"\n",
      "RT @UKLabour: BREAKING: A secret government report proves Boris Johnson is lying to the public about his plan for Brexit. \n",
      "If Boris Johnson…\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @DavidLammy: Huge blow for @Conservatives. Former Conservative Prime Minister John Major urging the public to vote against Boris Johnson…\n",
      "RT @nadialanomade: @HackedOffHugh Imagine the alternative. They get a majority. A hard Brexit is unstoppable. NHS is on the chopping block.…\n",
      "@femaledownfall You me and the BEST part of the population. All I can tell you, anyone who voted #Brexit or #Boris will not get to visit us in France. #harshbutfair\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "🎼 So here it is, Merry Christmas,\n",
      "Everybody's having fun.🎵\n",
      "🎼 @theSNP are scunnered,\n",
      "&amp; the 'Toaaarrrieees' are No.1🎵\n",
      "\n",
      "{STD Verse}\n",
      "\n",
      "🎼 So here it is, Merry Christmas,\n",
      "Everybody's having fun.🎵\n",
      "🎼Look to the future,\n",
      "#BrExit has just begun🎵\n",
      "\n",
      "#GE2019 \n",
      "#VoteConservative\n",
      "#BackBoris\n",
      "RT @Keir_Starmer: Boris Johnson has been caught out lying (again) about the damaging impact of his Brexit deal.\n",
      " \n",
      "Johnson has repeatedly sa…\n",
      "RT @juliefair: I am starting to think that this Brexit election is a massive  Trojan Horse, designed to slip in manifesto page 48 , so that…\n",
      "RT @jeremycorbyn: This leaked government document shows Boris Johnson hasn't been telling the truth to the people of our country about his…\n",
      "RT @Tpopularfront: There was a BBC series in the 90’s called ‘Our friends in the North’. Big budget, made massive stars of the main actors.…\n",
      "#NeverCorbyn #CorbynUnfit4PM #DONTVOTELABOUR #NeverLabour #TerroristSympathiser \n",
      "D\n",
      "O\n",
      "N\n",
      "T\n",
      "\n",
      "V\n",
      "O\n",
      "T\n",
      "E\n",
      "\n",
      "L\n",
      "A\n",
      "B\n",
      "O\n",
      "U\n",
      "R https://t.co/be9xpOrNTg\n",
      "@jeremycorbyn BREXIT UNDER LABOUR WONT HAPPEN - THE MAN IS INCAPABLE OF RUNNING A BATH -UNICORN IDEAS THAT WILL MAKE YOU POOR https://t.co/aKY8vjd8Cx\n",
      "RT @AudreyAurus1: Jeremy Corbyn doing the job that journalists are supposed to be doing... \n",
      "You know, dear journalists, there are more to f…\n",
      "RT @Shamils18: @bbclaurak Caught lying again?\n",
      "\n",
      "This is the only Brexit video everyone must watch.\n",
      "\n",
      "Whether you voted Leave or Remain, take…\n",
      "RT @lewis_goodall: This isn’t true. There will. \n",
      "\n",
      "The civil service says it. The Brexit Secretary says it. The PM’s de facto deputy says it…\n",
      "@paul13walnut5 @AnnieWellsMSP @ScotTories It's the risk of Brexit  - uncertainty and actuality - that is damaging business.\n",
      "\n",
      "Its Brexit that will be the shock that finally wakes Scotland to the need for independence. \n",
      "\n",
      "A happier, fairer, richer future awaits us.\n",
      "\n",
      "#ItsTime to #DissolveTheUnion\n",
      "RT @Peston: A Tory former prime minister Sir John Major does something extraordinary in an extraordinary election. He says vote to stop Bre…\n",
      "RT @Alex_Loze_Davis: All 6 constituencies in Cornwall have candidates from the new Liberal Party, which include 3 re. active UKIP campaigne…\n",
      "RT @nicktolhurst: I’ve been a bit skeptical about those attacking @bbclaurak\n",
      "..but when a leaked document reveals PM lied, NI economy utter…\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "RT @DavidLammy: Huge blow for @Conservatives. Former Conservative Prime Minister John Major urging the public to vote against Boris Johnson…\n",
      "RT @AaronBastani: Labour is competitive in seats it needs to win but didn't last time: Swindon, Putney, Hendon, Southampton, Hastings.\n",
      "\n",
      "Mea…\n",
      "@prodlegacy @BorisJohnson Nope; that’s not correct.\n",
      "\n",
      "The Good Friday Agreement is a treaty between two countries.\n",
      "\n",
      "Whereas\n",
      "\n",
      "Brexit was an exercise in public opinion. It does not bind the UK Parliament since you are not a Republic. The UK people are not sovereign: your Parliament and your Queen are. https://t.co/CUbCRc7YuQ\n",
      "RT @DavidLammy: Evidence that @BorisJohnson is lying again and doing what he previously said he would never accept. Putting a border down t…\n",
      "RT @OwenJones84: The leaked document revealed by Jeremy Corbyn exposes Boris Johnson is lying about Brexit and Northern Ireland, just like…\n",
      "#BottleJobBoris does it again!\n",
      "The truth about whether Boris Johnson is misleading voters over his Brexit deal https://t.co/6Py0lKUTb8\n",
      "RT @BBCPolitics: Boris Johnson is asked about a leaked document, which Labour says shows his Brexit deal will mean checks between Northern…\n",
      "RT @jpwhite1985: My brother doing us proud on Question Time!!! “The problems have got nothing to do with Brexit, the problems have been inf…\n",
      "RT @faisalislam: table in leaked Government presentation shows extraordinary new Irish Sea checks on the cards as a result of PMs Brexit de…\n",
      "RT @trebor4128: @JWalton12267995 @Paula55855 @Lugey6 @DanielJHannan @LanceForman @zatzi @john4brexit @Conservatives Only Lucy has removed B…\n",
      "RT @SamCoatesSky: NEW - Leaked Treasury document, here in full, which suggests potential checks on goods going to/ from NI under Boris John…\n",
      "RT @13sarahmurphy: Everything about Brexit is stupid and really quite evil: the way the mandate has been twisted into a Tory wet dream, the…\n",
      "RT @jeremycorbyn: If some accuse me of talking to both sides in the Brexit debate then so be it. I’m proud of it.\n",
      "\n",
      "Why would I only want to…\n",
      "If only we could all distance ourselves from Johnson.\n",
      "EU distances itself from Johnson’s timetable for post-Brexit trade deal https://t.co/ZKi09aEBQg\n",
      "#PantsOnFire #BorisOut #ToriesOut #BrexitShambles #brexitchaos #brexit #brexitbarometer\n",
      "RT @mrjamesob: Two former PMs to join Final Say rally calling for tactical voting to block majority for Boris Johnson https://t.co/RftokdKD…\n",
      "RT @Simon_Nixon: An astonishing moment. https://t.co/0L4puSOvPU\n",
      "RT @AngusRobertson: Interesting to see that negative impressions about Boris Johnson and his Brexit policy is making some traditional Scott…\n",
      "RT @MatthewGreen02: If, 4 years ago, someone said Tony Blair &amp; John Major, would both join a rally in a General Election that's explicitly…\n",
      "RT @bbclaurak: PM admitted there would be some checks in this interview here - acknowledges this was compromise with EU to avoid checks on…\n"
     ]
    }
   ],
   "source": [
    "# (5) Write a for-loop that runs through the first 100 Twitter objects \n",
    "# from the JSON data, converts the string into a dictionary, and prints \n",
    "# the tweet_text for each. \n",
    "# Tipp: Check our if-else statements to ensure that you extract the text \n",
    "# reliably for each Tweet format.\n",
    "\n",
    "# Let's loop through the first 100 elements in the json_data list, and\n",
    "# do some stuff for each Twitter object\n",
    "for ix in range(0, 100):\n",
    "    # First, let's turn the string into a dictionary that we can query\n",
    "    # for relevant information\n",
    "    tweet = json.loads(json_data[ix])\n",
    "    \n",
    "    # Now let's print the tweet text, and make sure we get the \n",
    "    # extended version in case the text is too long...\n",
    "    \n",
    "    if 'extended_tweet' in tweet: # If you find the key 'extended_tweet' in the tweet dictionary, do the following\n",
    "        print(tweet['extended_tweet']['full_text'])\n",
    "    else: # If you don't find the key 'extended_tweet' in the tweet dictionary, do this instead\n",
    "        print(tweet['text'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>user_desc</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  user_handle  user_loc  user_desc  tweet_text  tweet_id  tweet_time\n",
       "0      NaN          NaN       NaN        NaN         NaN       NaN         NaN"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (6) Extend this loop to create a new pandas dataframe with the same \n",
    "# columns as \"df\" and one row with np.nan for each column. (call it \n",
    "# \"new_row\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# First, let's define some empty data for the same columns as in the\n",
    "# df DataFrame, which we can use to store the respective information\n",
    "# for each Twitter object (see 03_Tasting.ipynb)\n",
    "empty_data = {col: [np.nan] for col in selected_cols}\n",
    "\n",
    "for ix in range(0, 100):\n",
    "    # Get the dictionary of the Twitter object\n",
    "    tweet = json.loads(json_data[ix])\n",
    "    \n",
    "    # Create an DataFrame with one empty row\n",
    "    new_row = pd.DataFrame(empty_data)\n",
    "    \n",
    "new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>user_desc</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2496109354</td>\n",
       "      <td>rb218702</td>\n",
       "      <td>Northampton, England</td>\n",
       "      <td>British liberal, artist, check out my instagra...</td>\n",
       "      <td>RT @jeremycorbyn: If some accuse me of talking...</td>\n",
       "      <td>1202956978286452738</td>\n",
       "      <td>2019-12-06 14:24:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>496433273</td>\n",
       "      <td>david707x</td>\n",
       "      <td>Newport, Wales</td>\n",
       "      <td>http://Gov.UK/registertovote\\n#RemainAlliance\\...</td>\n",
       "      <td>RT @LaboursBlackPLP: This is massive, Former T...</td>\n",
       "      <td>1202956979284647938</td>\n",
       "      <td>2019-12-06 14:24:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3390733695</td>\n",
       "      <td>AndrewHemmingt2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @faisalislam: table in leaked Government pr...</td>\n",
       "      <td>1202956979838304260</td>\n",
       "      <td>2019-12-06 14:24:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>269708883</td>\n",
       "      <td>ferrier3</td>\n",
       "      <td>paisley</td>\n",
       "      <td>singer sometimes!</td>\n",
       "      <td>RT @Conservatives: \"This is a Brexit election ...</td>\n",
       "      <td>1202956980949786627</td>\n",
       "      <td>2019-12-06 14:24:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1038400204305850368</td>\n",
       "      <td>fran_oneill_s</td>\n",
       "      <td>Leeds, England</td>\n",
       "      <td>Feminist. Humanist. Cyclist. Likes kindness &amp; ...</td>\n",
       "      <td>@KLbils @BiztheBuz @NickBoles @jeremycorbyn Pl...</td>\n",
       "      <td>1202956981767720961</td>\n",
       "      <td>2019-12-06 14:24:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1822726884</td>\n",
       "      <td>MatthewGreen02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Director, Green Planning Studio @greenplanning...</td>\n",
       "      <td>RT @mrjamesob: Two former PMs to join Final Sa...</td>\n",
       "      <td>1202957080090599426</td>\n",
       "      <td>2019-12-06 14:24:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>124313779</td>\n",
       "      <td>Untidy_mind</td>\n",
       "      <td>UK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @Simon_Nixon: An astonishing moment. https:...</td>\n",
       "      <td>1202957080333828098</td>\n",
       "      <td>2019-12-06 14:24:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>431515838</td>\n",
       "      <td>mclaren_joanne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @AngusRobertson: Interesting to see that ne...</td>\n",
       "      <td>1202957080669425666</td>\n",
       "      <td>2019-12-06 14:24:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>104141401</td>\n",
       "      <td>angegarrod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#BlockTheCoup  Arty farty. Artist, photographe...</td>\n",
       "      <td>RT @MatthewGreen02: If, 4 years ago, someone s...</td>\n",
       "      <td>1202957082254860292</td>\n",
       "      <td>2019-12-06 14:24:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>351664268</td>\n",
       "      <td>rastahill</td>\n",
       "      <td>Eastbourne, East Sussex, UK</td>\n",
       "      <td>Husband, father. X Deputy CX Reigate &amp; Banstea...</td>\n",
       "      <td>RT @bbclaurak: PM admitted there would be some...</td>\n",
       "      <td>1202957082619785216</td>\n",
       "      <td>2019-12-06 14:24:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                user_id      user_handle                     user_loc  \\\n",
       "0            2496109354         rb218702         Northampton, England   \n",
       "1             496433273        david707x               Newport, Wales   \n",
       "2            3390733695  AndrewHemmingt2                          NaN   \n",
       "3             269708883         ferrier3                      paisley   \n",
       "4   1038400204305850368    fran_oneill_s               Leeds, England   \n",
       "..                  ...              ...                          ...   \n",
       "95           1822726884   MatthewGreen02                          NaN   \n",
       "96            124313779      Untidy_mind                           UK   \n",
       "97            431515838   mclaren_joanne                          NaN   \n",
       "98            104141401       angegarrod                          NaN   \n",
       "99            351664268        rastahill  Eastbourne, East Sussex, UK   \n",
       "\n",
       "                                            user_desc  \\\n",
       "0   British liberal, artist, check out my instagra...   \n",
       "1   http://Gov.UK/registertovote\\n#RemainAlliance\\...   \n",
       "2                                                 NaN   \n",
       "3                                   singer sometimes!   \n",
       "4   Feminist. Humanist. Cyclist. Likes kindness & ...   \n",
       "..                                                ...   \n",
       "95  Director, Green Planning Studio @greenplanning...   \n",
       "96                                                NaN   \n",
       "97                                                NaN   \n",
       "98  #BlockTheCoup  Arty farty. Artist, photographe...   \n",
       "99  Husband, father. X Deputy CX Reigate & Banstea...   \n",
       "\n",
       "                                           tweet_text             tweet_id  \\\n",
       "0   RT @jeremycorbyn: If some accuse me of talking...  1202956978286452738   \n",
       "1   RT @LaboursBlackPLP: This is massive, Former T...  1202956979284647938   \n",
       "2   RT @faisalislam: table in leaked Government pr...  1202956979838304260   \n",
       "3   RT @Conservatives: \"This is a Brexit election ...  1202956980949786627   \n",
       "4   @KLbils @BiztheBuz @NickBoles @jeremycorbyn Pl...  1202956981767720961   \n",
       "..                                                ...                  ...   \n",
       "95  RT @mrjamesob: Two former PMs to join Final Sa...  1202957080090599426   \n",
       "96  RT @Simon_Nixon: An astonishing moment. https:...  1202957080333828098   \n",
       "97  RT @AngusRobertson: Interesting to see that ne...  1202957080669425666   \n",
       "98  RT @MatthewGreen02: If, 4 years ago, someone s...  1202957082254860292   \n",
       "99  RT @bbclaurak: PM admitted there would be some...  1202957082619785216   \n",
       "\n",
       "             tweet_time  \n",
       "0   2019-12-06 14:24:28  \n",
       "1   2019-12-06 14:24:28  \n",
       "2   2019-12-06 14:24:28  \n",
       "3   2019-12-06 14:24:28  \n",
       "4   2019-12-06 14:24:28  \n",
       "..                  ...  \n",
       "95  2019-12-06 14:24:52  \n",
       "96  2019-12-06 14:24:52  \n",
       "97  2019-12-06 14:24:52  \n",
       "98  2019-12-06 14:24:52  \n",
       "99  2019-12-06 14:24:53  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (7) Extend this loop to fill in the cells for each new Tweet and append\n",
    "# the result to the \"df\" dataframe.\n",
    "empty_data = {col: [np.nan] for col in selected_cols}\n",
    "\n",
    "for ix in range(0, 100):\n",
    "    tweet = json.loads(json_data[ix])\n",
    "    new_row = pd.DataFrame(empty_data)\n",
    "    \n",
    "    if 'extended_tweet' in tweet: \n",
    "        new_row.loc[0, \"tweet_text\"] = tweet['extended_tweet']['full_text']\n",
    "    else: \n",
    "        new_row.loc[0, \"tweet_text\"] = tweet['text']\n",
    "    \n",
    "    new_row.loc[0, \"user_id\"] = tweet['user']['id_str']\n",
    "    new_row.loc[0, \"user_handle\"] = tweet['user']['screen_name']\n",
    "    new_row.loc[0, \"user_loc\"] = tweet['user']['location']\n",
    "    new_row.loc[0, \"user_desc\"] = tweet['user']['description']\n",
    "    new_row.loc[0, \"tweet_id\"] = tweet[\"id_str\"]\n",
    "\n",
    "\n",
    "    # For fun's sake, let's apply what we learned in exercise 2\n",
    "    tweet_time = tweet['created_at']\n",
    "    tweet_time = time.strptime(tweet_time,'%a %b %d %H:%M:%S +0000 %Y')\n",
    "    new_row.loc[0, \"tweet_time\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\", tweet_time)\n",
    "    \n",
    "    # Now, in order to save each newly extracted row, append it to the master \n",
    "    # DataFrame created in exercise 4. Use the ignore_index option to ensure\n",
    "    # a clean indexing of the master DataFrame df.\n",
    "    df = df.append(new_row, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8) After this loop, save \"df\" on your disk in the feather format.\n",
    "df.to_feather(\"DATA/processed_tweets.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 0 of 25000\n",
      "Processed: 1000 of 25000\n",
      "Processed: 2000 of 25000\n",
      "Processed: 3000 of 25000\n",
      "Processed: 4000 of 25000\n",
      "Processed: 5000 of 25000\n",
      "Processed: 6000 of 25000\n",
      "Processed: 7000 of 25000\n",
      "Processed: 8000 of 25000\n",
      "Processed: 9000 of 25000\n",
      "Processed: 10000 of 25000\n",
      "Processed: 11000 of 25000\n",
      "Processed: 12000 of 25000\n",
      "Processed: 13000 of 25000\n",
      "Processed: 14000 of 25000\n",
      "Processed: 15000 of 25000\n",
      "Processed: 16000 of 25000\n",
      "Processed: 17000 of 25000\n",
      "Processed: 18000 of 25000\n",
      "Processed: 19000 of 25000\n",
      "Processed: 20000 of 25000\n",
      "Processed: 21000 of 25000\n",
      "Processed: 22000 of 25000\n",
      "Processed: 23000 of 25000\n",
      "Processed: 24000 of 25000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>user_desc</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2496109354</td>\n",
       "      <td>rb218702</td>\n",
       "      <td>Northampton, England</td>\n",
       "      <td>British liberal, artist, check out my instagra...</td>\n",
       "      <td>RT @jeremycorbyn: If some accuse me of talking...</td>\n",
       "      <td>1202956978286452738</td>\n",
       "      <td>2019-12-06 14:24:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>496433273</td>\n",
       "      <td>david707x</td>\n",
       "      <td>Newport, Wales</td>\n",
       "      <td>http://Gov.UK/registertovote\\n#RemainAlliance\\...</td>\n",
       "      <td>RT @LaboursBlackPLP: This is massive, Former T...</td>\n",
       "      <td>1202956979284647938</td>\n",
       "      <td>2019-12-06 14:24:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3390733695</td>\n",
       "      <td>AndrewHemmingt2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @faisalislam: table in leaked Government pr...</td>\n",
       "      <td>1202956979838304260</td>\n",
       "      <td>2019-12-06 14:24:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>269708883</td>\n",
       "      <td>ferrier3</td>\n",
       "      <td>paisley</td>\n",
       "      <td>singer sometimes!</td>\n",
       "      <td>RT @Conservatives: \"This is a Brexit election ...</td>\n",
       "      <td>1202956980949786627</td>\n",
       "      <td>2019-12-06 14:24:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1038400204305850368</td>\n",
       "      <td>fran_oneill_s</td>\n",
       "      <td>Leeds, England</td>\n",
       "      <td>Feminist. Humanist. Cyclist. Likes kindness &amp; ...</td>\n",
       "      <td>@KLbils @BiztheBuz @NickBoles @jeremycorbyn Pl...</td>\n",
       "      <td>1202956981767720961</td>\n",
       "      <td>2019-12-06 14:24:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24995</td>\n",
       "      <td>28837985</td>\n",
       "      <td>HRHTudor1976</td>\n",
       "      <td>Infinity &amp; Beyond 🧚🏻‍♀️🧚</td>\n",
       "      <td>Proud Welsh ❤️ INFJ 🧚‍♂️ I'm the one that's go...</td>\n",
       "      <td>RT @JoeMurphyLondon: Exclusive\\nEx-PM Sir John...</td>\n",
       "      <td>1202976850596843520</td>\n",
       "      <td>2019-12-06 15:43:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24996</td>\n",
       "      <td>385996137</td>\n",
       "      <td>Selzer_David</td>\n",
       "      <td>UK</td>\n",
       "      <td>Writer and publisher.</td>\n",
       "      <td>Our message from Labour’s battle bus? This is ...</td>\n",
       "      <td>1202976851137900545</td>\n",
       "      <td>2019-12-06 15:43:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24997</td>\n",
       "      <td>223981829</td>\n",
       "      <td>Roelandpaul</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Psychologist. Dutch. If I would live in the UK...</td>\n",
       "      <td>@K57Steve @Crypto_Slice @RuthLeaEcon You blame...</td>\n",
       "      <td>1202976853197230080</td>\n",
       "      <td>2019-12-06 15:43:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24998</td>\n",
       "      <td>29167204</td>\n",
       "      <td>folanchi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Be human - vote Labour 🌹</td>\n",
       "      <td>RT @DavidLammy: Huge blow for @Conservatives. ...</td>\n",
       "      <td>1202976853318946819</td>\n",
       "      <td>2019-12-06 15:43:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24999</td>\n",
       "      <td>21261686</td>\n",
       "      <td>treesey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>journalist/filmmaker</td>\n",
       "      <td>RT @katie_martin_fx: \"I am at a stage in life ...</td>\n",
       "      <td>1202976854262648839</td>\n",
       "      <td>2019-12-06 15:43:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user_id      user_handle                  user_loc  \\\n",
       "0               2496109354         rb218702      Northampton, England   \n",
       "1                496433273        david707x            Newport, Wales   \n",
       "2               3390733695  AndrewHemmingt2                       NaN   \n",
       "3                269708883         ferrier3                   paisley   \n",
       "4      1038400204305850368    fran_oneill_s            Leeds, England   \n",
       "...                    ...              ...                       ...   \n",
       "24995             28837985     HRHTudor1976  Infinity & Beyond 🧚🏻‍♀️🧚   \n",
       "24996            385996137     Selzer_David                        UK   \n",
       "24997            223981829      Roelandpaul                 Amsterdam   \n",
       "24998             29167204         folanchi                       NaN   \n",
       "24999             21261686          treesey                       NaN   \n",
       "\n",
       "                                               user_desc  \\\n",
       "0      British liberal, artist, check out my instagra...   \n",
       "1      http://Gov.UK/registertovote\\n#RemainAlliance\\...   \n",
       "2                                                    NaN   \n",
       "3                                      singer sometimes!   \n",
       "4      Feminist. Humanist. Cyclist. Likes kindness & ...   \n",
       "...                                                  ...   \n",
       "24995  Proud Welsh ❤️ INFJ 🧚‍♂️ I'm the one that's go...   \n",
       "24996                              Writer and publisher.   \n",
       "24997  Psychologist. Dutch. If I would live in the UK...   \n",
       "24998                           Be human - vote Labour 🌹   \n",
       "24999                               journalist/filmmaker   \n",
       "\n",
       "                                              tweet_text             tweet_id  \\\n",
       "0      RT @jeremycorbyn: If some accuse me of talking...  1202956978286452738   \n",
       "1      RT @LaboursBlackPLP: This is massive, Former T...  1202956979284647938   \n",
       "2      RT @faisalislam: table in leaked Government pr...  1202956979838304260   \n",
       "3      RT @Conservatives: \"This is a Brexit election ...  1202956980949786627   \n",
       "4      @KLbils @BiztheBuz @NickBoles @jeremycorbyn Pl...  1202956981767720961   \n",
       "...                                                  ...                  ...   \n",
       "24995  RT @JoeMurphyLondon: Exclusive\\nEx-PM Sir John...  1202976850596843520   \n",
       "24996  Our message from Labour’s battle bus? This is ...  1202976851137900545   \n",
       "24997  @K57Steve @Crypto_Slice @RuthLeaEcon You blame...  1202976853197230080   \n",
       "24998  RT @DavidLammy: Huge blow for @Conservatives. ...  1202976853318946819   \n",
       "24999  RT @katie_martin_fx: \"I am at a stage in life ...  1202976854262648839   \n",
       "\n",
       "                tweet_time  \n",
       "0      2019-12-06 14:24:28  \n",
       "1      2019-12-06 14:24:28  \n",
       "2      2019-12-06 14:24:28  \n",
       "3      2019-12-06 14:24:28  \n",
       "4      2019-12-06 14:24:28  \n",
       "...                    ...  \n",
       "24995  2019-12-06 15:43:26  \n",
       "24996  2019-12-06 15:43:26  \n",
       "24997  2019-12-06 15:43:26  \n",
       "24998  2019-12-06 15:43:26  \n",
       "24999  2019-12-06 15:43:26  \n",
       "\n",
       "[25000 rows x 7 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (9) Try to process all 25.000 Twitter objects with this loop. \n",
    "# Tipp: If you run into troubles, manually check out the Twitter object\n",
    "# that breaks the loop to ensure you're looking for the information at\n",
    "# the right place in the dictionary.\n",
    "\n",
    "# First let's load all the different packages that we need for this\n",
    "# process\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Then, recreate the master DataFrame that we want to store the\n",
    "# processed data in:\n",
    "selected_cols = [\"user_id\", \"user_handle\", \"user_loc\", \"user_desc\", \n",
    "                 \"tweet_text\", \"tweet_id\", \"tweet_time\"]\n",
    "df = pd.DataFrame([], columns=selected_cols)\n",
    "empty_data = {col: [np.nan] for col in selected_cols}\n",
    "\n",
    "# Let's open the JSON batch of 25.000 tweets\n",
    "json_data = open(\"DATA/2019-12-06_16-43-32.json\").read()\n",
    "json_data = json.loads(json_data)\n",
    "\n",
    "# Now, loop through the list of json-formatted Twitter objects,\n",
    "# extract the information we need, and add rows to the main \n",
    "# DataFrame for each Tweet.\n",
    "for ix in range(0, len(json_data)):\n",
    "    tweet = json.loads(json_data[ix])\n",
    "    new_row = pd.DataFrame(empty_data)\n",
    "    \n",
    "    # EXTRACTION\n",
    "    # Non problematic information\n",
    "    new_row.loc[0, \"user_id\"] = tweet['user']['id_str']\n",
    "    new_row.loc[0, \"user_handle\"] = tweet['user']['screen_name']\n",
    "    new_row.loc[0, \"user_loc\"] = tweet['user']['location']\n",
    "    new_row.loc[0, \"user_desc\"] = tweet['user']['description']\n",
    "    new_row.loc[0, \"tweet_id\"] = tweet[\"id_str\"]\n",
    "    \n",
    "    if 'extended_tweet' in tweet: \n",
    "        new_row.loc[0, \"tweet_text\"] = tweet['extended_tweet']['full_text']\n",
    "    else: \n",
    "        new_row.loc[0, \"tweet_text\"] = tweet['text']\n",
    "    \n",
    "    tweet_time = tweet['created_at']\n",
    "    tweet_time = time.strptime(tweet_time,'%a %b %d %H:%M:%S +0000 %Y')\n",
    "    new_row.loc[0, \"tweet_time\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\", tweet_time)\n",
    "    \n",
    "    df = df.append(new_row, ignore_index=True)\n",
    "    \n",
    "    # In order to check how quickly or slowly you computer is handling this\n",
    "    # let's just print something at every 100 Tweets processed:\n",
    "    if ix%1000 == 0: # If the remainder of dividing ix by 100 is equal to 0, do the following\n",
    "        print(\"Processed: \" + str(ix) + \" of \" + str(len(json_data)))\n",
    "df        \n",
    "# df.to_feather(\"DATA/processed_tweets.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10) Check out how to write functions in python, and write this process\n",
    "# into a function that takes the string Twitter object, converts it into\n",
    "# a dictionary, etc. and outputs the new_row pandas dataframe. You should\n",
    "# be able to run the following for-loop executing everything from the \n",
    "# previous exercises:\n",
    "for ix in range(0, len(json_data)):\n",
    "    new_row = process_raw(json_data[ix])\n",
    "    df = df.append(new_row)\n",
    "\n",
    "# (11) Try to find a way to time how long your computer takes to calculate\n",
    "# each of these loops. Is the short version with the function quicker?\n",
    "# Can you think of ways to speed this up? Why is it taking so long?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Week 4: Natural Language Processing\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# For the purpose of the NLP sessions, we will be working with a \n",
    "# small set of Brexit Tweets from the users eucopresident, \n",
    "# BorisJohnson, and theresa_may. The data for this was extracted \n",
    "# using the process_tweet function you can find in the \n",
    "# 04_processing.py script I uploaded to Absalon. There you can\n",
    "# also find the CSV and feather versions of this dataset, which\n",
    "# was taken directly from DIPLOFACE's SQL server.\n",
    "\n",
    "# Let's load the usual packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# pandas has an inbuild function to read feather files, but \n",
    "# depending on you package version, this sometimes gives you \n",
    "# some error messages. If that happens, a quick fix is to use\n",
    "# the feather package directly\n",
    "import feather\n",
    "df = feather.read_dataframe(\"DATA/love-triangle.feather\")\n",
    "df\n",
    "?np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'fillNone'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a5e74f76c064>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# one over the other as the standard for missing values. You can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# easily change this with the following line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillNone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5179\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'fillNone'"
     ]
    }
   ],
   "source": [
    "# Note that missing values are now specified with None instead of\n",
    "# np.nan – Both are fine to handle, but sometimes, you might prefer\n",
    "# one over the other as the standard for missing values. You can\n",
    "# easily change this with the following line\n",
    "df.fillNone(value=np.nan, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_handle</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Corbyn and his friends in Parliament don’t tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Fantastic to address our party faithful at the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>theresa_may</td>\n",
       "      <td>You want this stage of the Brexit process to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>eucopresident</td>\n",
       "      <td>EU27 unanimously agrees on its response to UK’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>I’m deeply honoured to have secured more than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>I’m standing to be Leader of the Conservative ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Jeremy Corbyn wants to cancel the referendum a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Let’s come together and get Brexit done on Oct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Thank you @JSHeappey for the invitation to spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>We must leave the EU on October 31st, with or ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_handle                                         tweet_text\n",
       "0    BorisJohnson  Corbyn and his friends in Parliament don’t tru...\n",
       "1    BorisJohnson  Fantastic to address our party faithful at the...\n",
       "2     theresa_may  You want this stage of the Brexit process to b...\n",
       "3   eucopresident  EU27 unanimously agrees on its response to UK’...\n",
       "4    BorisJohnson  I’m deeply honoured to have secured more than ...\n",
       "..            ...                                                ...\n",
       "91   BorisJohnson  I’m standing to be Leader of the Conservative ...\n",
       "92   BorisJohnson  Jeremy Corbyn wants to cancel the referendum a...\n",
       "93   BorisJohnson  Let’s come together and get Brexit done on Oct...\n",
       "94   BorisJohnson  Thank you @JSHeappey for the invitation to spe...\n",
       "95   BorisJohnson  We must leave the EU on October 31st, with or ...\n",
       "\n",
       "[96 rows x 2 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2) Document-Term Matrices\n",
    "# Let's focus on the tweet_text variable for now, and filter\n",
    "# out all rows without a text. Let's also keep the user handle\n",
    "# so we can later on compare how these four politicians tweet\n",
    "# about the topic.\n",
    "df = df.loc[df['tweet_text'].notnull(), ['user_handle', 'tweet_text']]\n",
    "\n",
    "# Make sure to reset the index to avoid confusion down the line...\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method CountVectorizer.fit_transform of CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)>"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to turn the column 'tweet_text' into a\n",
    "# document-term matrix, we can simply use the sklearn\n",
    "# package that should come pre-installed with your Anaconda\n",
    "# distribution. Either we use the Tfidf or Count Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Let's start with the simple CountVectorizer and create a \n",
    "# DTM using the inbuild tokenizer.\n",
    "\n",
    "# Notice, there is something slightly odd about the name of \n",
    "# this imported thing. Rather than count_vectorizer, it's \n",
    "# spelled CountVectorizer. You can take this as a hint that \n",
    "# you did notimport a specific function, but something slightly\n",
    "# different.\n",
    "# What we imported is a more general object called \"class\", \n",
    "# which is a template for creating new objects that contain\n",
    "# specific attributes and methods (see also the StreamListener \n",
    "# situation in the StreamingAPI script). With this template,\n",
    "# we create a vectorizer object, on which we can now call\n",
    "# certain methods.\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<96x790 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2773 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit_transform returns the DTM in a sparse matrix format\n",
    "# from numpy that is extremely computationally efficient. \n",
    "sparse_dtm = vectorizer.fit_transform(df['tweet_text'])\n",
    "sparse_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0kxjwwsprm</th>\n",
       "      <th>0w7ghgviel</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>16</th>\n",
       "      <th>200</th>\n",
       "      <th>2019</th>\n",
       "      <th>31st</th>\n",
       "      <th>3ke6f1fgx0</th>\n",
       "      <th>...</th>\n",
       "      <th>yet</th>\n",
       "      <th>ygrsfessfy</th>\n",
       "      <th>yorkshire</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yykczinjbv</th>\n",
       "      <th>yzobcftvjd</th>\n",
       "      <th>zgb6dfhbhd</th>\n",
       "      <th>zvudfp7mon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 790 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0kxjwwsprm  0w7ghgviel  10  100  150  16  200  2019  31st  3ke6f1fgx0  \\\n",
       "0            0           0   0    0    0   0    0     0     1           0   \n",
       "1            0           0   0    0    0   0    0     0     0           0   \n",
       "2            0           1   0    0    0   0    0     0     0           0   \n",
       "3            0           0   0    0    0   0    0     0     0           0   \n",
       "4            0           0   0    0    0   0    0     0     0           0   \n",
       "..         ...         ...  ..  ...  ...  ..  ...   ...   ...         ...   \n",
       "91           0           0   0    0    0   0    0     0     0           0   \n",
       "92           0           0   0    0    0   0    0     0     1           0   \n",
       "93           0           0   0    0    0   0    0     0     1           0   \n",
       "94           0           0   0    0    0   0    0     0     0           0   \n",
       "95           0           0   0    0    0   0    0     0     1           0   \n",
       "\n",
       "    ...  yet  ygrsfessfy  yorkshire  you  young  your  yykczinjbv  yzobcftvjd  \\\n",
       "0   ...    0           0          0    1      0     0           0           0   \n",
       "1   ...    0           0          0    0      0     0           0           0   \n",
       "2   ...    0           0          0    1      0     1           0           0   \n",
       "3   ...    0           0          0    0      0     0           0           0   \n",
       "4   ...    0           0          0    1      0     1           0           0   \n",
       "..  ...  ...         ...        ...  ...    ...   ...         ...         ...   \n",
       "91  ...    0           0          0    0      0     1           0           0   \n",
       "92  ...    0           0          0    0      0     0           0           0   \n",
       "93  ...    0           0          0    0      0     0           0           0   \n",
       "94  ...    0           0          0    1      0     1           0           0   \n",
       "95  ...    0           0          0    0      0     0           0           0   \n",
       "\n",
       "    zgb6dfhbhd  zvudfp7mon  \n",
       "0            0           0  \n",
       "1            0           0  \n",
       "2            0           0  \n",
       "3            0           0  \n",
       "4            0           0  \n",
       "..         ...         ...  \n",
       "91           0           0  \n",
       "92           0           0  \n",
       "93           0           0  \n",
       "94           0           0  \n",
       "95           0           0  \n",
       "\n",
       "[96 rows x 790 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But for the sake of illustration, let's turn this into\n",
    "# a nice pandas DataFrame, which works fine with such a\n",
    "# small amount of documents and tokens (or features).\n",
    "tokens = vectorizer.get_feature_names()\n",
    "dtm = pd.DataFrame(data=sparse_dtm.toarray(), \n",
    "                   index=df.index,\n",
    "                   columns=tokens)\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0kxjwwsprm',\n",
       " '0w7ghgviel',\n",
       " '10',\n",
       " '100',\n",
       " '150',\n",
       " '16',\n",
       " '200',\n",
       " '2019',\n",
       " '31st',\n",
       " '3ke6f1fgx0',\n",
       " '3pypnuvpyp',\n",
       " '3vrdupnwhs',\n",
       " '42y3hi5z8p',\n",
       " '4jinkgtzyc',\n",
       " '4lj0whityp',\n",
       " '50',\n",
       " '596iosh01u',\n",
       " '7jydiszdjb',\n",
       " '8000',\n",
       " '8gkvhwud55',\n",
       " '8vbg3jz6dk',\n",
       " '8vcdlajean',\n",
       " '9sdjciimxl',\n",
       " '9vi8oqqjgj',\n",
       " 'aada8qvd1x',\n",
       " 'about',\n",
       " 'accept',\n",
       " 'across',\n",
       " 'address',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'again',\n",
       " 'agenda',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'ahead',\n",
       " 'all',\n",
       " 'also',\n",
       " 'alternatives',\n",
       " 'although',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'amp',\n",
       " 'an',\n",
       " 'and',\n",
       " 'andrejplenkovic',\n",
       " 'another',\n",
       " 'anti',\n",
       " 'anyone',\n",
       " 'appeal',\n",
       " 'approach',\n",
       " 'april',\n",
       " 'are',\n",
       " 'argue',\n",
       " 'around',\n",
       " 'art',\n",
       " 'as',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'aspects',\n",
       " 'at',\n",
       " 'avoid',\n",
       " 'b02wiljds2',\n",
       " 'b3luadnfjw',\n",
       " 'back',\n",
       " 'backboris',\n",
       " 'backing',\n",
       " 'backstop',\n",
       " 'bad',\n",
       " 'ballot',\n",
       " 'basz4qx36s',\n",
       " 'bbi0kc6cdg',\n",
       " 'be',\n",
       " 'become',\n",
       " 'been',\n",
       " 'before',\n",
       " 'begin',\n",
       " 'begins',\n",
       " 'being',\n",
       " 'belfast',\n",
       " 'believe',\n",
       " 'believing',\n",
       " 'benches',\n",
       " 'bennqkfftd',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'bicester',\n",
       " 'big',\n",
       " 'bill',\n",
       " 'birmingham',\n",
       " 'bjugonyyq2',\n",
       " 'bmwsoqn12q',\n",
       " 'bold',\n",
       " 'borisjohnson',\n",
       " 'both',\n",
       " 'bournemouth',\n",
       " 'break',\n",
       " 'brexit',\n",
       " 'brighter',\n",
       " 'bring',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'brussels',\n",
       " 'bsyqxmtzuw',\n",
       " 'bucks',\n",
       " 'build',\n",
       " 'bum39qtizg',\n",
       " 'businesses',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'buts',\n",
       " 'by',\n",
       " 'cabinet',\n",
       " 'call',\n",
       " 'campaign',\n",
       " 'campaignforleo',\n",
       " 'campaigning',\n",
       " 'can',\n",
       " 'cancel',\n",
       " 'candidate',\n",
       " 'candidates',\n",
       " 'cannot',\n",
       " 'capitulation',\n",
       " 'cent',\n",
       " 'champion',\n",
       " 'chance',\n",
       " 'chancellor',\n",
       " 'change',\n",
       " 'check',\n",
       " 'choice',\n",
       " 'chvlb0ului',\n",
       " 'clear',\n",
       " 'close',\n",
       " 'co',\n",
       " 'coldfield',\n",
       " 'colleagues',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'commiserations',\n",
       " 'commit',\n",
       " 'commitment',\n",
       " 'committed',\n",
       " 'commons',\n",
       " 'concrete',\n",
       " 'condoning',\n",
       " 'confidence',\n",
       " 'confirm',\n",
       " 'congratulations',\n",
       " 'consensus',\n",
       " 'conservatism',\n",
       " 'conservative',\n",
       " 'conservatives',\n",
       " 'constant',\n",
       " 'consult',\n",
       " 'consultations',\n",
       " 'consulting',\n",
       " 'contest',\n",
       " 'continue',\n",
       " 'contribution',\n",
       " 'control',\n",
       " 'convention',\n",
       " 'corbyn',\n",
       " 'corbyns',\n",
       " 'could',\n",
       " 'council',\n",
       " 'councillors',\n",
       " 'country',\n",
       " 'counts',\n",
       " 'create',\n",
       " 'creators',\n",
       " 'crime',\n",
       " 'dablu8iqmq',\n",
       " 'date',\n",
       " 'day',\n",
       " 'dctjdo8orp',\n",
       " 'deal',\n",
       " 'decided',\n",
       " 'decision',\n",
       " 'deepening',\n",
       " 'deeply',\n",
       " 'defeat',\n",
       " 'defects',\n",
       " 'delay',\n",
       " 'delayed',\n",
       " 'delays',\n",
       " 'deliver',\n",
       " 'delivered',\n",
       " 'delivering',\n",
       " 'democracy',\n",
       " 'deserve',\n",
       " 'despair',\n",
       " 'determine',\n",
       " 'developments',\n",
       " 'did',\n",
       " 'diet',\n",
       " 'difficult',\n",
       " 'dignified',\n",
       " 'disappointing',\n",
       " 'discover',\n",
       " 'discuss',\n",
       " 'discussing',\n",
       " 'divided',\n",
       " 'do',\n",
       " 'document',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'done',\n",
       " 'down',\n",
       " 'downing',\n",
       " 'dreamers',\n",
       " 'dreaming',\n",
       " 'dreams',\n",
       " 'dublin',\n",
       " 'during',\n",
       " 'dxugrhr6ia',\n",
       " 'e2inihqjtq',\n",
       " 'either',\n",
       " 'elected',\n",
       " 'election',\n",
       " 'elections',\n",
       " 'else',\n",
       " 'emmanuelmacron',\n",
       " 'end',\n",
       " 'energise',\n",
       " 'enhanced',\n",
       " 'entrust',\n",
       " 'eu',\n",
       " 'eu27',\n",
       " 'euco',\n",
       " 'eucopresident',\n",
       " 'europe',\n",
       " 'european',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'events',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'exactly',\n",
       " 'excellent',\n",
       " 'exeter',\n",
       " 'explain',\n",
       " 'extension',\n",
       " 'extraordinary',\n",
       " 'face',\n",
       " 'facts',\n",
       " 'faith',\n",
       " 'faithful',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'fatalism',\n",
       " 'fatigue',\n",
       " 'fgtmhp33vx',\n",
       " 'fgxgdkh0yz',\n",
       " 'fi1meregmz',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'finding',\n",
       " 'finds',\n",
       " 'first',\n",
       " 'fitzmp',\n",
       " 'fixing',\n",
       " 'flat',\n",
       " 'focus',\n",
       " 'focused',\n",
       " 'folks',\n",
       " 'follow',\n",
       " 'following',\n",
       " 'for',\n",
       " 'forced',\n",
       " 'forward',\n",
       " 'fos9ag42ht',\n",
       " 'frail',\n",
       " 'friday',\n",
       " 'friends',\n",
       " 'friendship',\n",
       " 'from',\n",
       " 'full',\n",
       " 'fund',\n",
       " 'further',\n",
       " 'future',\n",
       " 'gavinwilliamson',\n",
       " 'georgefreeman',\n",
       " 'georgefreemanmp',\n",
       " 'get',\n",
       " 'getting',\n",
       " 'gitanasnauseda',\n",
       " 'giuseppeconteit',\n",
       " 'give',\n",
       " 'given',\n",
       " 'giving',\n",
       " 'gjgkvfk8ft',\n",
       " 'global',\n",
       " 'glorious',\n",
       " 'go',\n",
       " 'going',\n",
       " 'good',\n",
       " 'government',\n",
       " 'great',\n",
       " 'greater',\n",
       " 'grybauskaite_lt',\n",
       " 'gt',\n",
       " 'had',\n",
       " 'handed',\n",
       " 'handling',\n",
       " 'happen',\n",
       " 'happening',\n",
       " 'has',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'he',\n",
       " 'head',\n",
       " 'health',\n",
       " 'help',\n",
       " 'her',\n",
       " 'here',\n",
       " 'high',\n",
       " 'his',\n",
       " 'hlyrizpc3i',\n",
       " 'homes',\n",
       " 'honour',\n",
       " 'honoured',\n",
       " 'honours',\n",
       " 'hope',\n",
       " 'hosting',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'housing',\n",
       " 'how',\n",
       " 'https',\n",
       " 'humiliation',\n",
       " 'hundreds',\n",
       " 'hustings',\n",
       " 'i5d4byuram',\n",
       " 'iainastewart',\n",
       " 'if',\n",
       " 'ifs',\n",
       " 'illusory',\n",
       " 'impasse',\n",
       " 'importance',\n",
       " 'important',\n",
       " 'improve',\n",
       " 'improved',\n",
       " 'in',\n",
       " 'increasingly',\n",
       " 'incredible',\n",
       " 'innovation',\n",
       " 'intensifying',\n",
       " 'interest',\n",
       " 'interests',\n",
       " 'into',\n",
       " 'investing',\n",
       " 'invitation',\n",
       " 'involved',\n",
       " 'irz8b0flrk',\n",
       " 'is',\n",
       " 'isle',\n",
       " 'isnpukg1e4',\n",
       " 'issues',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itvdebate',\n",
       " 'jacvrzq5n6',\n",
       " 'jazud0xtgv',\n",
       " 'jeremy',\n",
       " 'jeremy_hunt',\n",
       " 'jj30xepetk',\n",
       " 'job',\n",
       " 'join',\n",
       " 'jsheappey',\n",
       " 'just',\n",
       " 'justified',\n",
       " 'keep',\n",
       " 'key',\n",
       " 'kmec3wvxtj',\n",
       " 'know',\n",
       " 'krisjaniskarins',\n",
       " 'kxoprhodzh',\n",
       " 'l1oqppjbxr',\n",
       " 'labour',\n",
       " 'lasee8iimt',\n",
       " 'last',\n",
       " 'latest',\n",
       " 'launch',\n",
       " 'law',\n",
       " 'laws',\n",
       " 'leader',\n",
       " 'leaders',\n",
       " 'leadership',\n",
       " 'leading',\n",
       " 'least',\n",
       " 'leave',\n",
       " 'leaveoct31',\n",
       " 'leaving',\n",
       " 'less',\n",
       " 'let',\n",
       " 'letsgetthisdone',\n",
       " 'letter',\n",
       " 'likely',\n",
       " 'line',\n",
       " 'lithuania',\n",
       " 'live',\n",
       " 'lives',\n",
       " 'ljs7f2wjug',\n",
       " 'll',\n",
       " 'local',\n",
       " 'london',\n",
       " 'long',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'losing',\n",
       " 'losses',\n",
       " 'lost',\n",
       " 'maidstone',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'manchester',\n",
       " 'many',\n",
       " 'market',\n",
       " 'matter',\n",
       " 'may',\n",
       " 'me',\n",
       " 'means',\n",
       " 'measures',\n",
       " 'meet',\n",
       " 'meeting',\n",
       " 'meetings',\n",
       " 'mega',\n",
       " 'members',\n",
       " 'meps',\n",
       " 'merkel',\n",
       " 'message',\n",
       " 'met',\n",
       " 'midlands',\n",
       " 'miles',\n",
       " 'minds',\n",
       " 'minister',\n",
       " 'minpres',\n",
       " 'missed',\n",
       " 'mkconservatives',\n",
       " 'modern',\n",
       " 'moment',\n",
       " 'more',\n",
       " 'morning',\n",
       " 'move',\n",
       " 'mps',\n",
       " 'much',\n",
       " 'must',\n",
       " 'mv4wre9ao4',\n",
       " 'my',\n",
       " 'n9fqetq25s',\n",
       " 'narrative',\n",
       " 'nation',\n",
       " 'national',\n",
       " 'nations',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'negotiations',\n",
       " 'new',\n",
       " 'news',\n",
       " 'next',\n",
       " 'night',\n",
       " 'nkzii7dx1r',\n",
       " 'no',\n",
       " 'no10',\n",
       " 'not',\n",
       " 'nottinghamshire',\n",
       " 'now',\n",
       " 'oct',\n",
       " 'october',\n",
       " 'of',\n",
       " 'offer',\n",
       " 'olcgggs6x5',\n",
       " 'on',\n",
       " 'one',\n",
       " 'only',\n",
       " 'open',\n",
       " 'opportunities',\n",
       " 'opportunity',\n",
       " 'optimism',\n",
       " 'oqsbd5dvwo',\n",
       " 'or',\n",
       " 'our',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outlined',\n",
       " 'over',\n",
       " 'overwhelmed',\n",
       " 'owerka4ade',\n",
       " 'own',\n",
       " 'package',\n",
       " 'painful',\n",
       " 'paper',\n",
       " 'paris',\n",
       " 'parliament',\n",
       " 'partnership',\n",
       " 'party',\n",
       " 'patient',\n",
       " 'paulbristow79',\n",
       " 'people',\n",
       " 'per',\n",
       " 'peterborough',\n",
       " 'phase',\n",
       " 'phone',\n",
       " 'piikkg4hys',\n",
       " 'plan',\n",
       " 'plans',\n",
       " 'please',\n",
       " 'pledged',\n",
       " 'pm',\n",
       " 'pmcpzlb0wy',\n",
       " 'point',\n",
       " 'policy',\n",
       " 'political',\n",
       " 'politicians',\n",
       " 'politics',\n",
       " 'polls',\n",
       " 'portsmouth',\n",
       " 'positive',\n",
       " 'positivity',\n",
       " 'possible',\n",
       " 'post',\n",
       " 'power',\n",
       " 'powers',\n",
       " 'pragmatic',\n",
       " 'pragmatically',\n",
       " 'prepare',\n",
       " 'preparedness',\n",
       " 'president',\n",
       " 'prime',\n",
       " 'problems',\n",
       " 'process',\n",
       " 'promises',\n",
       " 'proper',\n",
       " 'proposals',\n",
       " 'protect',\n",
       " 'proud',\n",
       " 'public',\n",
       " 'punish',\n",
       " 'put',\n",
       " 'pzbzbd4haj',\n",
       " 'q8tiwdmkch',\n",
       " 'qqooioatoz',\n",
       " 'qri41evzp7',\n",
       " 'qv7blaohw7',\n",
       " 'qxkbc1tbty',\n",
       " 'r184tcluef',\n",
       " 're',\n",
       " 'ready',\n",
       " 'real',\n",
       " 'realistic',\n",
       " 'really',\n",
       " 'receive',\n",
       " 'received',\n",
       " 'receiving',\n",
       " 'reception',\n",
       " 'record',\n",
       " 'referendum',\n",
       " 'region',\n",
       " 'regional',\n",
       " 'rejection',\n",
       " 'remarks',\n",
       " 'remedy',\n",
       " 'repay',\n",
       " 'report',\n",
       " 'represent',\n",
       " 'requesting',\n",
       " 'requests',\n",
       " 'residents',\n",
       " 'resist',\n",
       " 'response',\n",
       " 'restore',\n",
       " 'result',\n",
       " 'results',\n",
       " 'rethink',\n",
       " 'reversed',\n",
       " 'right',\n",
       " 'rights',\n",
       " 'risk',\n",
       " 'rlcppvdmw8',\n",
       " 'role',\n",
       " 'room',\n",
       " 'run',\n",
       " 'running',\n",
       " 'rutte',\n",
       " 'rzt8r1o01i',\n",
       " 'salford',\n",
       " 'same',\n",
       " 'sarecmarjan',\n",
       " 'say',\n",
       " 'sbgyhrhkrk',\n",
       " 'sc6wjdpdkw',\n",
       " 'schools',\n",
       " 'science',\n",
       " 'scqnokprdb',\n",
       " 'sczyb18xcf',\n",
       " 'seats',\n",
       " 'second',\n",
       " 'secured',\n",
       " 'seeking',\n",
       " 'seem',\n",
       " 'seems',\n",
       " 'semitism',\n",
       " 'sensible',\n",
       " 'sensibly',\n",
       " 'service',\n",
       " 'services',\n",
       " 'session',\n",
       " 'set',\n",
       " 'setting',\n",
       " 'shaping',\n",
       " 'shortly',\n",
       " 'shows',\n",
       " 'shropshire',\n",
       " 'sick',\n",
       " 'side',\n",
       " 'sides',\n",
       " 'sign',\n",
       " 'signing',\n",
       " 'simple',\n",
       " 'sincerely',\n",
       " 'situation',\n",
       " 'so',\n",
       " 'society',\n",
       " 'solution',\n",
       " 'some',\n",
       " 'somerset',\n",
       " 'soon',\n",
       " 'speak',\n",
       " 'speaking',\n",
       " 'special',\n",
       " 'spend',\n",
       " 'spending',\n",
       " 'spring',\n",
       " 'stage',\n",
       " 'standing',\n",
       " 'start',\n",
       " 'statement',\n",
       " 'step',\n",
       " 'sticks',\n",
       " 'still',\n",
       " 'stoical',\n",
       " 'stop',\n",
       " 'strategy',\n",
       " 'street',\n",
       " 'strive',\n",
       " 'strong',\n",
       " 'succeed',\n",
       " 'success',\n",
       " 'such',\n",
       " 'suffered',\n",
       " 'suggestion',\n",
       " 'summit',\n",
       " 'support',\n",
       " 'surrenderbill',\n",
       " 'sutton',\n",
       " 'tackling',\n",
       " 'take',\n",
       " 'talk',\n",
       " 'talking',\n",
       " 'talkradio',\n",
       " 'taoiseach',\n",
       " 'taxing',\n",
       " 'taxpayer',\n",
       " 'team',\n",
       " 'ten',\n",
       " 'tendencies',\n",
       " 'tfgkx4slib',\n",
       " 'tgrxu94cmt',\n",
       " 'than',\n",
       " 'thank',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'therefore',\n",
       " 'theresa_may',\n",
       " 'these',\n",
       " 'thesun',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'throughout',\n",
       " 'time',\n",
       " 'times',\n",
       " 'to',\n",
       " 'today',\n",
       " 'together',\n",
       " 'tomorrow',\n",
       " 'tonight',\n",
       " 'too',\n",
       " 'took',\n",
       " 'tories',\n",
       " 'touring',\n",
       " 'track',\n",
       " 'trade',\n",
       " 'tradition',\n",
       " 'trap',\n",
       " 'trust',\n",
       " 'uk',\n",
       " 'unanimously',\n",
       " 'uncertain',\n",
       " 'uncertainty',\n",
       " 'union',\n",
       " 'unions',\n",
       " 'unite',\n",
       " 'united',\n",
       " 'unity',\n",
       " 'until',\n",
       " 'up',\n",
       " 'urgings',\n",
       " 'us',\n",
       " 'use',\n",
       " 'value',\n",
       " 've',\n",
       " 'version',\n",
       " 'very',\n",
       " 'video',\n",
       " 'view',\n",
       " 'visible',\n",
       " 'vision',\n",
       " 'visit',\n",
       " 'vital',\n",
       " 'vote',\n",
       " 'voted',\n",
       " 'voters',\n",
       " 'votes',\n",
       " 'vqh3jx8y2x',\n",
       " 'waiting',\n",
       " 'want',\n",
       " 'wants',\n",
       " 'warned',\n",
       " 'was',\n",
       " 'way',\n",
       " 'we',\n",
       " 'wealth',\n",
       " 'wednesday',\n",
       " 'week',\n",
       " 'weekend',\n",
       " 'well',\n",
       " 'wells',\n",
       " 'west',\n",
       " 'westminster',\n",
       " 'what',\n",
       " 'when',\n",
       " 'whether',\n",
       " 'who',\n",
       " 'whole',\n",
       " 'why',\n",
       " 'wight',\n",
       " 'will',\n",
       " 'willingness',\n",
       " 'win',\n",
       " 'with',\n",
       " 'withdrawal',\n",
       " 'without',\n",
       " 'wmxg40xrkl',\n",
       " 'work',\n",
       " 'workers',\n",
       " 'working',\n",
       " 'works',\n",
       " 'worse',\n",
       " 'written',\n",
       " 'wtvqqryyvq',\n",
       " 'x9hfkop0qu',\n",
       " 'years',\n",
       " 'yesterday',\n",
       " 'yet',\n",
       " 'ygrsfessfy',\n",
       " 'yorkshire',\n",
       " 'you',\n",
       " 'young',\n",
       " 'your',\n",
       " 'yykczinjbv',\n",
       " 'yzobcftvjd',\n",
       " 'zgb6dfhbhd',\n",
       " 'zvudfp7mon']"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So, this DTM has 96 rows (documents, in this case Tweets),\n",
    "# and 790 columns (features/tokens/variables). The CountVectorizer\n",
    "# looks at all the unique tokens it can find across all the\n",
    "# documents. It automatically uses a very simple tokenizer\n",
    "# for this. Check out the documentation to see whether you\n",
    "# can find out how its tokenizer splits texts into individual\n",
    "# tokens. Let's look at the outcome, and see whether we can\n",
    "# improve on this crude first take:\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3) Pre-Processing: Tokenizing, Removing-Stuff, Stemming\n",
    "# As we can see, there is a bunch of weird stuff in there, and\n",
    "# some tokens should be counted as one, which we can achieve\n",
    "# by pre-processing techniques like stemming (getting rid of\n",
    "# suffixes etc.). \n",
    "\n",
    "# There are many different packages to do this, and I hope\n",
    "# that Jurafsky and Martin convinced you that there are \n",
    "# different computational approaches to pre-processing, most\n",
    "# of which will give you different results. For this session,\n",
    "# we will stick to a collection of tools provided by the \n",
    "# NLTK (Natural Language Tool Kit) package. This is kind of\n",
    "# a hub of different techniques that comes in handy. Besides\n",
    "# installing nltk via pip (google \"install nltk package Windows/Mac\"),\n",
    "# you will als need to download individual packages. There\n",
    "# are two ways to do so. Either you try to run the code, and\n",
    "# let NLTK tell you which things you need to download to\n",
    "# run a specific functionality (the error messages will\n",
    "# provide precise instructions), or you just install all\n",
    "# of their functionalities at once via the command line \n",
    "# interface. I prefer the latter, but be aware that this\n",
    "# requires up to 4GB storage space on your computer. \n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Corbyn and his friends in Parliament don’t trust you to make this decision - but I do. Let’s put it to the people: more delay with Corbyn’s #SurrenderBill, or Brexit delivered on October 31st ???? https://t.co/q8tIwDMkcH'"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do all the pre-processing on a single tweet first,\n",
    "# so we can have a look at the individual changes as they\n",
    "# happen to the text.\n",
    "tweet = df.loc[0, 'tweet_text']\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Corbyn',\n",
       " 'and',\n",
       " 'his',\n",
       " 'friends',\n",
       " 'in',\n",
       " 'Parliament',\n",
       " 'don’t',\n",
       " 'trust',\n",
       " 'you',\n",
       " 'to',\n",
       " 'make',\n",
       " 'this',\n",
       " 'decision',\n",
       " '-',\n",
       " 'but',\n",
       " 'I',\n",
       " 'do.',\n",
       " 'Let’s',\n",
       " 'put',\n",
       " 'it',\n",
       " 'to',\n",
       " 'the',\n",
       " 'people:',\n",
       " 'more',\n",
       " 'delay',\n",
       " 'with',\n",
       " 'Corbyn’s',\n",
       " '#SurrenderBill,',\n",
       " 'or',\n",
       " 'Brexit',\n",
       " 'delivered',\n",
       " 'on',\n",
       " 'October',\n",
       " '31st',\n",
       " '????',\n",
       " 'https://t.co/q8tIwDMkcH']"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [3a] Tokenizing\n",
    "# The most simple way to tokenize a given text is to use the \n",
    "# python-internal string function split(), which we can\n",
    "# call on a given string object. It simply splits the string\n",
    "# into individual tokens at every whitespace it encounters.\n",
    "tokens = tweet.split()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Corbyn',\n",
       " 'and',\n",
       " 'his',\n",
       " 'friends',\n",
       " 'in',\n",
       " 'Parliament',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'trust',\n",
       " 'you',\n",
       " 'to',\n",
       " 'make',\n",
       " 'this',\n",
       " 'decision',\n",
       " '-',\n",
       " 'but',\n",
       " 'I',\n",
       " 'do',\n",
       " '.',\n",
       " 'Let',\n",
       " '’',\n",
       " 's',\n",
       " 'put',\n",
       " 'it',\n",
       " 'to',\n",
       " 'the',\n",
       " 'people',\n",
       " ':',\n",
       " 'more',\n",
       " 'delay',\n",
       " 'with',\n",
       " 'Corbyn',\n",
       " '’',\n",
       " 's',\n",
       " '#',\n",
       " 'SurrenderBill',\n",
       " ',',\n",
       " 'or',\n",
       " 'Brexit',\n",
       " 'delivered',\n",
       " 'on',\n",
       " 'October',\n",
       " '31st',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " 'https',\n",
       " ':',\n",
       " '//t.co/q8tIwDMkcH']"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is a bunch of problems with this, which have\n",
    "# to do with the punctuation that is directly linked\n",
    "# to a word and not separated by whitespace. Plenty\n",
    "# of people have worked to solve such issues, and the\n",
    "# easy-to-use alternative that you see the most is\n",
    "# the word_tokenize function from NLTK. Let's import it:\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(tweet)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Corbyn',\n",
       " 'and',\n",
       " 'his',\n",
       " 'friends',\n",
       " 'in',\n",
       " 'Parliament',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'trust',\n",
       " 'you',\n",
       " 'to',\n",
       " 'make',\n",
       " 'this',\n",
       " 'decision',\n",
       " '-',\n",
       " 'but',\n",
       " 'I',\n",
       " 'do',\n",
       " '.',\n",
       " 'Let',\n",
       " '’',\n",
       " 's',\n",
       " 'put',\n",
       " 'it',\n",
       " 'to',\n",
       " 'the',\n",
       " 'people',\n",
       " ':',\n",
       " 'more',\n",
       " 'delay',\n",
       " 'with',\n",
       " 'Corbyn',\n",
       " '’',\n",
       " 's',\n",
       " '#SurrenderBill',\n",
       " ',',\n",
       " 'or',\n",
       " 'Brexit',\n",
       " 'delivered',\n",
       " 'on',\n",
       " 'October',\n",
       " '31st',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " 'https://t.co/q8tIwDMkcH']"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This looks slightly better in that it recognized more\n",
    "# common English language style separation of two words\n",
    "# like in \"don't\" = \"do not\" – However, it also has a \n",
    "# weird understanding of URLs and separated the hashtag\n",
    "# from the word in #SurrenderBill. We might want to \n",
    "# keep this as the hashtag is part of the tokens underlying\n",
    "# meaning in Twitter communication.\n",
    "\n",
    "# In order to find out whether there is a tokenizer \n",
    "# more appropriate for our context, we can have a look\n",
    "# at the documentation of the nltk tokenize section\n",
    "# https://www.nltk.org/api/nltk.tokenize.html \n",
    "\n",
    "# And voilà, there is a tokenizer specifically \n",
    "# developped for parsing tweets. Again, we can import the\n",
    "# general class, create an instance of this class, and\n",
    "# then call certain methods from this instance.\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "tokens = tokenizer.tokenize(tweet)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corbyn',\n",
       " 'and',\n",
       " 'his',\n",
       " 'friends',\n",
       " 'in',\n",
       " 'parliament',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'trust',\n",
       " 'you',\n",
       " 'to',\n",
       " 'make',\n",
       " 'this',\n",
       " 'decision',\n",
       " '-',\n",
       " 'but',\n",
       " 'i',\n",
       " 'do',\n",
       " '.',\n",
       " 'let',\n",
       " '’',\n",
       " 's',\n",
       " 'put',\n",
       " 'it',\n",
       " 'to',\n",
       " 'the',\n",
       " 'people',\n",
       " ':',\n",
       " 'more',\n",
       " 'delay',\n",
       " 'with',\n",
       " 'corbyn',\n",
       " '’',\n",
       " 's',\n",
       " '#surrenderbill',\n",
       " ',',\n",
       " 'or',\n",
       " 'brexit',\n",
       " 'delivered',\n",
       " 'on',\n",
       " 'october',\n",
       " '31st',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " 'https://t.co/q8tiwdmkch']"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [3b] Lowercasing\n",
    "# Now that we have individual tokens, we can easilyapply more \n",
    "# pre-processing techniques to each token with list-comprehension.\n",
    "# Turning every character to lowercasing is super easy in python,\n",
    "# and uncontroversial for once.\n",
    "tokens = [word.lower() for word in tokens]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [3c] Punctuation Removal\n",
    "# There are a bunch of approaches to this, but let's\n",
    "# use the string package, which has a lot of other\n",
    "# cool features\n",
    "import string\n",
    "\n",
    "# It contains a list of the most common punctuation \n",
    "# characters\n",
    "punct = string.punctuation\n",
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem is that this list contains the # symbol,\n",
    "# which we do want to keep, so let's replace this\n",
    "punct = punct.replace(\"#\", \"\")\n",
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corbyn',\n",
       " 'and',\n",
       " 'his',\n",
       " 'friends',\n",
       " 'in',\n",
       " 'parliament',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'trust',\n",
       " 'you',\n",
       " 'to',\n",
       " 'make',\n",
       " 'this',\n",
       " 'decision',\n",
       " 'but',\n",
       " 'i',\n",
       " 'do',\n",
       " 'let',\n",
       " '’',\n",
       " 's',\n",
       " 'put',\n",
       " 'it',\n",
       " 'to',\n",
       " 'the',\n",
       " 'people',\n",
       " 'more',\n",
       " 'delay',\n",
       " 'with',\n",
       " 'corbyn',\n",
       " '’',\n",
       " 's',\n",
       " '#surrenderbill',\n",
       " 'or',\n",
       " 'brexit',\n",
       " 'delivered',\n",
       " 'on',\n",
       " 'october',\n",
       " '31st',\n",
       " 'https://t.co/q8tiwdmkch']"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we can use list comprehension to drop all\n",
    "# the punctuation tokens in our list of tokens\n",
    "tokens = [word for word in tokens if word not in punct]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~’'"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we see, this didn't remove the ’ – let's just add it to punct,\n",
    "# and repeat the process\n",
    "punct = punct + \"’\"\n",
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corbyn',\n",
       " 'and',\n",
       " 'his',\n",
       " 'friends',\n",
       " 'in',\n",
       " 'parliament',\n",
       " 'don',\n",
       " 't',\n",
       " 'trust',\n",
       " 'you',\n",
       " 'to',\n",
       " 'make',\n",
       " 'this',\n",
       " 'decision',\n",
       " 'but',\n",
       " 'i',\n",
       " 'do',\n",
       " 'let',\n",
       " 's',\n",
       " 'put',\n",
       " 'it',\n",
       " 'to',\n",
       " 'the',\n",
       " 'people',\n",
       " 'more',\n",
       " 'delay',\n",
       " 'with',\n",
       " 'corbyn',\n",
       " 's',\n",
       " '#surrenderbill',\n",
       " 'or',\n",
       " 'brexit',\n",
       " 'delivered',\n",
       " 'on',\n",
       " 'october',\n",
       " '31st',\n",
       " 'https://t.co/q8tiwdmkch']"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we are left with only alphanumerical characters\n",
    "# and we managed to not throw away the hashtag sign.\n",
    "# in the process.\n",
    "tokens = [word for word in tokens if word not in punct]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corbyn',\n",
       " 'and',\n",
       " 'his',\n",
       " 'friends',\n",
       " 'in',\n",
       " 'parliament',\n",
       " 'don',\n",
       " 't',\n",
       " 'trust',\n",
       " 'you',\n",
       " 'to',\n",
       " 'make',\n",
       " 'this',\n",
       " 'decision',\n",
       " 'but',\n",
       " 'i',\n",
       " 'do',\n",
       " 'let',\n",
       " 's',\n",
       " 'put',\n",
       " 'it',\n",
       " 'to',\n",
       " 'the',\n",
       " 'people',\n",
       " 'more',\n",
       " 'delay',\n",
       " 'with',\n",
       " 'corbyn',\n",
       " 's',\n",
       " '#surrenderbill',\n",
       " 'or',\n",
       " 'brexit',\n",
       " 'delivered',\n",
       " 'on',\n",
       " 'october',\n",
       " '31st',\n",
       " 'https://t.co/q8tiwdmkch']"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [3d] Number Removal\n",
    "# If we just want to remove pure numbers, the task is easy. \n",
    "tokens = [w for w in tokens if not w.isdigit()]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this case, it does not do anything because there are no\n",
    "# strings that only consists of digits. But we do have \"31st\"\n",
    "# which we might want to remove (remember, this is similar to \n",
    "# \"Article50\" and might therefore be useful to keep). But let's\n",
    "# try to get rid of it nevertheless.\n",
    "\"31st\".isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this case, we could specify for example a for loop that \n",
    "# checks whether any of the characters in a given string is\n",
    "# a digit.\n",
    "any(char.isdigit() for char in \"31st\")\n",
    "\n",
    "# We could insert that into list comprehension, but let's \n",
    "# leave it to keep stuff like #RevokeArticle50, which\n",
    "# might be important in the context of Brexit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [3e] Stopword Removal\n",
    "# There are many different stopwords lists that contain\n",
    "# words conventionally thought of as carrying little \n",
    "# meaning. You should always inspect the stopwords lists\n",
    "# you use to ensure that it does not accidently delete\n",
    "# things that matter in your context. Let's look at the \n",
    "# NLTK standard stoplist for English.\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corbyn',\n",
       " 'friends',\n",
       " 'parliament',\n",
       " 'trust',\n",
       " 'make',\n",
       " 'decision',\n",
       " 'let',\n",
       " 'put',\n",
       " 'people',\n",
       " 'delay',\n",
       " 'corbyn',\n",
       " '#surrenderbill',\n",
       " 'brexit',\n",
       " 'delivered',\n",
       " 'october',\n",
       " '31st',\n",
       " 'https://t.co/q8tiwdmkch']"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This looks fine to me, so let's get rid of all of these\n",
    "# words in our list of tokens. \n",
    "tokens = [w for w in tokens if not w in stop_words]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corbyn',\n",
       " 'friend',\n",
       " 'parliament',\n",
       " 'trust',\n",
       " 'make',\n",
       " 'decis',\n",
       " 'let',\n",
       " 'put',\n",
       " 'peopl',\n",
       " 'delay',\n",
       " 'corbyn',\n",
       " '#surrenderbil',\n",
       " 'brexit',\n",
       " 'deliv',\n",
       " 'octob',\n",
       " '31st',\n",
       " 'https://t.co/q8tiwdmkch']"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [3f] Stemming\n",
    "# Finally, let's stem the leftovers and thereby\n",
    "# get rid of all the suffixes and stuff. The \n",
    "# Porter Stemmer is one of the most widely used.\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "tokens_porter = [stemmer.stem(w) for w in tokens]\n",
    "tokens_porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corbyn',\n",
       " 'friend',\n",
       " 'parliament',\n",
       " 'trust',\n",
       " 'make',\n",
       " 'decis',\n",
       " 'let',\n",
       " 'put',\n",
       " 'peopl',\n",
       " 'delay',\n",
       " 'corbyn',\n",
       " '#surrenderbil',\n",
       " 'brexit',\n",
       " 'deliv',\n",
       " 'octob',\n",
       " '31st',\n",
       " 'https://t.co/q8tiwdmkch']"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another widespread one is the SnowballStemmer,\n",
    "# which is also available in some different languages,\n",
    "# which might come in handy if you want to keep\n",
    "# pre-processing fairly similar across different\n",
    "# languages in your texts.\n",
    "from nltk import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "tokens_snowball = [stemmer.stem(w) for w in tokens]\n",
    "tokens_snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corbyn',\n",
       " 'friend',\n",
       " 'parliament',\n",
       " 'trust',\n",
       " 'make',\n",
       " 'decis',\n",
       " 'let',\n",
       " 'put',\n",
       " 'peopl',\n",
       " 'delay',\n",
       " 'corbyn',\n",
       " '#surrenderbil',\n",
       " 'brexit',\n",
       " 'deliv',\n",
       " 'octob',\n",
       " '31st']"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [3g] URL removal\n",
    "# We can simply drop everything that contains \"https://\"\n",
    "tokens = [word for word in tokens_porter if not \"https://\" in word]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_handle</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Corbyn and his friends in Parliament don’t tru...</td>\n",
       "      <td>Corbyn and his friends in Parliament don’t tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Fantastic to address our party faithful at the...</td>\n",
       "      <td>Fantastic to address our party faithful at the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>theresa_may</td>\n",
       "      <td>You want this stage of the Brexit process to b...</td>\n",
       "      <td>You want this stage of the Brexit process to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>eucopresident</td>\n",
       "      <td>EU27 unanimously agrees on its response to UK’...</td>\n",
       "      <td>EU27 unanimously agrees on its response to UK’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>I’m deeply honoured to have secured more than ...</td>\n",
       "      <td>I’m deeply honoured to have secured more than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>I’m standing to be Leader of the Conservative ...</td>\n",
       "      <td>I’m standing to be Leader of the Conservative ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Jeremy Corbyn wants to cancel the referendum a...</td>\n",
       "      <td>Jeremy Corbyn wants to cancel the referendum a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Let’s come together and get Brexit done on Oct...</td>\n",
       "      <td>Let’s come together and get Brexit done on Oct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Thank you @JSHeappey for the invitation to spe...</td>\n",
       "      <td>Thank you @JSHeappey for the invitation to spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>We must leave the EU on October 31st, with or ...</td>\n",
       "      <td>We must leave the EU on October 31st, with or ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_handle                                         tweet_text  \\\n",
       "0    BorisJohnson  Corbyn and his friends in Parliament don’t tru...   \n",
       "1    BorisJohnson  Fantastic to address our party faithful at the...   \n",
       "2     theresa_may  You want this stage of the Brexit process to b...   \n",
       "3   eucopresident  EU27 unanimously agrees on its response to UK’...   \n",
       "4    BorisJohnson  I’m deeply honoured to have secured more than ...   \n",
       "..            ...                                                ...   \n",
       "91   BorisJohnson  I’m standing to be Leader of the Conservative ...   \n",
       "92   BorisJohnson  Jeremy Corbyn wants to cancel the referendum a...   \n",
       "93   BorisJohnson  Let’s come together and get Brexit done on Oct...   \n",
       "94   BorisJohnson  Thank you @JSHeappey for the invitation to spe...   \n",
       "95   BorisJohnson  We must leave the EU on October 31st, with or ...   \n",
       "\n",
       "                                            processed  \n",
       "0   Corbyn and his friends in Parliament don’t tru...  \n",
       "1   Fantastic to address our party faithful at the...  \n",
       "2   You want this stage of the Brexit process to b...  \n",
       "3   EU27 unanimously agrees on its response to UK’...  \n",
       "4   I’m deeply honoured to have secured more than ...  \n",
       "..                                                ...  \n",
       "91  I’m standing to be Leader of the Conservative ...  \n",
       "92  Jeremy Corbyn wants to cancel the referendum a...  \n",
       "93  Let’s come together and get Brexit done on Oct...  \n",
       "94  Thank you @JSHeappey for the invitation to spe...  \n",
       "95  We must leave the EU on October 31st, with or ...  \n",
       "\n",
       "[96 rows x 3 columns]"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we can see in this case, the different stemmers return\n",
    "# the same result. But remember to double-check with different\n",
    "# tweets and keep in mind that this is one parameter you can \n",
    "# change in your analysis. \n",
    "\n",
    "# Let's write a loop that applies all of this to each tweet \n",
    "# in the dataframe and creates a new 'processed' variable. \n",
    "# that we can turn into a DTM now. Let's create a new variable\n",
    "# to make sure that we don't loose the original text\n",
    "df['processed'] = df['tweet_text']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_handle</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Corbyn and his friends in Parliament don’t tru...</td>\n",
       "      <td>corbyn friend parliament trust make decis let ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Fantastic to address our party faithful at the...</td>\n",
       "      <td>fantast address parti faith nation conserv con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>theresa_may</td>\n",
       "      <td>You want this stage of the Brexit process to b...</td>\n",
       "      <td>want stage brexit process done agre side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>eucopresident</td>\n",
       "      <td>EU27 unanimously agrees on its response to UK’...</td>\n",
       "      <td>eu27 unanim agre respons uk request meet pm @t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>I’m deeply honoured to have secured more than ...</td>\n",
       "      <td>deepli honour secur per cent vote final ballot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>I’m standing to be Leader of the Conservative ...</td>\n",
       "      <td>stand leader conserv parti deliv proper brexit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Jeremy Corbyn wants to cancel the referendum a...</td>\n",
       "      <td>jeremi corbyn want cancel referendum argu brex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Let’s come together and get Brexit done on Oct...</td>\n",
       "      <td>let come togeth get brexit done octob 31st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Thank you @JSHeappey for the invitation to spe...</td>\n",
       "      <td>thank @jsheappey invit speak fantast member we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>We must leave the EU on October 31st, with or ...</td>\n",
       "      <td>must leav eu octob 31st without deal begin uni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_handle                                         tweet_text  \\\n",
       "0    BorisJohnson  Corbyn and his friends in Parliament don’t tru...   \n",
       "1    BorisJohnson  Fantastic to address our party faithful at the...   \n",
       "2     theresa_may  You want this stage of the Brexit process to b...   \n",
       "3   eucopresident  EU27 unanimously agrees on its response to UK’...   \n",
       "4    BorisJohnson  I’m deeply honoured to have secured more than ...   \n",
       "..            ...                                                ...   \n",
       "91   BorisJohnson  I’m standing to be Leader of the Conservative ...   \n",
       "92   BorisJohnson  Jeremy Corbyn wants to cancel the referendum a...   \n",
       "93   BorisJohnson  Let’s come together and get Brexit done on Oct...   \n",
       "94   BorisJohnson  Thank you @JSHeappey for the invitation to spe...   \n",
       "95   BorisJohnson  We must leave the EU on October 31st, with or ...   \n",
       "\n",
       "                                            processed  \n",
       "0   corbyn friend parliament trust make decis let ...  \n",
       "1   fantast address parti faith nation conserv con...  \n",
       "2            want stage brexit process done agre side  \n",
       "3   eu27 unanim agre respons uk request meet pm @t...  \n",
       "4   deepli honour secur per cent vote final ballot...  \n",
       "..                                                ...  \n",
       "91  stand leader conserv parti deliv proper brexit...  \n",
       "92  jeremi corbyn want cancel referendum argu brex...  \n",
       "93         let come togeth get brexit done octob 31st  \n",
       "94  thank @jsheappey invit speak fantast member we...  \n",
       "95  must leav eu octob 31st without deal begin uni...  \n",
       "\n",
       "[96 rows x 3 columns]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's pre-process all of these tweets in order to \n",
    "# make our DTM conceptually more valid.\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "import string\n",
    "punct = string.punctuation\n",
    "punct = punct.replace(\"#\", \"\")\n",
    "punct = punct + \"’\"\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for ix in range(0, len(df)):\n",
    "    tweet = df.loc[ix, \"tweet_text\"]\n",
    "    \n",
    "    # TweetTokenizer\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    \n",
    "    # Punctuation Removal\n",
    "    tokens = [word for word in tokens if word not in punct]\n",
    "    \n",
    "    # Number removal\n",
    "    tokens = [word for word in tokens if not word.isdigit()]\n",
    "    \n",
    "    # Stopword removal\n",
    "    tokens = [word for word in tokens if not word in stop_words]\n",
    "    \n",
    "    # Stemming (Porter)\n",
    "    tokens = [porter.stem(w) for w in tokens]\n",
    "    \n",
    "    # URL removal\n",
    "    tokens = [word for word in tokens if not \"https://\" in word]\n",
    "    \n",
    "    # In order to put this back into a single cell that can\n",
    "    # be put into the CountVectorizer, we can use the .join()\n",
    "    # method to put all individual strings back together, \n",
    "    # separated by whitespace.\n",
    "    tweet = \" \".join(tokens)\n",
    "    \n",
    "    # now save it into the \"processed\" column\n",
    "    df.loc[ix, \"processed\"] = tweet\n",
    "\n",
    "# Let's look at the outcome...\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<96x532 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1574 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use the processed variable to create a new DTM\n",
    "# that is cleaner than the one with the un-processed \n",
    "# Twitter texts.\n",
    "sparse_dtm = vectorizer.fit_transform(df['processed'])\n",
    "sparse_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['31st',\n",
       " 'accept',\n",
       " 'across',\n",
       " 'address',\n",
       " 'afternoon',\n",
       " 'agenda',\n",
       " 'agre',\n",
       " 'agreement',\n",
       " 'ahead',\n",
       " 'also',\n",
       " 'altern',\n",
       " 'although',\n",
       " 'altogeth',\n",
       " 'alway',\n",
       " 'amaz',\n",
       " 'andrejplenkov',\n",
       " 'anoth',\n",
       " 'anti',\n",
       " 'anyon',\n",
       " 'appeal',\n",
       " 'approach',\n",
       " 'april',\n",
       " 'argu',\n",
       " 'around',\n",
       " 'art',\n",
       " 'ask',\n",
       " 'aspect',\n",
       " 'avoid',\n",
       " 'back',\n",
       " 'backbori',\n",
       " 'backstop',\n",
       " 'bad',\n",
       " 'ballot',\n",
       " 'becom',\n",
       " 'begin',\n",
       " 'belfast',\n",
       " 'believ',\n",
       " 'bench',\n",
       " 'best',\n",
       " 'better',\n",
       " 'beyond',\n",
       " 'bicest',\n",
       " 'big',\n",
       " 'bill',\n",
       " 'birmingham',\n",
       " 'bold',\n",
       " 'borisjohnson',\n",
       " 'bournemouth',\n",
       " 'break',\n",
       " 'brexit',\n",
       " 'brighter',\n",
       " 'bring',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'brussel',\n",
       " 'buck',\n",
       " 'build',\n",
       " 'busi',\n",
       " 'but',\n",
       " 'cabinet',\n",
       " 'call',\n",
       " 'campaign',\n",
       " 'campaignforleo',\n",
       " 'cancel',\n",
       " 'candid',\n",
       " 'cannot',\n",
       " 'capitul',\n",
       " 'cent',\n",
       " 'champion',\n",
       " 'chanc',\n",
       " 'chancellor',\n",
       " 'chang',\n",
       " 'check',\n",
       " 'choic',\n",
       " 'clear',\n",
       " 'close',\n",
       " 'coldfield',\n",
       " 'colleagu',\n",
       " 'come',\n",
       " 'commiser',\n",
       " 'commit',\n",
       " 'common',\n",
       " 'concret',\n",
       " 'condon',\n",
       " 'confid',\n",
       " 'confirm',\n",
       " 'congratul',\n",
       " 'consensu',\n",
       " 'conserv',\n",
       " 'conservat',\n",
       " 'constant',\n",
       " 'consult',\n",
       " 'contest',\n",
       " 'continu',\n",
       " 'contribut',\n",
       " 'control',\n",
       " 'convent',\n",
       " 'corbyn',\n",
       " 'could',\n",
       " 'council',\n",
       " 'councillor',\n",
       " 'count',\n",
       " 'countri',\n",
       " 'creat',\n",
       " 'creator',\n",
       " 'crime',\n",
       " 'date',\n",
       " 'day',\n",
       " 'deal',\n",
       " 'decid',\n",
       " 'decis',\n",
       " 'deepen',\n",
       " 'deepli',\n",
       " 'defeat',\n",
       " 'defect',\n",
       " 'delay',\n",
       " 'deliv',\n",
       " 'democraci',\n",
       " 'deserv',\n",
       " 'despair',\n",
       " 'determin',\n",
       " 'develop',\n",
       " 'diet',\n",
       " 'difficult',\n",
       " 'dignifi',\n",
       " 'disappoint',\n",
       " 'discov',\n",
       " 'discuss',\n",
       " 'divid',\n",
       " 'document',\n",
       " 'done',\n",
       " 'down',\n",
       " 'dream',\n",
       " 'dreamer',\n",
       " 'dublin',\n",
       " 'either',\n",
       " 'elect',\n",
       " 'els',\n",
       " 'emmanuelmacron',\n",
       " 'end',\n",
       " 'energis',\n",
       " 'enhanc',\n",
       " 'entrust',\n",
       " 'eu',\n",
       " 'eu27',\n",
       " 'euco',\n",
       " 'eucopresid',\n",
       " 'europ',\n",
       " 'european',\n",
       " 'even',\n",
       " 'event',\n",
       " 'ever',\n",
       " 'everi',\n",
       " 'everyon',\n",
       " 'exactli',\n",
       " 'excel',\n",
       " 'exet',\n",
       " 'explain',\n",
       " 'extens',\n",
       " 'extraordinari',\n",
       " 'face',\n",
       " 'fact',\n",
       " 'faith',\n",
       " 'fantast',\n",
       " 'far',\n",
       " 'fatal',\n",
       " 'fatigu',\n",
       " 'final',\n",
       " 'find',\n",
       " 'first',\n",
       " 'fitzmp',\n",
       " 'fix',\n",
       " 'flat',\n",
       " 'focu',\n",
       " 'focus',\n",
       " 'folk',\n",
       " 'follow',\n",
       " 'forc',\n",
       " 'forward',\n",
       " 'frail',\n",
       " 'friday',\n",
       " 'friend',\n",
       " 'friendship',\n",
       " 'full',\n",
       " 'fund',\n",
       " 'futur',\n",
       " 'gavinwilliamson',\n",
       " 'georgefreeman',\n",
       " 'georgefreemanmp',\n",
       " 'get',\n",
       " 'gitanasnauseda',\n",
       " 'giuseppeconteit',\n",
       " 'give',\n",
       " 'given',\n",
       " 'global',\n",
       " 'gloriou',\n",
       " 'go',\n",
       " 'good',\n",
       " 'govern',\n",
       " 'government',\n",
       " 'great',\n",
       " 'greater',\n",
       " 'grybauskaite_lt',\n",
       " 'hand',\n",
       " 'handl',\n",
       " 'happen',\n",
       " 'head',\n",
       " 'health',\n",
       " 'help',\n",
       " 'high',\n",
       " 'home',\n",
       " 'honour',\n",
       " 'hope',\n",
       " 'host',\n",
       " 'hour',\n",
       " 'hous',\n",
       " 'humili',\n",
       " 'hundr',\n",
       " 'hust',\n",
       " 'iainastewart',\n",
       " 'if',\n",
       " 'illusori',\n",
       " 'impass',\n",
       " 'import',\n",
       " 'improv',\n",
       " 'increasingli',\n",
       " 'incred',\n",
       " 'innov',\n",
       " 'intensifi',\n",
       " 'interest',\n",
       " 'invest',\n",
       " 'invit',\n",
       " 'involv',\n",
       " 'isl',\n",
       " 'issu',\n",
       " 'itvdeb',\n",
       " 'jeremi',\n",
       " 'jeremy_hunt',\n",
       " 'job',\n",
       " 'join',\n",
       " 'jsheappey',\n",
       " 'justifi',\n",
       " 'keep',\n",
       " 'key',\n",
       " 'know',\n",
       " 'krisjaniskarin',\n",
       " 'labour',\n",
       " 'last',\n",
       " 'latest',\n",
       " 'launch',\n",
       " 'law',\n",
       " 'lead',\n",
       " 'leader',\n",
       " 'leadership',\n",
       " 'least',\n",
       " 'leav',\n",
       " 'leaveoct31',\n",
       " 'less',\n",
       " 'let',\n",
       " 'letsgetthisdon',\n",
       " 'letter',\n",
       " 'like',\n",
       " 'line',\n",
       " 'lithuania',\n",
       " 'live',\n",
       " 'll',\n",
       " 'local',\n",
       " 'london',\n",
       " 'long',\n",
       " 'look',\n",
       " 'lose',\n",
       " 'loss',\n",
       " 'lost',\n",
       " 'maidston',\n",
       " 'make',\n",
       " 'manchest',\n",
       " 'mani',\n",
       " 'market',\n",
       " 'matter',\n",
       " 'may',\n",
       " 'mean',\n",
       " 'measur',\n",
       " 'meet',\n",
       " 'mega',\n",
       " 'member',\n",
       " 'mep',\n",
       " 'merkel',\n",
       " 'messag',\n",
       " 'met',\n",
       " 'midland',\n",
       " 'mile',\n",
       " 'mind',\n",
       " 'minist',\n",
       " 'minpr',\n",
       " 'miss',\n",
       " 'mkconserv',\n",
       " 'modern',\n",
       " 'moment',\n",
       " 'morn',\n",
       " 'move',\n",
       " 'mp',\n",
       " 'much',\n",
       " 'must',\n",
       " 'narr',\n",
       " 'nation',\n",
       " 'necessari',\n",
       " 'need',\n",
       " 'negoti',\n",
       " 'new',\n",
       " 'news',\n",
       " 'next',\n",
       " 'night',\n",
       " 'no',\n",
       " 'no10',\n",
       " 'nottinghamshir',\n",
       " 'oct',\n",
       " 'octob',\n",
       " 'offer',\n",
       " 'one',\n",
       " 'open',\n",
       " 'opportun',\n",
       " 'optim',\n",
       " 'outlin',\n",
       " 'overwhelm',\n",
       " 'packag',\n",
       " 'pain',\n",
       " 'paper',\n",
       " 'pari',\n",
       " 'parliament',\n",
       " 'parti',\n",
       " 'partnership',\n",
       " 'patient',\n",
       " 'paulbristow79',\n",
       " 'peopl',\n",
       " 'per',\n",
       " 'peterborough',\n",
       " 'phase',\n",
       " 'phone',\n",
       " 'plan',\n",
       " 'pleas',\n",
       " 'pledg',\n",
       " 'pm',\n",
       " 'point',\n",
       " 'polici',\n",
       " 'polit',\n",
       " 'politician',\n",
       " 'poll',\n",
       " 'portsmouth',\n",
       " 'posit',\n",
       " 'possibl',\n",
       " 'post',\n",
       " 'power',\n",
       " 'pragmat',\n",
       " 'prepar',\n",
       " 'prepared',\n",
       " 'presid',\n",
       " 'prime',\n",
       " 'problem',\n",
       " 'process',\n",
       " 'promis',\n",
       " 'proper',\n",
       " 'propos',\n",
       " 'protect',\n",
       " 'proud',\n",
       " 'public',\n",
       " 'punish',\n",
       " 'put',\n",
       " 'readi',\n",
       " 'real',\n",
       " 'realist',\n",
       " 'realli',\n",
       " 'receiv',\n",
       " 'recept',\n",
       " 'record',\n",
       " 'referendum',\n",
       " 'region',\n",
       " 'reject',\n",
       " 'remark',\n",
       " 'remedi',\n",
       " 'repay',\n",
       " 'report',\n",
       " 'repres',\n",
       " 'request',\n",
       " 'resid',\n",
       " 'resist',\n",
       " 'respons',\n",
       " 'restor',\n",
       " 'result',\n",
       " 'rethink',\n",
       " 'revers',\n",
       " 'right',\n",
       " 'risk',\n",
       " 'role',\n",
       " 'room',\n",
       " 'run',\n",
       " 'rutt',\n",
       " 'salford',\n",
       " 'sarecmarjan',\n",
       " 'say',\n",
       " 'school',\n",
       " 'scienc',\n",
       " 'seat',\n",
       " 'second',\n",
       " 'secur',\n",
       " 'seek',\n",
       " 'seem',\n",
       " 'semitism',\n",
       " 'sensibl',\n",
       " 'servic',\n",
       " 'session',\n",
       " 'set',\n",
       " 'shape',\n",
       " 'shortli',\n",
       " 'show',\n",
       " 'shropshir',\n",
       " 'sick',\n",
       " 'side',\n",
       " 'sign',\n",
       " 'simpl',\n",
       " 'sincer',\n",
       " 'situat',\n",
       " 'societi',\n",
       " 'solut',\n",
       " 'somerset',\n",
       " 'soon',\n",
       " 'speak',\n",
       " 'special',\n",
       " 'spend',\n",
       " 'spring',\n",
       " 'stage',\n",
       " 'stand',\n",
       " 'start',\n",
       " 'statement',\n",
       " 'step',\n",
       " 'stick',\n",
       " 'still',\n",
       " 'stoical',\n",
       " 'stop',\n",
       " 'strategi',\n",
       " 'street',\n",
       " 'strive',\n",
       " 'strong',\n",
       " 'succeed',\n",
       " 'success',\n",
       " 'suffer',\n",
       " 'suggest',\n",
       " 'summit',\n",
       " 'support',\n",
       " 'surrenderbil',\n",
       " 'sutton',\n",
       " 'tackl',\n",
       " 'take',\n",
       " 'talk',\n",
       " 'talkradio',\n",
       " 'taoiseach',\n",
       " 'tax',\n",
       " 'taxpay',\n",
       " 'team',\n",
       " 'ten',\n",
       " 'tendenc',\n",
       " 'thank',\n",
       " 'that',\n",
       " 'therefor',\n",
       " 'theresa_may',\n",
       " 'thesun',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'third',\n",
       " 'throughout',\n",
       " 'time',\n",
       " 'to',\n",
       " 'today',\n",
       " 'togeth',\n",
       " 'tomorrow',\n",
       " 'tonight',\n",
       " 'took',\n",
       " 'tori',\n",
       " 'tour',\n",
       " 'track',\n",
       " 'trade',\n",
       " 'tradit',\n",
       " 'trap',\n",
       " 'trust',\n",
       " 'uk',\n",
       " 'unanim',\n",
       " 'uncertain',\n",
       " 'uncertainti',\n",
       " 'union',\n",
       " 'unit',\n",
       " 'uniti',\n",
       " 'urg',\n",
       " 'us',\n",
       " 'use',\n",
       " 'valu',\n",
       " 'version',\n",
       " 'video',\n",
       " 'view',\n",
       " 'visibl',\n",
       " 'vision',\n",
       " 'visit',\n",
       " 'vital',\n",
       " 'vote',\n",
       " 'voter',\n",
       " 'wait',\n",
       " 'want',\n",
       " 'warn',\n",
       " 'way',\n",
       " 'we',\n",
       " 'wealth',\n",
       " 'wednesday',\n",
       " 'week',\n",
       " 'weekend',\n",
       " 'well',\n",
       " 'west',\n",
       " 'westminst',\n",
       " 'what',\n",
       " 'whether',\n",
       " 'whole',\n",
       " 'wight',\n",
       " 'willing',\n",
       " 'win',\n",
       " 'withdraw',\n",
       " 'without',\n",
       " 'work',\n",
       " 'worker',\n",
       " 'wors',\n",
       " 'written',\n",
       " 'year',\n",
       " 'yesterday',\n",
       " 'yet',\n",
       " 'yorkshir',\n",
       " 'young']"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As you can see, we reduced the amount of tokens from 790 to 532.\n",
    "# Let's look at them to see whether this makes more sense.\n",
    "tokens = vectorizer.get_feature_names()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_handle</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Corbyn and his friends in Parliament don’t tru...</td>\n",
       "      <td>corbyn friend parliament trust make decis let ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>eucopresident</td>\n",
       "      <td>EU27 has agreed an extension of Art. 50. I wil...</td>\n",
       "      <td>eu27 agre extens art meet pm @theresa_may uk g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_handle                                         tweet_text  \\\n",
       "0   BorisJohnson  Corbyn and his friends in Parliament don’t tru...   \n",
       "7  eucopresident  EU27 has agreed an extension of Art. 50. I wil...   \n",
       "\n",
       "                                           processed  \n",
       "0  corbyn friend parliament trust make decis let ...  \n",
       "7  eu27 agre extens art meet pm @theresa_may uk g...  "
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (4) Pairwise cosine Similarity scores:\n",
    "# Calculating pariwise cosine similarity is super easy in\n",
    "# python. You just submit two individual rows (documents)\n",
    "# of your DTM to the cosine_similarity function from sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# If we look at the df dataframe, we can pick two tweets from\n",
    "# Boris and Tusk and see how they compare in terms of cosine \n",
    "# similarity \n",
    "df.loc[[0,7],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07106691]])"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(sparse_dtm[0,], sparse_dtm[7,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_handle</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BorisJohnson</td>\n",
       "      <td>Corbyn and his friends in Parliament don’t tru...</td>\n",
       "      <td>corbyn friend parliament trust make decis let ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>theresa_may</td>\n",
       "      <td>My message to Jeremy Corbyn: people want polit...</td>\n",
       "      <td>messag jeremi corbyn peopl want politician get...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_handle                                         tweet_text  \\\n",
       "0   BorisJohnson  Corbyn and his friends in Parliament don’t tru...   \n",
       "15   theresa_may  My message to Jeremy Corbyn: people want polit...   \n",
       "\n",
       "                                            processed  \n",
       "0   corbyn friend parliament trust make decis let ...  \n",
       "15  messag jeremi corbyn peopl want politician get...  "
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Theresa and Boris might be more similar? \n",
    "df.loc[[0, 15],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35533453]])"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(sparse_dtm[0,], sparse_dtm[15,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Exercise 04\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# (1) Unit of analysis challenge: Single tweets lead to zero-inflated\n",
    "# DTMs, use the join() function to collapse all tweets from each user\n",
    "# into a single string object. You should end with a list of three\n",
    "# large strings.\n",
    "# Tip: Google how to apply join() to a list of strings.\n",
    "\n",
    "# (2) Process these three strings above using the word_tokenizer, \n",
    "# lowercasing, punctuation removal, number removal, \n",
    "# stopword removal, and stemming with the PorterStemmer.\n",
    "\n",
    "# (3) Turn this into a DTM for these three documents (3 rows)\n",
    "\n",
    "# (4) Our prior believe is that BorisJohnson is more similar to \n",
    "# theresa_may than to eucopresident in terms of their Brexit tweets.\n",
    "# Do the pairwise cosine similarity scores confirm that prior believe?\n",
    "\n",
    "# (5) Now repeat exercises 2 to 4, but use the Twitter tokenizer \n",
    "# instead. Is there a significant difference in the outcome? Which\n",
    "# tokenizer should I use if I want to analyze these tweets?\n",
    "\n",
    "# (6) What happens to these cosine similarity scores if I use the \n",
    "# Tfidf Vectorizer instead of the CountVectorizer from sklearn?\n",
    "\n",
    "# (7) For extra points: Apply cosine similarity scores to each \n",
    "# individual tweet-tweet combination, average the multidimensional\n",
    "# numpy array you get to understand for each tweet in the dataframe\n",
    "# how much this tweet resembles tweets from Boris, Theresa, and Donald\n",
    "# respectively. So, you should have three additional variables in your\n",
    "# DataFrame relating to 'boris_csim', 'theresa_csim', and 'tusk_csim'.\n",
    "# Tipp: Find the mean for each of these comparisons by applying the mean\n",
    "# function to a subset of the multidimensional numpy array that relates\n",
    "# to Boris, Theresa, or Tusks' tweets respectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
